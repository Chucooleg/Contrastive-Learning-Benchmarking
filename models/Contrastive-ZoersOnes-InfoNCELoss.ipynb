{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchucooleg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import math\n",
    "import json\n",
    "from typing import Callable, Iterable, Tuple\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 1\n",
    "\n",
    "def construct_full_model(hparams):\n",
    "    '''\n",
    "    return: nn.Module. Take a sequence of input symbols and \n",
    "    return a sequence of output symbols\n",
    "    '''\n",
    "\n",
    "    # cloned\n",
    "    clone = copy.deepcopy\n",
    "    pff = Positiontwise_FF(d_model=hparams['d_model'], d_ff=hparams['d_ff'])\n",
    "    attn = MultiHeadAttention(\n",
    "        d_model=hparams['d_model'], \n",
    "        h=hparams['num_heads'], \n",
    "        attn_wt_dropout=hparams['attn_wt_dropout'],\n",
    "    )\n",
    "    layer_norm = LayerNorm(d_model=hparams['d_model'])\n",
    "\n",
    "    # embeddings\n",
    "    scaled_embed_X = ScaledEmbedding(hparams['vocab_size'], hparams['d_model'])\n",
    "#     scaled_embed_query = ScaledEmbedding(hparams['vocab_size_query'], hparams['d_model'])\n",
    "    # shared\n",
    "    # position_encoder = PositionEncoder(\n",
    "    #     d_model=hparams['d_model'], \n",
    "    #     max_len=hparams['max_len'], \n",
    "    #     emb_var=torch.var(scaled_embed.embedding.weight)\n",
    "    # )\n",
    "    position_encoder = LearnedPositionEncoder(\n",
    "        d_model=hparams['d_model'], \n",
    "        max_len=hparams['max_len'],\n",
    "        emb_init_var=torch.var(scaled_embed_X.embedding.weight).cpu().item()\n",
    "    )\n",
    "#     query_position_encoder = LearnedQueryPositionEncoder(\n",
    "#         d_model=hparams['d_model'], \n",
    "#         max_len=hparams['max_len'], \n",
    "#         emb_init_var=torch.var(scaled_embed_X.embedding.weight).cpu().item()\n",
    "#     )\n",
    "    embed_dropout = nn.Dropout(hparams['embed_dropout'])\n",
    "\n",
    "    # full model\n",
    "    model = EncoderPredictor(\n",
    "        encoder_query=Encoder(\n",
    "            encoder_layer=EncoderLayer(\n",
    "                poswise_ff=clone(pff),\n",
    "                self_attn=clone(attn), \n",
    "                layer_norm=clone(layer_norm), \n",
    "                heads_dropout=hparams['heads_dropout'],\n",
    "                pff_dropout=hparams['pff_dropout']\n",
    "            ), \n",
    "            N_layers=hparams['N_enc'],\n",
    "            d_model=hparams['d_model'],\n",
    "        ),\n",
    "        encoder_key=Encoder(\n",
    "            encoder_layer=EncoderLayer(\n",
    "                poswise_ff=clone(pff),\n",
    "                self_attn=clone(attn), \n",
    "                layer_norm=clone(layer_norm), \n",
    "                heads_dropout=hparams['heads_dropout'],\n",
    "                pff_dropout=hparams['pff_dropout']\n",
    "            ), \n",
    "            N_layers=hparams['N_enc'],\n",
    "            d_model=hparams['d_model'],\n",
    "        ),\n",
    "        inp_query_layer=nn.Sequential(\n",
    "            OrderedDict([('scaled_embed', scaled_embed_X),\n",
    "                        ('position_encoder', position_encoder),\n",
    "                        ('embed_dropout', embed_dropout)]\n",
    "            )\n",
    "        ),\n",
    "        inp_key_layer=nn.Sequential(\n",
    "            OrderedDict([('scaled_embed', scaled_embed_X),\n",
    "                        ('position_encoder', position_encoder),\n",
    "                        ('embed_dropout', embed_dropout)]\n",
    "            )\n",
    "        ),\n",
    "        pad_idx_query=hparams['padding_idx_query'],\n",
    "        pad_idx_key=hparams['padding_idx_key'],\n",
    "        repr_pos=hparams['representation_pos']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 2\n",
    "\n",
    "class EncoderPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_query, encoder_key, inp_query_layer, inp_key_layer, pad_idx_query, pad_idx_key, repr_pos):\n",
    "        super(EncoderPredictor, self).__init__()\n",
    "        self.encoder_query = encoder_query\n",
    "        self.encoder_key = encoder_key\n",
    "        self.inp_query_layer = inp_query_layer\n",
    "        self.inp_key_layer = inp_key_layer\n",
    "        self.pad_idx_query = pad_idx_query\n",
    "        self.pad_idx_key = pad_idx_key\n",
    "        self.repr_pos = repr_pos\n",
    "\n",
    "    def forward(self, X_query, X_key, debug=False):\n",
    "        '''\n",
    "        X_query: (b, inp_len)\n",
    "        X_pos_key: (b, inp_len)\n",
    "        '''\n",
    "        assert X_query.shape == X_key.shape\n",
    "        b, l = X_query.shape\n",
    "        \n",
    "        # shape(batch_size=b, inp_len)\n",
    "        inp_query_pads = (X_query == self.pad_idx_query).int()\n",
    "        # shape(batch_size=b, inp_len)\n",
    "        inp_key_pads = (X_key == self.pad_idx_key).int()\n",
    "        \n",
    "        # shape(b, inp_len, d_model)\n",
    "        encoder_query_out = self.encode_query(X_query, inp_query_pads)        \n",
    "        # shape(b, inp_len, d_model)\n",
    "        encoder_key_out = self.encode_query(X_key, inp_key_pads)\n",
    "        \n",
    "        # choose position to extract vector!\n",
    "        # shape(b, d_model), shape(b, d_model)\n",
    "        query_repr, key_repr = encoder_query_out[:,self.repr_pos,:], encoder_key_out[:,self.repr_pos,:]\n",
    "        \n",
    "        # project vectors one more time?\n",
    "        \n",
    "        # make b by b dotproduct=logit matrix\n",
    "        dot_product_logits = torch.sum((query_repr.unsqueeze(1) * key_repr.unsqueeze(0)), dim=-1)\n",
    "        assert dot_product_logits.shape == (b, b)\n",
    "        \n",
    "        # shape(b, b)\n",
    "        return dot_product_logits        \n",
    "\n",
    "\n",
    "    def encode_query(self, X, inp_pads):\n",
    "        '''\n",
    "        X: (batch_size=b, inp_len)\n",
    "        inp_pads: (batch_size=b, inp_len)\n",
    "        '''\n",
    "        # shape(b, inp_len, d_model)\n",
    "        inp_embed = self.inp_query_layer(X)\n",
    "        # shape(b, N_enc, inp_len, d_model)\n",
    "        encoder_out = self.encoder_query(inp_embed, inp_pads)\n",
    "        \n",
    "        # only take the top layer output\n",
    "        # shape(b, inp_len, d_model)\n",
    "        return encoder_out[:, -1, :, :]\n",
    "\n",
    "    \n",
    "    def encode_key(self, X, inp_pads):\n",
    "        '''\n",
    "        X: (batch_size=b, inp_len)\n",
    "        inp_pads: (batch_size=b, inp_len)\n",
    "        '''\n",
    "        # shape(b, inp_len, d_model)\n",
    "        inp_embed = self.inp_key_layer(X)\n",
    "        # shape(b, N_enc, inp_len, d_model)\n",
    "        encoder_out = self.encoder_key(inp_embed, inp_pads)\n",
    "        \n",
    "        # only take the top layer output\n",
    "        # shape(b, inp_len, d_model)\n",
    "        return encoder_out[:, -1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 3\n",
    "# http://karlstratos.com/notes/transformer17.pdf\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_layer, N_layers, d_model):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [copy.deepcopy(encoder_layer) for _ in range(N_layers)])\n",
    "        self.N_layers = N_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, inp_embedding, inp_pads):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        inp_embedding: Input embeddings. Already position encoded.\n",
    "                        shape (batch_size=b, inp_len, d_model)\n",
    "        inp_pads: Input pads. shape (batch_size=b, inp_len). 1s are padded.\n",
    "        Returns\n",
    "        encoder_out: output from encoder stack. \n",
    "                    shape (batch_size=b, inp_len, d_model)\n",
    "        \"\"\"\n",
    "        m, inp_len, d_model = inp_embedding.shape\n",
    "\n",
    "        # Make self-attn mask\n",
    "        self_attn_mask = make_attn_mask(inp_pads, inp_pads, mask_forward=False)\n",
    "\n",
    "        # Initiate encoder output tensor\n",
    "        encoder_out = torch.empty(\n",
    "            m, self.N_layers, inp_len, self.d_model).type_as(inp_embedding)\n",
    "\n",
    "        # Loop through layers in stack\n",
    "        last_z = inp_embedding\n",
    "        for l, encoder_layer in enumerate(self.encoder_layers):\n",
    "            # shape (b, inp_len, d_model)\n",
    "            last_z, _ = encoder_layer(last_z, self_attn_mask)\n",
    "#             print(\"encoder layer\",l)\n",
    "            encoder_out[:, l, :, :] = last_z\n",
    "\n",
    "        # shape(b, N_enc, inp_len, d_model)\n",
    "        return encoder_out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_layer, N_layers, d_model):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [copy.deepcopy(decoder_layer) for _ in range(N_layers)])\n",
    "        self.N_layers = N_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, encoder_out, out_embedding, \n",
    "                inp_pads, out_pads, max_decode=100):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        encoder_out: output from encoder stack.\n",
    "                    shape (batch_size=b, N_enc, inp_len, d_model)\n",
    "        out_embedding: Output embedding. Shape (batch_size=b, out_len, d_model)\n",
    "                    Already position encoded. Offset by one position.\n",
    "        inp_pads: Input pads. shape (batch_size=b, inp_len). 1s are padded.\n",
    "        out_pads: Input pads. shape (batch_size=b, out_len). 1s are padded.\n",
    "        Returns\n",
    "            decoder_out: output from decoder stack\n",
    "        \"\"\"\n",
    "        # b, N_enc, inp_len, d_model = encoder_out.shape\n",
    "        # b, out_len, d_model = out_embedding.shape\n",
    "\n",
    "        self_attn_mask = make_attn_mask(out_pads, out_pads, mask_forward=True)\n",
    "        cross_attn_mask = make_attn_mask(out_pads, inp_pads, mask_forward=False)\n",
    "\n",
    "        # Loop through layers in stack\n",
    "        last_o = out_embedding\n",
    "        for l, decoder_layer in enumerate(self.decoder_layers):\n",
    "            # shape (b, out_len, d_model)\n",
    "            last_o, _, _ = decoder_layer(\n",
    "                last_o, \n",
    "                # encoder_out[:, -1, :, :],\n",
    "                encoder_out[:, l, :, :],\n",
    "                self_attn_mask, cross_attn_mask\n",
    "            )\n",
    "        decoder_output = last_o\n",
    "        return decoder_output\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, shared_embed):\n",
    "        '''\n",
    "        shared_embed: same embedding matrix as the input and output layers.\n",
    "                    shape(V, d_model)\n",
    "        '''\n",
    "        super(Classifier, self).__init__()\n",
    "        self.shared_embed = shared_embed\n",
    "\n",
    "    def forward(self, decoder_out):\n",
    "        '''\n",
    "        decoder_out: last layer output of decoder stack. \n",
    "                 shape(batch_size=b, out_len, d_model)\n",
    "        '''\n",
    "        # shape (b, out_len, d_model) mm (d_model, V) = (b, out_len, V)\n",
    "        logits = decoder_out.matmul(self.shared_embed.weight.t())\n",
    "        # # shape (b, out_len, V) too expensive to compute everytime\n",
    "        # probs = torch.softmax(logits, dim=-1)\n",
    "        return logits #, probs\n",
    "\n",
    "\n",
    "class ScaledEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, V, d_model):\n",
    "        super(ScaledEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(V, d_model)\n",
    "        # scale embedding to have variance 0.01\n",
    "        nn.init.normal_(self.embedding.weight, mean=0., std=(0.01)**(1/2))\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        '''\n",
    "        tokens: shape (batch_size=b, len)\n",
    "        '''\n",
    "        # shape (b, len, d_model)\n",
    "        embedded = self.embedding(tokens) * math.sqrt(self.d_model)\n",
    "        if torch.max(embedded) > 2000.:\n",
    "            import pdb; pdb.set_trace()\n",
    "        return embedded\n",
    "\n",
    "    \n",
    "class PositionEncoder(nn.Module):\n",
    "    # Alternative implementation\n",
    "    # https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb\n",
    "\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionEncoder, self).__init__()\n",
    "        # even\n",
    "        # i = 0, 2, 4, 6, ..., 510\n",
    "        # j = 0, 1, 2, 3, ..., 255\n",
    "        # PE(pos, i=2j) = sin(pos/10000**(2*j/d_model))\n",
    "        # odd\n",
    "        # i = 1, 3, 5, 7, ..., 511\n",
    "        # j = 0, 1, 2, 3, ..., 255\n",
    "        # PE(pos, i=2j+1) = cos(pos/10000**(2*j/d_model))\n",
    "        # shape(256,)\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.register_buffer(\n",
    "            name=\"positional_encoding\", \n",
    "            tensor=self.make_encodings(self.d_model, self.max_len)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def make_encodings(d_model, max_len):\n",
    "        # shape (d_model/2)\n",
    "        div_terms = torch.pow(\n",
    "            10000, \n",
    "            2*torch.arange(start=0, # j = 0\n",
    "                       end=d_model/2 # j = 255\n",
    "            )/d_model\n",
    "        )\n",
    "\n",
    "        # shape (max_len,) -> shape (max_len, d_model)\n",
    "        positions = torch.arange(\n",
    "            max_len\n",
    "            ).unsqueeze(-1).expand(-1, d_model)\n",
    "\n",
    "        # shape (max_len, d_model)\n",
    "        positional_encoding = torch.empty(\n",
    "            max_len, d_model, dtype=torch.float, \n",
    "        )\n",
    "    \n",
    "        # shape (max_len, d_model/2)\n",
    "        pos_at_even_dims = positions[:, ::2]\n",
    "        # shape (max_len, d_model/2)\n",
    "        pos_at_odd_dims  = positions[:, 1::2]\n",
    "\n",
    "        # shape (max_len, d_model/2)\n",
    "        div_terms_expand = div_terms.unsqueeze(0).expand(max_len, -1)\n",
    "\n",
    "        # shape (max_len, d_model/2)\n",
    "        positional_encoding[:, ::2] = torch.sin(pos_at_even_dims / div_terms_expand)\n",
    "        # shape (max_len, d_model/2)\n",
    "        positional_encoding[:, 1::2] = torch.cos(pos_at_odd_dims / div_terms_expand)\n",
    "\n",
    "        # shape (max_len, d_model)\n",
    "        return positional_encoding\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        '''\n",
    "        embedded: shape (batch_size=b, len, d_model)\n",
    "        '''\n",
    "        b, len, d_model = embedded.shape\n",
    "        assert len <= self.max_len\n",
    "        # shape (batch_size=b, len, d_model)\n",
    "        positional_encoding = (\n",
    "            self.positional_encoding[:len, :].unsqueeze(0).expand(b, -1, -1)\n",
    "        )\n",
    "        # shape (batch_size=b, len, d_model)\n",
    "        return positional_encoding + embedded\n",
    "\n",
    "\n",
    "class LearnedPositionEncoder(nn.Module):\n",
    "    '''Learned, instead of sinusoidal position encoder'''\n",
    "\n",
    "    def __init__(self, d_model, max_len, emb_init_var):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            torch.nn.init.normal_(\n",
    "                torch.zeros(max_len, d_model), \n",
    "                mean=0.0, \n",
    "#                 std=1.0,\n",
    "#                 std=(emb_init_var)**(0.5)\n",
    "                std=(emb_init_var/2)**(0.5)\n",
    "        ))\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        '''\n",
    "        embedded: shape (batch_size=b, len, d_model)\n",
    "        '''\n",
    "        b, inp_len, d_model = embedded.shape\n",
    "        # shape (1, len, d_model)\n",
    "        pos_embeddings = self.pos_embedding[:inp_len, :].unsqueeze(0)\n",
    "        \n",
    "        # use broadcasting\n",
    "        # shape (b, len, d_model)\n",
    "        return embedded + pos_embeddings\n",
    "\n",
    "\n",
    "class LearnedScenePositionEncoder(nn.Module):\n",
    "    '''Learned position encoder for scene. Each position i,j is concat of encoding_i and encoding_j'''\n",
    "    def __init__(self, d_model, grid_dim, emb_init_var):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.grid_dim = grid_dim\n",
    "        self.emb_init_var = emb_init_var\n",
    "        \n",
    "        self.pos_embedding_i = nn.Parameter(\n",
    "            torch.nn.init.normal_(\n",
    "                torch.zeros(grid_dim, d_model/2), \n",
    "                mean=0.0, \n",
    "                std=(emb_init_var/2)**(0.5)\n",
    "            ).unsqueeze(1)\n",
    "        )\n",
    "        self.pos_embedding_j = nn.Parameter(\n",
    "            torch.nn.init.normal_(\n",
    "                torch.zeros(grid_dim, d_model/2), \n",
    "                mean=0.0, \n",
    "                std=(emb_init_var/2)**(0.5)\n",
    "            ).unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "    def make_embedding_ij(self):\n",
    "        pos_embedding_ij = torch.cat(\n",
    "            (\n",
    "                self.pos_embedding_i.expand(\n",
    "                    self.pos_embedding_i.shape[0],\n",
    "                    self.grid_dim,\n",
    "                    self.pos_embedding_i.shape[1]\n",
    "                ),\n",
    "                self.pos_embedding_j.expand(\n",
    "                    self.grid_dim,\n",
    "                    self.pos_embedding_j.shape[0],\n",
    "                    self.pos_embedding_j.shape[1]\n",
    "                )\n",
    "            ),\n",
    "            dim=-1\n",
    "        )\n",
    "        assert pos_embedding_ij.shape == (self.grid_dim, self.grid_dim, self.d_model)\n",
    "        # shape (grid_dim**2, d_model)\n",
    "        # order(0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)\n",
    "        return pos_embedding_ij.view(-1, self.d_model)\n",
    "        \n",
    "    def forward(self, embedded):\n",
    "        '''\n",
    "        embedded: shape (batch_size=b, grid_dim**2, d_model)\n",
    "        '''\n",
    "        b, inp_len, d_model = embedded.shape\n",
    "        # shape (1, len=grid_dim**2, d_model)\n",
    "        pos_embeddings = self.make_embedding_ij().unsqueeze(0)\n",
    "        # use broadcasting\n",
    "        # shape (b, len=grid_dim**2, d_model)\n",
    "        return embedded + pos_embeddings        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing positional encoder\n",
    "\n",
    "def test_positional_encoder(PositionEncoder, max_len=10, d_model=64):\n",
    "    # test positional encoding\n",
    "    b, len, d_model = 20, max_len, d_model\n",
    "    embedding = torch.randn(b, len, d_model)\n",
    "    pos_enc = PositionEncoder(d_model, 50)\n",
    "    positional_encoding = pos_enc.positional_encoding\n",
    "    plot_positional_encoding(positional_encoding)\n",
    "\n",
    "def plot_positional_encoding(positional_encoding):\n",
    "    '''\n",
    "    positional_encoding: tensor shape (len, d_model)\n",
    "    '''\n",
    "\n",
    "    tokens, dimensions = positional_encoding.shape\n",
    "  \n",
    "    pos_encoding = positional_encoding.unsqueeze(0).cpu().numpy()\n",
    "\n",
    "    print (pos_encoding.shape)\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.pcolormesh(pos_encoding[0], cmap='viridis')\n",
    "    plt.xlabel('Embedding Dimensions')\n",
    "    plt.xlim((0, dimensions))\n",
    "    plt.ylim((tokens,0))\n",
    "    plt.ylabel('Token Position')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "test_positional_encoder(PositionEncoder, d_model=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 4\n",
    "# http://karlstratos.com/notes/transformer17.pdf\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    '''\n",
    "    single layer encoder\n",
    "    '''\n",
    "    def __init__(self, poswise_ff, self_attn, layer_norm,\n",
    "                heads_dropout, pff_dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.poswise_ff = poswise_ff\n",
    "        self.self_attn = self_attn\n",
    "        self.layer_norms = nn.ModuleList([copy.deepcopy(layer_norm) for _ in range(2)])\n",
    "        self.heads_dropout = nn.Dropout(heads_dropout)\n",
    "        self.pff_dropout = nn.Dropout(pff_dropout)\n",
    "\n",
    "    def forward(self, z_lm1, self_attn_mask):\n",
    "        '''\n",
    "        z_lm1 : last encoder layer activations. shape (batch_size=b, inp_len, d_model)\n",
    "        '''\n",
    "\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_h, self_attn_wts = self.self_attn(z_lm1, z_lm1, self_attn_mask)\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_h_norm = self.layer_norms[0](z_lm1 + self.heads_dropout(z_lm1_h))\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_ff = self.poswise_ff(z_lm1_h_norm)\n",
    "        # (b, inp_len, d_model)\n",
    "        z_l = self.layer_norms[1](z_lm1_h_norm + self.pff_dropout(z_lm1_ff))\n",
    "        \n",
    "        if torch.isinf(z_l).any() or torch.isnan(z_l).any():\n",
    "            print(\"z_l is nan or inf\")\n",
    "            import pdb; pdb.set_trace()\n",
    "        \n",
    "        return z_l, self_attn_wts\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    '''\n",
    "    single layer decoder\n",
    "    '''\n",
    "    def __init__(self, poswise_ff, self_attn, cross_attn, \n",
    "                layer_norm, heads_dropout, pff_dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.poswise_ff = poswise_ff\n",
    "        self.self_attn = self_attn\n",
    "        self.cross_attn = cross_attn\n",
    "        self.layer_norms = nn.ModuleList([copy.deepcopy(layer_norm) for _ in range(3)])\n",
    "        self.heads_dropout = nn.Dropout(heads_dropout)\n",
    "        self.pff_dropout = nn.Dropout(pff_dropout)\n",
    "\n",
    "    def forward(self, o_lm1, encoder_l_output, self_attn_mask, cross_attn_mask):\n",
    "        '''\n",
    "        o_lm1 : last decoder layer activations. \n",
    "            shape (batch_size=b, out_len, d_model).\n",
    "        encoder_l_output : encoder output from at the same layer index. \n",
    "                       shape (batch_size=b, inp_len, d_model)\n",
    "        '''\n",
    "\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_self_h, self_attn_wts = self.self_attn(o_lm1, o_lm1, self_attn_mask)\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_self_h_norm = self.layer_norms[0](o_lm1 + self.heads_dropout(o_lm1_self_h))\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_cross_h, cross_attn_wts = self.cross_attn(o_lm1_self_h_norm, encoder_l_output, cross_attn_mask)\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_cross_h_norm = self.layer_norms[1](o_lm1_self_h_norm + self.heads_dropout(o_lm1_cross_h))\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_ff = self.poswise_ff(o_lm1_cross_h_norm)\n",
    "        # (b, out_len, d_model)\n",
    "        o_l = self.layer_norms[2](o_lm1_cross_h_norm + self.pff_dropout(o_lm1_ff))\n",
    "        return o_l, self_attn_wts, cross_attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 5\n",
    "# https://arxiv.org/pdf/1607.06450.pdf\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    '''Layer Normalization'''\n",
    "\n",
    "    def __init__(self, d_model, epsilon=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(d_model))\n",
    "        self.bias = nn.Parameter(torch.zeros(d_model))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x : shape (m, len, d_model)\n",
    "        Returns:\n",
    "            whitened_x : shape (m, len, d_model)\n",
    "        '''\n",
    "        # (m, len, 1)\n",
    "        mu = torch.mean(x, dim=-1, keepdim=True)\n",
    "        std = torch.std(x, dim=-1, keepdim=True)\n",
    "        # (m, len, d_model)\n",
    "        whitened_x = self.gain * (x - mu / (std + self.epsilon)) + self.bias\n",
    "        return whitened_x\n",
    "\n",
    "\n",
    "class Positiontwise_FF(nn.Module):\n",
    "    '''Pointwise FeedForward / Fat-RELU'''\n",
    "\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(Positiontwise_FF, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x : shape (m, len, d_model)\n",
    "        Returns:\n",
    "            shape (m, len, d_model)\n",
    "        '''\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multihead Attention'''\n",
    "\n",
    "    def __init__(self, d_model, h, attn_wt_dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h = h\n",
    "        self.d_model = d_model\n",
    "        # d_k, same as d_q, d_v\n",
    "        self.d_k = int(d_model / h)\n",
    "        \n",
    "\n",
    "        ############################################################\n",
    "        # simply use clone\n",
    "    \n",
    "#         # shape (d_model, d_k * h = d_model)\n",
    "#         projection = nn.Linear(d_model, d_model, bias=True)\n",
    "#         # clone projection to become WQ, WK, WV, WO\n",
    "#         self.projections_QKVO = nn.ModuleList([copy.deepcopy(projection) for _ in range(4)])\n",
    "        ############################################################\n",
    "#         # Untie only WQ\n",
    "\n",
    "#         # template for WQ, WK, WV, WO projection matrices\n",
    "#         # shape (d_model, d_k * h = d_model)\n",
    "#         make_projection = lambda: nn.Linear(d_model, d_model, bias=True)\n",
    "\n",
    "#         # shape (d_model, d_k * h = d_model)\n",
    "#         shared_projection = make_projection()\n",
    "\n",
    "#         # WQ independent, WKVO shared\n",
    "#         projections = (\n",
    "#             [make_projection()] + [copy.deepcopy(shared_projection) for _ in range(3)]\n",
    "#         )\n",
    "#         self.projections_QKVO = nn.ModuleList(projections)\n",
    "\n",
    "        ############################################################\n",
    "        # Untie WQ, WK, WV, WO\n",
    "        \n",
    "        # template for WQ, WK, WV, WO projection matrices\n",
    "        # shape (d_model, d_k * h = d_model)\n",
    "        make_projection = lambda: nn.Linear(d_model, d_model, bias=True)\n",
    "        # make WQ, WK, WV, WO\n",
    "        self.projections_QKVO = nn.ModuleList([make_projection() for _ in range(4)])\n",
    "        ############################################################\n",
    "       # initialize WO as zeros to start training w/ identity function\n",
    "        self.projections_QKVO[3].weight.data = self.projections_QKVO[3].weight.data * 0.0\n",
    "        self.projections_QKVO[3].bias.data = self.projections_QKVO[3].bias.data * 0.0\n",
    "        ############################################################       \n",
    "        \n",
    "        self.attn_wt_dropout = nn.Dropout(p=attn_wt_dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, X, Y, mask):\n",
    "        '''\n",
    "        Args:\n",
    "            X : Attender. shape (batch_size=b, attender len=n, d_model)\n",
    "            Y : Attendee. shape (batch_size=b, attendee len=m, d_model)\n",
    "        Return:\n",
    "            attn_V : shape (b, n, h*d_k=d_model)\n",
    "        '''\n",
    "        b, n, d_model = X.shape\n",
    "\n",
    "        # Project X and Y to Q, K, V matrices\n",
    "        # Step 1 W(vals)\n",
    "        # XQ shape(b, n, d_k *h = d_model)\n",
    "        # YK shape(b, m, d_k *h = d_model)\n",
    "        # YV shape(b, m, d_k *h = d_model)\n",
    "        # Step 2 reshape()\n",
    "        # XQ shape(b, n, h, d_k)\n",
    "        # YK shape(b, m, h, d_k)\n",
    "        # YV shape(b, m, h, d_k)\n",
    "        # Step 3 swap axis with transpose()\n",
    "        # XQ shape(b, h, n, d_k)\n",
    "        # YK shape(b, h, m, d_k)\n",
    "        # YV shape(b, h, m, d_k)\n",
    "        XQ, YK, YV = [\n",
    "                      W(vals).reshape(b, -1, self.h, self.d_k)\n",
    "                      .transpose(1, 2) \n",
    "                      for (W, vals) in zip(self.projections_QKVO[:3], (X, Y, Y))]\n",
    "\n",
    "        # attention weighted values, attention weights\n",
    "        # shape (b, n, h, d_k), (b, h, n, m)\n",
    "        concat_V, attn = dotproduct_attention(\n",
    "            XQ, YK, YV, mask, self.attn_wt_dropout)\n",
    "        # shape (b, n, h*d_k=d_model)\n",
    "        concat_V = concat_V.reshape(b, n, -1)\n",
    "\n",
    "        # project by WO, shape (b, n, h*d_k=d_model)\n",
    "        attn_V = self.projections_QKVO[3](concat_V)\n",
    "   \n",
    "        return attn_V, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[[0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 1., 0.]]])\n",
      "alpha\n",
      " tensor([[[[-1.0231,  0.0260,  0.2767],\n",
      "          [ 0.7859,  0.2193,  0.9244],\n",
      "          [-0.5686,  1.7561,  1.9875]],\n",
      "\n",
      "         [[-0.5513, -0.7215,  0.3740],\n",
      "          [ 0.9782,  1.1411, -0.4604],\n",
      "          [-0.0315,  0.7704, -0.9848]]]])\n",
      "mask_stack\n",
      " tensor([[[[0., 1., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 0.]]]])\n",
      "alpha_masked\n",
      " tensor([[[[-1.0231e+00, -1.0000e+04,  2.7667e-01],\n",
      "          [ 7.8594e-01, -1.0000e+04,  9.2435e-01],\n",
      "          [-1.0000e+04, -1.0000e+04,  1.9875e+00]],\n",
      "\n",
      "         [[-5.5126e-01, -1.0000e+04,  3.7404e-01],\n",
      "          [ 9.7823e-01, -1.0000e+04, -4.6042e-01],\n",
      "          [-1.0000e+04, -1.0000e+04, -9.8484e-01]]]])\n",
      "beta\n",
      " tensor([[[[0.2142, 0.0000, 0.7858],\n",
      "          [0.4655, 0.0000, 0.5345],\n",
      "          [0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.2839, 0.0000, 0.7161],\n",
      "          [0.8082, 0.0000, 0.1918],\n",
      "          [0.0000, 0.0000, 1.0000]]]])\n",
      "wt_V\n",
      " tensor([[[[ 0.0503,  1.3734,  1.3906,  1.1347, -1.4249],\n",
      "          [ 0.2252,  0.0178,  1.1088, -1.3340, -0.2037]],\n",
      "\n",
      "         [[ 0.3770,  1.4147,  0.6841,  0.8578, -1.6775],\n",
      "          [-0.3468, -1.9870,  0.6939, -1.2022,  0.5139]],\n",
      "\n",
      "         [[-0.2282,  1.3382,  1.9929,  1.3708, -1.2096],\n",
      "          [ 0.5349,  1.1031,  1.3334, -1.4053, -0.5922]]]])\n",
      "ref wt_V\n",
      " tensor([[[[ 0.0503,  1.3734,  1.3906,  1.1347, -1.4249],\n",
      "          [ 0.2252,  0.0178,  1.1088, -1.3340, -0.2037]],\n",
      "\n",
      "         [[ 0.3770,  1.4147,  0.6841,  0.8578, -1.6775],\n",
      "          [-0.3468, -1.9870,  0.6939, -1.2022,  0.5139]],\n",
      "\n",
      "         [[-0.2282,  1.3382,  1.9929,  1.3708, -1.2096],\n",
      "          [ 0.5349,  1.1031,  1.3334, -1.4053, -0.5922]]]])\n",
      "ref wt_V\n",
      " torch.Size([1, 2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "## Code Depth 6\n",
    "\n",
    "def dotproduct_attention(Q, K, V, mask, beta_dropout, debug=False):\n",
    "    '''\n",
    "    Q: shape(batch_size=b, num heads=h, attender len=n, d_k)\n",
    "    K: shape(batch_size=b, num heads=h, attendee len=m, d_k)\n",
    "    V: shape(batch_size=b, num heads=h, attendee len=m, d_k)\n",
    "    mask: shape(batch_size=b, n, m)\n",
    "    beta_dropout: nn.Dropout().apply module\n",
    "    '''\n",
    "    b, h, n, d_k = Q.shape\n",
    "    b, h, m, d_k = K.shape\n",
    "\n",
    "    # XQ shape(b, h, n, d_k) matmul YK.T shape(b, h, d_k, m)\n",
    "    # = alpha shape (b, h, n, m)\n",
    "    alpha = torch.matmul(Q, K.transpose(-1, -2))/ math.sqrt(d_k)\n",
    "\n",
    "    # Apply mask \n",
    "    # (b, h, n, m)\n",
    "    mask_stack = mask.unsqueeze(1).expand(-1, h, -1, -1)\n",
    "    alpha_masked = torch.masked_fill(alpha, mask_stack==1, -1e4)\n",
    "\n",
    "    # normalize across attendee len m\n",
    "    # (b, h, n, m)\n",
    "    beta = beta_dropout(torch.softmax(alpha_masked, dim=-1))\n",
    "\n",
    "    # beta shape(b, h, n, m) bmm YK.T shape(b, h, m, d_k) = shape (b, h, n, d_k)\n",
    "    # transpose to (b, n, h, d_k)\n",
    "    wt_V = torch.matmul(beta, V).transpose(1, 2)\n",
    "\n",
    "    if debug:\n",
    "        print('alpha\\n', alpha)\n",
    "        print('mask_stack\\n', mask_stack)\n",
    "        print('alpha_masked\\n', alpha_masked)\n",
    "        print('beta\\n', beta)\n",
    "        print('wt_V\\n', wt_V)\n",
    "        \n",
    "    return wt_V, beta\n",
    "\n",
    "\n",
    "def ref_attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 1, -1e9)\n",
    "    p_attn = torch.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "def test_attention(attn_fn):\n",
    "    torch.manual_seed(123)\n",
    "    b, h, n, m, d_k = 1, 2, 3, 3, 5\n",
    "    Q = torch.randn(b, h, n, d_k)\n",
    "    K = torch.randn(b, h, m, d_k)\n",
    "    V = torch.randn(b, h, m, d_k)\n",
    "\n",
    "    # print('Q\\n', Q)\n",
    "    # print('K\\n', K)\n",
    "    # print('V\\n', V)\n",
    "\n",
    "    mask = torch.zeros((b, n, m))\n",
    "    mask[:,:,1] = 1\n",
    "    mask[:,2,:1] = 1\n",
    "    print('input', mask)\n",
    "\n",
    "    my_wt_V = dotproduct_attention(Q, K, V, mask, nn.Dropout(0.0), debug=True)\n",
    "    ref_wt_V, ref_p_attn = ref_attention(Q, K, V, mask, nn.Dropout(0.0))\n",
    "  \n",
    "    print('ref wt_V\\n', ref_wt_V.transpose(1, 2))\n",
    "    print('ref wt_V\\n', ref_wt_V.shape)\n",
    "\n",
    "test_attention(dotproduct_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Attention:\n",
      "attender_mask_expanded\n",
      " tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]]])\n",
      "attendee_mask_expanded\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]]])\n",
      "sum mask\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]]], dtype=torch.int32)\n",
      "--------------------------------------\n",
      "Self Attention:\n",
      "future_mask\n",
      " tensor([[0, 1, 1, 1],\n",
      "        [0, 0, 1, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 0, 0, 0]])\n",
      "attender_mask_expanded\n",
      " tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]]])\n",
      "attendee_mask_expanded\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]]])\n",
      "sum mask\n",
      " tensor([[[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_attn_mask(attender_pads, attendee_pads, mask_forward=False, debug=False):\n",
    "    '''\n",
    "    Mask away attendee positions from attender.\n",
    "    Args:\n",
    "        attender_pads: shape(batch_size=b, attender len=n). 1s are pads.\n",
    "        attendee_pads: shape(batch_size=b, attender len=m). 1s are pads.\n",
    "    Return:\n",
    "        attn_mask: shape(b, n, m)\n",
    "    '''\n",
    "\n",
    "    b, n = attender_pads.shape\n",
    "    b, m = attendee_pads.shape\n",
    "\n",
    "    if mask_forward: \n",
    "        assert n == m\n",
    "        # shape (n, m)\n",
    "        try:\n",
    "            future_mask = torch.from_numpy(\n",
    "                np.triu(np.ones((n, m)), k=1)).type_as(attender_pads)\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "        # shape (b, n, m)\n",
    "        future_mask_expanded = future_mask.unsqueeze(0).expand(b, -1, -1)\n",
    "\n",
    "    # shape(b, n, m)\n",
    "    attender_mask_expanded = attender_pads.unsqueeze(-1).expand(-1, -1, m)\n",
    "    # shape(b, n, m)\n",
    "    attendee_mask_expanded = attendee_pads.unsqueeze(1).expand(-1, n, -1)\n",
    "\n",
    "    # shape(b, n, m)\n",
    "    if mask_forward: \n",
    "        sum_mask = attender_mask_expanded + attendee_mask_expanded + future_mask\n",
    "    else:\n",
    "        sum_mask = attender_mask_expanded + attendee_mask_expanded\n",
    "    sum_mask = (sum_mask > 0).type(torch.int)\n",
    "\n",
    "    if debug:\n",
    "        if mask_forward:\n",
    "            print('future_mask\\n',future_mask)\n",
    "        print('attender_mask_expanded\\n',attender_mask_expanded)\n",
    "        print('attendee_mask_expanded\\n',attendee_mask_expanded)\n",
    "        print('sum mask\\n', sum_mask)\n",
    "\n",
    "    return sum_mask\n",
    "\n",
    "\n",
    "def test_make_attn_mask():\n",
    "    #   attender_pads = torch.tensor([[0,0,0,1,1], [0,0,1,1,1], [0,0,0,0,0]])\n",
    "    attender_pads = torch.tensor([[0,0,0,1], [0,0,0,0], [0,0,0,1]])\n",
    "    attendee_pads = torch.tensor([[0,0,0,1], [0,0,0,0], [0,0,0,1]])\n",
    "    print('Cross Attention:')\n",
    "    make_attn_mask(attender_pads, attendee_pads, mask_forward=False, debug=True)\n",
    "    print('--------------------------------------')\n",
    "    print('Self Attention:')\n",
    "    make_attn_mask(attender_pads, attender_pads, mask_forward=True, debug=True)\n",
    "\n",
    "\n",
    "test_make_attn_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LabelSmoothedLoss(nn.Module):\n",
    "    '''\n",
    "    KL divergence Loss with Label Smoothing and Temperature scaling\n",
    "    '''\n",
    "\n",
    "#     def __init__(self, K, padding_idx, smoothing_const=0.0, temperature_const=1.0):\n",
    "    def __init__(self, K, smoothing_const=0.0, temperature_const=1.0):\n",
    "        super(LabelSmoothedLoss, self).__init__()\n",
    "        self.smoothing_const = smoothing_const\n",
    "        self.temperature_const = temperature_const\n",
    "        self.K = K\n",
    "#         self.padding_idx = padding_idx\n",
    "        self.KLdiv_criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.logprob = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, logits, labels, debug=False):\n",
    "        '''\n",
    "        logits: shape (batch_size=b, 1 + num_negatives)\n",
    "        labels: shape (batch_size=b,)\n",
    "        '''\n",
    "        b, K = logits.shape\n",
    "\n",
    "        # Temperature Scaling\n",
    "        # shape (b, K)\n",
    "        scaled_logits = logits / self.temperature_const\n",
    "        pred_logprobs = self.logprob(scaled_logits)\n",
    "\n",
    "        # Expand Labels to one-hot, Smooth the values\n",
    "        gt_probs_smoothed = torch.full(\n",
    "            size=(b, K), \n",
    "            # fill_value=self.smoothing_const / (K - 1), # more mathematicaly correct\n",
    "            fill_value=self.smoothing_const / (K - 1) #minus true\n",
    "            # fill_value=self.smoothing_const / (K - 2) #minus true and padding\n",
    "        ).type_as(logits)\n",
    "\n",
    "        gt_probs_smoothed = gt_probs_smoothed.scatter(\n",
    "            dim=-1, \n",
    "            index=labels.reshape(-1, 1), \n",
    "            value=(1. - self.smoothing_const),\n",
    "            # value=(1. - self.smoothing_const) + (self.smoothing_const / (K - 1)) # more mathematicaly correct\n",
    "        )\n",
    "        \n",
    "#         # Zero out padding idx\n",
    "#         # shape (b, K)\n",
    "#         gt_probs_smoothed[:, self.padding_idx] = 0.\n",
    "    \n",
    "#         # Apply mask (e.g. if end of context is padded)\n",
    "#         # shape (b, 1)\n",
    "#         mask_ctx_pos = torch.nonzero(torch.flatten(labels) == self.padding_idx)\n",
    "#         if mask_ctx_pos.dim() > 0:\n",
    "#             # zero out rows for padded context positions\n",
    "#             # e.g. word at position 10 is a pad, we zero out all probs for row 10\n",
    "#             gt_probs_smoothed.index_fill_(\n",
    "#                 dim=0, index=mask_ctx_pos.squeeze(), value=0.0)\n",
    "\n",
    "        if debug:\n",
    "            print(scaled_logits)\n",
    "            print(labels_onehot)\n",
    "            print(mask_ctx_pos)\n",
    "        \n",
    "        try:\n",
    "            assert torch.all(\n",
    "                torch.logical_or(\n",
    "                    torch.logical_and(\n",
    "                        # sum of probs == 1\n",
    "                        # torch.greater(torch.sum(gt_probs_smoothed, dim=-1), 0.999),\n",
    "                        # torch.less(torch.sum(gt_probs_smoothed, dim=-1), 1.001) \n",
    "                        torch.all(torch.sum(gt_probs_smoothed, dim=-1) > 0.999),\n",
    "                        torch.all(torch.sum(gt_probs_smoothed, dim=-1) < 1.001) \n",
    "                    ),\n",
    "                    # except padded positions in context\n",
    "                    torch.eq(torch.sum(gt_probs_smoothed, dim=-1), 0.)\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        return self.KLdiv_criterion(input=pred_logprobs, target=gt_probs_smoothed)\n",
    "\n",
    "\n",
    "# Only Use for verification\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "#     def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "    def __init__(self, size, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "#         self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "#         true_dist[:, self.padding_idx] = 0\n",
    "#         mask = torch.nonzero(target.data == self.padding_idx)\n",
    "#         if mask.dim() > 0:\n",
    "#             true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "\n",
    "\n",
    "def test_loss_function(myLoss, refLoss, smoothing_const, temperature_const):\n",
    "    K = 3\n",
    "    padding_idx = 2\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    myKL = myLoss(K, smoothing_const, temperature_const)\n",
    "    refKL = refLoss(K, smoothing_const)\n",
    "\n",
    "    labels = torch.tensor([1, 1, 1, 0, 1])\n",
    "    inputs = torch.randn(5, 3) * 4\n",
    "    print(inputs)\n",
    "\n",
    "    ref_loss = refKL(F.log_softmax(inputs, dim=-1).reshape(-1, 3), torch.flatten(labels))\n",
    "    my_loss = myKL(inputs, labels )\n",
    "    #   if temperature_const == 1.0:\n",
    "    #     assert ref_loss == my_loss\n",
    "    print(ref_loss)\n",
    "    print(my_loss)\n",
    "\n",
    "# test_loss_function(myLoss=LabelSmoothedLoss, refLoss=LabelSmoothing, smoothing_const=0.1, temperature_const=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LRScheduledAdam(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Adam algorithm with learning rate schedule.\n",
    "    Modified based on hugging face implementation:\n",
    "    https://huggingface.co/transformers/_modules/transformers/optimization.html#AdamW\n",
    "\n",
    "    Parameters:\n",
    "        params (:obj:`Iterable[torch.nn.parameter.Parameter]`):\n",
    "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
    "        d_model (:obj:`int`):\n",
    "            Dimension of embedding vector.\n",
    "        warmup_steps (:obj:`int`):\n",
    "            Steps for warmup before learning rate peaks.\n",
    "        lr (:obj:`float`, `optional`, defaults to 0.):\n",
    "            The learning rate to use.\n",
    "        betas (:obj:`Tuple[float,float]`, `optional`, defaults to (0.9, 0.999)):\n",
    "            Adam's betas parameters (b1, b2).\n",
    "        eps (:obj:`float`, `optional`, defaults to 1e-6):\n",
    "            Adam's epsilon for numerical stability.\n",
    "        weight_decay (:obj:`float`, `optional`, defaults to 0):\n",
    "            Decoupled weight decay to apply.\n",
    "        correct_bias (:obj:`bool`, `optional`, defaults to `True`):\n",
    "            Whether ot not to correct bias in Adam (for instance, in Bert TF repository they use :obj:`False`).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Iterable[torch.nn.parameter.Parameter],\n",
    "        d_model: int,\n",
    "        warmup_steps: int,\n",
    "        lr: float = 0.,\n",
    "        betas: Tuple[float, float] = (0.9, 0.98),\n",
    "        eps: float = 1e-9,\n",
    "        correct_bias: bool = True,\n",
    "    ):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
    "        defaults = dict(\n",
    "            lr=lr, betas=betas, eps=eps, correct_bias=correct_bias)\n",
    "        super().__init__(params, defaults)\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def calc_step_size(self, step_num):\n",
    "        '''\n",
    "        Udpate lr\n",
    "        '''\n",
    "        return (\n",
    "            self.d_model**(-0.5) * min(step_num**(-0.5), step_num * self.warmup_steps**(-1.5))\n",
    "        )\n",
    "    \n",
    "\n",
    "    def step(self, closure: Callable = None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state[\"step\"] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
    "                beta1, beta2 = group[\"betas\"]\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                # In-place operations to update the averages at the same time\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1.0 - beta1)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
    "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
    "\n",
    "                group[\"lr\"] = self.calc_step_size(state[\"step\"])\n",
    "                step_size = group[\"lr\"]\n",
    "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
    "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
    "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
    "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "        return loss\n",
    "\n",
    "def plot_lr(myOpt):\n",
    "    model = nn.Linear(2,3)\n",
    "    opts = [myOpt(model.parameters(), 512, 4000), \n",
    "            myOpt(model.parameters(), 512, 8000),\n",
    "            myOpt(model.parameters(), 256, 4000)]\n",
    "    plt.plot(np.arange(1, 20000), [[opt.calc_step_size(i) for opt in opts] for i in range(1, 20000)])\n",
    "    plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "\n",
    "plot_lr(LRScheduledAdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_sequence(model, X, start_idx_Y, pad_idx_X, pad_idx_Y, max_len):\n",
    "    '''\n",
    "    Greedy Decoding\n",
    "    X : a sequence of input symbols. shape(batch_size=b, inp_len)\n",
    "    start_idx_Y: int.\n",
    "    pad_idx_X: int.\n",
    "    pad_idx_Y: int.\n",
    "    max_len: int. Maximum context length for generation. Include <SOS> and <EOS>\n",
    "    '''\n",
    "\n",
    "    b, inp_len = X.shape\n",
    "    inp_pads = (X == pad_idx_X).int()\n",
    "\n",
    "    # encode inputs\n",
    "    # shape (b, inp_len, d_model)\n",
    "    encoded_memory = model.encode(X, inp_pads)\n",
    " \n",
    "    # shape (b, max_len) e.g. (b, 10)\n",
    "    Y = torch.ones(b, max_len).type_as(X) * pad_idx_Y\n",
    "    Y[:,0] = start_idx_Y\n",
    "    # shape (b, max_len)\n",
    "    out_pads = (Y == pad_idx_Y).int()\n",
    "  \n",
    "    # generate one token at a time\n",
    "    for t in range(1, max_len): # (1 to 9)\n",
    "\n",
    "        # shape (b, t, d_model)\n",
    "        decoder_output = model.decode(encoded_memory, Y[:, :t], inp_pads, out_pads[:, :t])\n",
    "\n",
    "        # shape (b, t, V)\n",
    "        decoded_logits = model.classifier(decoder_output)\n",
    "        # decoded_probs = torch.softmax(decoded_logits, dim=-1)\n",
    "    \n",
    "        # shape (b,), (b,)\n",
    "        max_prob, max_idx = torch.max(decoded_logits[:, -1, :], dim=-1)\n",
    "    \n",
    "        # update Y, out_pads for next timestep\n",
    "        Y[:, t] = max_idx\n",
    "        out_pads[:, t] = (max_idx == pad_idx_Y).int()\n",
    "\n",
    "    # shape (b, max_len)\n",
    "    # (1 to 9)\n",
    "    return Y[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiclass_accuracy(start_idx_Y, pad_idx_Y, pred, labels):\n",
    "    '''\n",
    "    pred: shape (batch_size, max_len)\n",
    "    labels: shape (batch_size, max_len) \n",
    "    '''\n",
    "    assert not start_idx_Y in labels, '<GO> should not be evaluated'\n",
    "\n",
    "    mask = 1 - (labels == pad_idx_Y).int() # 0 means padded\n",
    "    tot_not_masked = torch.sum(mask)\n",
    "\n",
    "    same = (pred == labels).int() * mask\n",
    "    tot_correct = torch.sum(same)\n",
    "\n",
    "    return tot_correct * 1.0 / tot_not_masked\n",
    "\n",
    "# 4/6\n",
    "multiclass_accuracy(1, 0, torch.tensor([[2,2,0,0],[7,8,7,0]]), torch.tensor([[2,2,0,4],[7,8,9,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "def matrix_accuracy(logits):\n",
    "    '''logits: shape(b, b) matrix'''\n",
    "    b, b2 = logits.shape\n",
    "    assert b == b2\n",
    "    \n",
    "    # shape(b, )\n",
    "    labels = torch.arange(b).type_as(logits).long()\n",
    "    # \n",
    "    max_indices_per_col = torch.max(logits, dim=0)[1]\n",
    "    min_indices_per_col = torch.min(logits, dim=0)[1]\n",
    "    max_indices_per_row = torch.max(logits, dim=1)[1]\n",
    "    min_indices_per_row = torch.min(logits, dim=1)[1]\n",
    "\n",
    "    acc_across_cols = torch.mean((max_indices_per_col == labels ).type_as(logits) * (max_indices_per_col != min_indices_per_col).type_as(logits))\n",
    "    acc_across_rows = torch.mean((max_indices_per_row == labels ).type_as(logits) * (max_indices_per_row != min_indices_per_row).type_as(logits))\n",
    "                                 \n",
    "    return (acc_across_cols + acc_across_rows) * 0.5\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "logits = torch.tensor([\n",
    "    [1.,2.,3.],\n",
    "    [6.,7.,4.],\n",
    "    [5.,8.,9.]\n",
    "])\n",
    "\n",
    "# ((2/3) + (1/3))/2 = 0.5\n",
    "print(matrix_accuracy(logits))\n",
    "# ---------------------------\n",
    "logits = torch.tensor([\n",
    "    [3.,2.,3.],\n",
    "    [6.,7.,4.],\n",
    "    [5.,8.,9.]\n",
    "])\n",
    "\n",
    "# ((3/3) + (1/3))/2 = 0.66666\n",
    "print(matrix_accuracy(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_loss_per_row= tensor(20.0001)\n",
      "sum_loss_per_col= tensor(60.0001)\n",
      "avg loss= tensor(40.0001)\n",
      "-------------\n",
      "sum_loss_per_row= tensor(0.6933)\n",
      "sum_loss_per_col= tensor(40.0001)\n",
      "avg loss= tensor(20.3467)\n"
     ]
    }
   ],
   "source": [
    "class InfoCELoss(nn.Module):\n",
    "    '''\n",
    "    InfoCE Loss on a (b, b) logits matrix with Temperature scaling\n",
    "    '''\n",
    "\n",
    "    def __init__(self, temperature_const=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature_const = temperature_const\n",
    "        self.CE_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    def forward(self, logits, debug=False):\n",
    "        '''\n",
    "        logits: shape (batch_size=b, b)\n",
    "        '''\n",
    "        assert logits.shape[0] == logits.shape[1]\n",
    "        b = logits.shape[0]\n",
    "        \n",
    "        logits /= self.temperature_const\n",
    "        \n",
    "        labels = torch.arange(b).type_as(logits).long()\n",
    "        sum_loss_per_row = self.CE_loss(logits, labels)\n",
    "        sum_loss_per_col = self.CE_loss(logits.T, labels)\n",
    "        \n",
    "        if debug:\n",
    "            print('sum_loss_per_row=',sum_loss_per_row)\n",
    "            print('sum_loss_per_col=',sum_loss_per_col)\n",
    "\n",
    "        loss = (sum_loss_per_row + sum_loss_per_col) * 0.5\n",
    "        return loss\n",
    "\n",
    "\n",
    "# ---------------------------    \n",
    "loss_criterion = InfoCELoss(temperature_const=0.1)\n",
    "\n",
    "logits = torch.tensor([\n",
    "    [1.,2.,3.],\n",
    "    [6.,7.,4.],\n",
    "    [5.,8.,9.]\n",
    "])\n",
    "print('avg loss=',loss_criterion(logits, True))\n",
    "print('-------------')\n",
    "logits = torch.tensor([\n",
    "    [3.,2.,3.],\n",
    "    [6.,7.,4.],\n",
    "    [5.,8.,9.]\n",
    "])\n",
    "print('avg loss=',loss_criterion(logits, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Lightning Module\n",
    "# https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=UIXLW8CO-W8w\n",
    "\n",
    "class Transformer(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.model = construct_full_model(hparams)\n",
    "        \n",
    "#         self.loss_criterion = LabelSmoothedLoss(\n",
    "#             K= 1 + hparams['num_negatives'], # num positive queries + num negative queries\n",
    "#             smoothing_const=hparams['smoothing_const'],\n",
    "#             temperature_const=hparams['temperature_const']\n",
    "#         )\n",
    "#         self.loss_criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "        \n",
    "        self.loss_criterion = InfoCELoss(temperature_const=self.hparams['loss_temperature_const'])\n",
    "        self.accuracy = matrix_accuracy\n",
    "    \n",
    "    def log_metrics(self, metrics_dict):\n",
    "        for k, v in metrics_dict.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "    def get_max_memory_alloc(self):\n",
    "        devices_max_memory_alloc = {}\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            device = torch.device(f'cuda:{i}')\n",
    "            devices_max_memory_alloc[device] = torch.cuda.max_memory_allocated(device) / 1e6\n",
    "            torch.cuda.reset_max_memory_allocated(device)\n",
    "        return devices_max_memory_alloc\n",
    "    \n",
    "    def forward(self, X_query, X_pos_key, debug=False):\n",
    "        batch_size = X_query.shape[0]\n",
    "        # shape (b, num pos keys + num neg keys)\n",
    "        logits = self.model(X_query, X_pos_key, debug=debug)\n",
    "        loss = self.loss_criterion(logits)\n",
    "        acc = self.accuracy(logits)\n",
    "        return loss, acc\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # (b, inp_len), (b, inp_len), (b, num_negs, inp_len)\n",
    "        X_query, X_pos_key = batch\n",
    "        loss, acc = self(X_query, X_pos_key, debug=False)\n",
    "        # logs\n",
    "        step_metrics = {'train_loss': loss, 'train_acc':acc}\n",
    "        self.log_metrics(step_metrics)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        X_query, X_pos_key = batch\n",
    "        loss, acc = self(X_query, X_pos_key)\n",
    "        # print sample\n",
    "#         print('X_query:',X_query[0], '\\X_pos_key:',X_pos_key[0], '\\X_neg_keys:',X_neg_keys[0], '\\nloss:', loss, '\\nacc:', acc)\n",
    "        # log\n",
    "        step_metrics = {'val_loss': loss, 'val_acc': acc}\n",
    "        devices_max_memory_alloc = self.get_max_memory_alloc()\n",
    "        for device, val in devices_max_memory_alloc.items():\n",
    "            step_metrics[f'step_max_memory_alloc_cuda:{device}'] = val\n",
    "        self.log_metrics(step_metrics)\n",
    "        return step_metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        X_query, X_pos_key = batch\n",
    "        loss, acc = self(X_query, X_pos_key)\n",
    "        # log\n",
    "        step_metrics = {'test_loss': loss, 'test_acc': acc}\n",
    "        self.log_metrics(step_metrics)\n",
    "        return step_metrics\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        # log metrics\n",
    "        epoch_metrics = {'avg_val_loss': avg_loss, 'avg_val_acc': avg_acc}\n",
    "        self.log_metrics(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        # log\n",
    "        epoch_metrics = {'avg_test_loss': avg_loss, 'avg_test_acc': avg_acc}\n",
    "        self.log_metrics(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt = LRScheduledAdam(\n",
    "            params=self.model.parameters(),\n",
    "            d_model=self.hparams['d_model'], \n",
    "            warmup_steps=self.hparams['warmup_steps'],\n",
    "            lr=0.,\n",
    "            betas=(\n",
    "                self.hparams['adam_beta1'], self.hparams['adam_beta2']),\n",
    "            eps=self.hparams['adam_epsilon'],\n",
    "            correct_bias=True\n",
    "        )\n",
    "        \n",
    "        # learning rate decay on top of LRScheduled Adam\n",
    "        # Decays the learning rate of each parameter group by gamma every step_size epochs. \n",
    "#         scheduler = StepLR(opt, step_size=self.hparams['lr_decay_step_size'], gamma=self.hparams['lr_decay_gamma'], last_epoch=-1)\n",
    "#         return scheduler\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count distribution:\n",
      "train 49786 scenes \n",
      ": [(296, 133), (186, 130), (160, 129), (387, 127), (303, 125), (148, 125), (280, 122), (273, 121), (34, 121), (127, 121), (188, 120), (458, 120), (238, 120), (419, 120), (347, 120), (109, 119), (43, 119), (214, 119), (44, 119), (231, 119), (224, 118), (88, 118), (386, 118), (448, 117), (172, 117), (203, 117), (93, 117), (357, 117), (414, 116), (285, 116), (11, 116), (185, 116), (9, 116), (355, 116), (163, 115), (489, 115), (151, 115), (306, 115), (319, 115), (342, 114), (360, 114), (180, 114), (352, 114), (21, 114), (95, 114), (341, 114), (390, 114), (143, 114), (247, 114), (427, 114), (372, 113), (478, 113), (51, 113), (451, 112), (378, 112), (379, 112), (283, 112), (176, 112), (101, 112), (345, 112), (370, 112), (171, 112), (492, 112), (27, 112), (331, 111), (256, 111), (401, 111), (392, 111), (50, 111), (332, 111), (213, 111), (484, 111), (348, 110), (475, 110), (190, 110), (398, 110), (13, 110), (397, 110), (314, 110), (236, 110), (5, 110), (479, 110), (126, 110), (6, 109), (234, 109), (141, 109), (323, 109), (187, 109), (453, 109), (139, 109), (405, 109), (254, 109), (423, 109), (308, 109), (441, 109), (295, 109), (467, 109), (336, 109), (409, 109), (239, 108), (28, 108), (253, 108), (350, 108), (10, 108), (164, 108), (327, 108), (326, 108), (179, 108), (17, 108), (64, 108), (90, 108), (389, 108), (292, 108), (40, 108), (424, 108), (111, 107), (29, 107), (437, 107), (158, 107), (413, 107), (316, 107), (98, 107), (439, 106), (258, 106), (431, 106), (432, 106), (462, 106), (343, 106), (242, 106), (216, 106), (193, 106), (493, 106), (430, 106), (286, 106), (168, 105), (196, 105), (206, 105), (330, 105), (31, 105), (162, 105), (230, 105), (209, 105), (494, 105), (125, 105), (271, 105), (39, 105), (228, 105), (260, 105), (61, 105), (450, 105), (66, 105), (317, 105), (443, 105), (74, 104), (204, 104), (8, 104), (365, 104), (252, 104), (275, 104), (52, 104), (246, 104), (129, 104), (58, 104), (281, 104), (121, 104), (380, 104), (123, 104), (112, 104), (155, 104), (147, 104), (79, 104), (3, 104), (418, 104), (215, 104), (243, 104), (255, 103), (269, 103), (322, 103), (57, 103), (466, 103), (49, 103), (268, 103), (156, 103), (137, 103), (191, 103), (197, 103), (208, 103), (149, 103), (87, 103), (99, 103), (335, 103), (344, 103), (159, 103), (289, 103), (106, 103), (497, 103), (407, 102), (288, 102), (496, 102), (442, 102), (207, 102), (174, 102), (485, 102), (235, 102), (257, 102), (476, 102), (361, 102), (97, 102), (434, 102), (382, 102), (298, 102), (299, 102), (114, 101), (78, 101), (117, 101), (483, 101), (142, 101), (96, 101), (192, 101), (279, 101), (146, 101), (108, 101), (92, 101), (173, 101), (132, 101), (20, 101), (377, 101), (100, 101), (248, 101), (104, 101), (22, 101), (315, 101), (240, 101), (262, 101), (153, 101), (65, 101), (227, 100), (184, 100), (464, 100), (297, 100), (119, 100), (304, 100), (42, 100), (116, 100), (36, 100), (452, 100), (445, 100), (465, 100), (320, 100), (69, 100), (30, 100), (486, 100), (321, 100), (265, 100), (167, 99), (340, 99), (83, 99), (394, 99), (154, 99), (376, 99), (276, 99), (232, 99), (222, 99), (59, 99), (241, 99), (278, 99), (175, 99), (436, 99), (54, 99), (86, 99), (291, 99), (157, 99), (416, 99), (124, 99), (373, 99), (135, 99), (385, 99), (202, 99), (233, 98), (490, 98), (290, 98), (77, 98), (293, 98), (420, 98), (14, 98), (84, 98), (412, 98), (150, 98), (329, 98), (435, 98), (170, 98), (145, 98), (212, 98), (178, 98), (12, 98), (138, 98), (374, 98), (410, 98), (456, 98), (301, 98), (259, 97), (102, 97), (328, 97), (177, 97), (218, 97), (221, 97), (244, 97), (459, 97), (68, 97), (41, 97), (211, 97), (403, 97), (384, 96), (468, 96), (300, 96), (67, 96), (110, 96), (426, 96), (404, 96), (131, 96), (393, 96), (353, 96), (118, 96), (491, 96), (144, 96), (19, 96), (120, 96), (122, 96), (277, 96), (282, 96), (346, 95), (63, 95), (133, 95), (73, 95), (313, 95), (267, 95), (477, 95), (402, 95), (24, 95), (263, 95), (454, 95), (324, 95), (237, 95), (471, 95), (422, 95), (488, 95), (181, 95), (115, 95), (463, 95), (415, 95), (470, 95), (152, 95), (113, 95), (411, 95), (229, 95), (35, 95), (449, 94), (4, 94), (307, 94), (266, 94), (169, 94), (250, 94), (46, 94), (195, 94), (455, 94), (15, 94), (474, 94), (481, 94), (226, 94), (400, 93), (366, 93), (38, 93), (198, 93), (371, 93), (94, 93), (318, 93), (425, 93), (76, 93), (53, 93), (72, 93), (220, 93), (408, 93), (201, 93), (480, 92), (469, 92), (461, 92), (140, 92), (210, 92), (460, 92), (447, 92), (47, 92), (337, 92), (128, 91), (333, 91), (103, 91), (388, 91), (354, 91), (446, 91), (219, 91), (71, 91), (359, 91), (334, 91), (381, 91), (199, 91), (82, 91), (302, 90), (37, 90), (305, 90), (309, 90), (364, 90), (223, 90), (498, 90), (130, 90), (438, 90), (56, 90), (444, 90), (339, 90), (482, 90), (351, 90), (161, 90), (70, 90), (33, 90), (166, 90), (189, 90), (251, 89), (60, 89), (23, 89), (383, 88), (428, 88), (310, 88), (7, 88), (217, 88), (358, 88), (368, 88), (165, 88), (272, 87), (395, 87), (75, 87), (26, 87), (91, 87), (396, 87), (182, 87), (81, 87), (421, 87), (245, 87), (369, 87), (249, 86), (200, 86), (134, 86), (311, 86), (32, 86), (55, 86), (264, 86), (473, 86), (472, 86), (284, 85), (325, 85), (270, 85), (399, 85), (440, 85), (375, 84), (194, 84), (495, 84), (362, 84), (105, 84), (417, 84), (45, 84), (80, 84), (391, 84), (25, 84), (274, 83), (225, 83), (205, 83), (429, 83), (338, 82), (48, 82), (406, 82), (136, 82), (62, 81), (363, 81), (18, 81), (349, 81), (107, 81), (457, 80), (367, 80), (261, 80), (2, 80), (287, 80), (183, 79), (16, 79), (312, 77), (433, 77), (487, 76), (499, 76), (89, 76), (1, 76), (356, 76), (294, 74), (85, 70), (0, 1), (500, 1)]\n",
      "valid 1000 scenes \n",
      ": [(276, 9), (224, 8), (19, 8), (128, 7), (386, 7), (126, 6), (339, 6), (28, 6), (370, 5), (146, 5), (263, 5), (364, 5), (179, 5), (403, 5), (188, 5), (379, 5), (116, 5), (68, 5), (8, 5), (428, 5), (97, 5), (413, 5), (11, 5), (477, 5), (108, 5), (338, 5), (384, 5), (361, 5), (460, 4), (292, 4), (422, 4), (497, 4), (355, 4), (230, 4), (45, 4), (469, 4), (314, 4), (418, 4), (496, 4), (433, 4), (44, 4), (54, 4), (175, 4), (308, 4), (378, 4), (74, 4), (3, 4), (129, 4), (229, 4), (337, 4), (73, 4), (466, 4), (173, 4), (288, 4), (259, 4), (305, 4), (102, 4), (273, 4), (72, 4), (40, 4), (64, 4), (137, 4), (486, 4), (424, 4), (382, 4), (426, 4), (4, 4), (122, 4), (110, 4), (47, 4), (239, 4), (442, 4), (383, 4), (55, 4), (222, 4), (470, 4), (298, 3), (376, 3), (324, 3), (38, 3), (463, 3), (199, 3), (340, 3), (295, 3), (297, 3), (301, 3), (272, 3), (252, 3), (397, 3), (154, 3), (317, 3), (98, 3), (170, 3), (251, 3), (10, 3), (241, 3), (264, 3), (380, 3), (198, 3), (16, 3), (482, 3), (457, 3), (210, 3), (7, 3), (41, 3), (91, 3), (178, 3), (226, 3), (144, 3), (22, 3), (275, 3), (437, 3), (167, 3), (207, 3), (111, 3), (419, 3), (107, 3), (223, 3), (398, 3), (392, 3), (311, 3), (315, 3), (375, 3), (347, 3), (215, 3), (161, 3), (390, 3), (306, 3), (351, 3), (78, 3), (70, 3), (235, 3), (62, 3), (373, 3), (148, 3), (421, 3), (243, 3), (26, 3), (331, 3), (58, 3), (37, 3), (75, 3), (183, 3), (334, 3), (293, 3), (216, 3), (411, 3), (181, 3), (236, 3), (284, 3), (56, 3), (454, 3), (254, 3), (491, 3), (412, 3), (400, 3), (492, 3), (79, 3), (42, 3), (114, 3), (118, 3), (145, 3), (233, 3), (25, 3), (430, 3), (455, 3), (194, 2), (352, 2), (286, 2), (447, 2), (124, 2), (280, 2), (393, 2), (36, 2), (220, 2), (1, 2), (451, 2), (487, 2), (302, 2), (195, 2), (238, 2), (309, 2), (476, 2), (278, 2), (405, 2), (147, 2), (166, 2), (140, 2), (63, 2), (34, 2), (31, 2), (104, 2), (316, 2), (394, 2), (307, 2), (417, 2), (83, 2), (414, 2), (52, 2), (369, 2), (142, 2), (119, 2), (329, 2), (153, 2), (354, 2), (429, 2), (180, 2), (168, 2), (130, 2), (141, 2), (357, 2), (76, 2), (184, 2), (29, 2), (155, 2), (244, 2), (472, 2), (258, 2), (471, 2), (467, 2), (474, 2), (171, 2), (478, 2), (436, 2), (336, 2), (242, 2), (50, 2), (475, 2), (138, 2), (6, 2), (150, 2), (261, 2), (499, 2), (249, 2), (51, 2), (271, 2), (24, 2), (162, 2), (219, 2), (112, 2), (213, 2), (246, 2), (294, 2), (404, 2), (256, 2), (200, 2), (202, 2), (310, 2), (450, 2), (444, 2), (485, 2), (363, 2), (106, 2), (121, 2), (27, 2), (95, 2), (282, 2), (349, 2), (377, 2), (9, 2), (498, 2), (218, 2), (344, 2), (407, 2), (174, 2), (481, 2), (165, 2), (13, 2), (493, 2), (231, 2), (204, 2), (49, 2), (312, 2), (327, 2), (196, 2), (396, 2), (296, 2), (274, 2), (214, 2), (191, 2), (212, 2), (326, 2), (343, 2), (266, 2), (360, 2), (401, 2), (80, 2), (32, 2), (82, 1), (423, 1), (332, 1), (53, 1), (348, 1), (440, 1), (489, 1), (425, 1), (131, 1), (318, 1), (205, 1), (391, 1), (186, 1), (453, 1), (356, 1), (151, 1), (277, 1), (5, 1), (92, 1), (465, 1), (435, 1), (35, 1), (367, 1), (415, 1), (237, 1), (46, 1), (303, 1), (209, 1), (388, 1), (287, 1), (346, 1), (350, 1), (77, 1), (320, 1), (84, 1), (333, 1), (368, 1), (495, 1), (117, 1), (323, 1), (90, 1), (159, 1), (228, 1), (399, 1), (164, 1), (358, 1), (127, 1), (71, 1), (67, 1), (193, 1), (342, 1), (488, 1), (260, 1), (371, 1), (313, 1), (169, 1), (163, 1), (197, 1), (381, 1), (299, 1), (139, 1), (69, 1), (267, 1), (387, 1), (208, 1), (20, 1), (86, 1), (322, 1), (225, 1), (217, 1), (283, 1), (432, 1), (441, 1), (291, 1), (409, 1), (289, 1), (468, 1), (483, 1), (89, 1), (201, 1), (185, 1), (341, 1), (59, 1), (105, 1), (321, 1), (149, 1), (85, 1), (57, 1), (177, 1), (270, 1), (18, 1), (123, 1), (257, 1), (206, 1), (103, 1), (101, 1), (17, 1), (172, 1), (30, 1), (23, 1), (43, 1), (12, 1), (269, 1), (14, 1), (245, 1), (221, 1), (160, 1), (253, 1), (65, 1), (490, 1), (359, 1), (125, 1), (406, 1), (290, 1), (33, 1), (81, 1), (438, 1), (473, 1), (60, 1), (135, 1), (446, 1), (408, 1), (335, 1), (365, 1), (456, 1), (132, 1), (304, 1), (385, 1), (362, 1), (325, 1), (187, 1), (462, 1), (143, 1), (232, 1), (464, 1), (2, 1), (15, 1)]\n",
      "test 1000 scenes \n",
      ": [(3, 7), (119, 6), (436, 6), (66, 6), (495, 6), (94, 6), (248, 6), (25, 6), (32, 6), (405, 6), (109, 6), (17, 5), (226, 5), (228, 5), (310, 5), (340, 5), (324, 5), (154, 5), (218, 5), (12, 5), (414, 5), (290, 5), (342, 5), (115, 5), (329, 5), (411, 5), (238, 4), (352, 4), (100, 4), (26, 4), (332, 4), (6, 4), (425, 4), (149, 4), (69, 4), (497, 4), (475, 4), (172, 4), (53, 4), (373, 4), (150, 4), (267, 4), (496, 4), (200, 4), (455, 4), (34, 4), (239, 4), (348, 4), (426, 4), (357, 4), (482, 4), (64, 4), (31, 4), (161, 4), (368, 4), (208, 4), (456, 4), (102, 4), (253, 4), (146, 4), (22, 4), (473, 4), (155, 4), (148, 4), (296, 4), (423, 4), (291, 4), (250, 4), (391, 3), (73, 3), (86, 3), (399, 3), (254, 3), (442, 3), (52, 3), (213, 3), (67, 3), (162, 3), (170, 3), (58, 3), (74, 3), (464, 3), (316, 3), (141, 3), (428, 3), (15, 3), (93, 3), (222, 3), (96, 3), (212, 3), (468, 3), (424, 3), (33, 3), (457, 3), (265, 3), (139, 3), (350, 3), (91, 3), (138, 3), (272, 3), (288, 3), (412, 3), (311, 3), (376, 3), (5, 3), (493, 3), (10, 3), (103, 3), (190, 3), (204, 3), (408, 3), (262, 3), (147, 3), (245, 3), (433, 3), (395, 3), (393, 3), (41, 3), (118, 3), (463, 3), (244, 3), (392, 3), (312, 3), (314, 3), (98, 3), (29, 3), (259, 3), (343, 3), (8, 3), (299, 3), (269, 3), (362, 3), (251, 3), (293, 3), (184, 3), (351, 3), (401, 3), (429, 3), (70, 3), (388, 3), (281, 3), (16, 3), (18, 3), (39, 3), (194, 3), (241, 3), (274, 3), (13, 3), (87, 3), (302, 3), (427, 3), (19, 3), (284, 3), (431, 3), (341, 3), (409, 3), (367, 3), (37, 3), (364, 3), (84, 3), (345, 3), (303, 3), (448, 3), (301, 3), (27, 3), (390, 3), (242, 3), (45, 2), (209, 2), (55, 2), (432, 2), (441, 2), (153, 2), (28, 2), (437, 2), (105, 2), (24, 2), (478, 2), (89, 2), (354, 2), (326, 2), (199, 2), (330, 2), (196, 2), (298, 2), (167, 2), (271, 2), (246, 2), (370, 2), (365, 2), (403, 2), (297, 2), (374, 2), (387, 2), (375, 2), (358, 2), (117, 2), (92, 2), (278, 2), (333, 2), (124, 2), (177, 2), (249, 2), (283, 2), (185, 2), (168, 2), (494, 2), (75, 2), (366, 2), (472, 2), (232, 2), (313, 2), (491, 2), (489, 2), (179, 2), (499, 2), (127, 2), (384, 2), (108, 2), (47, 2), (164, 2), (279, 2), (275, 2), (192, 2), (346, 2), (216, 2), (114, 2), (331, 2), (131, 2), (444, 2), (207, 2), (492, 2), (182, 2), (35, 2), (305, 2), (438, 2), (276, 2), (292, 2), (483, 2), (56, 2), (188, 2), (337, 2), (380, 2), (61, 2), (461, 2), (465, 2), (406, 2), (224, 2), (486, 2), (404, 2), (280, 2), (113, 2), (220, 2), (449, 2), (397, 2), (440, 2), (110, 2), (191, 2), (80, 2), (120, 2), (68, 2), (158, 2), (307, 2), (38, 2), (300, 2), (443, 2), (260, 2), (104, 2), (396, 2), (178, 2), (308, 2), (320, 2), (221, 2), (446, 2), (479, 2), (231, 2), (171, 2), (54, 2), (163, 2), (413, 2), (344, 2), (360, 2), (460, 2), (434, 2), (157, 2), (227, 2), (327, 2), (452, 2), (217, 2), (181, 2), (180, 2), (176, 2), (488, 2), (236, 1), (126, 1), (490, 1), (7, 1), (30, 1), (183, 1), (187, 1), (106, 1), (49, 1), (315, 1), (44, 1), (422, 1), (230, 1), (223, 1), (50, 1), (252, 1), (323, 1), (215, 1), (116, 1), (48, 1), (165, 1), (169, 1), (386, 1), (439, 1), (339, 1), (273, 1), (447, 1), (383, 1), (198, 1), (477, 1), (21, 1), (379, 1), (20, 1), (144, 1), (174, 1), (137, 1), (202, 1), (81, 1), (474, 1), (134, 1), (128, 1), (470, 1), (90, 1), (466, 1), (317, 1), (135, 1), (485, 1), (51, 1), (453, 1), (121, 1), (347, 1), (355, 1), (143, 1), (484, 1), (132, 1), (421, 1), (72, 1), (480, 1), (268, 1), (23, 1), (318, 1), (78, 1), (233, 1), (263, 1), (336, 1), (304, 1), (83, 1), (415, 1), (286, 1), (459, 1), (255, 1), (173, 1), (325, 1), (111, 1), (381, 1), (430, 1), (175, 1), (334, 1), (206, 1), (193, 1), (467, 1), (435, 1), (349, 1), (416, 1), (295, 1), (225, 1), (321, 1), (235, 1), (145, 1), (369, 1), (240, 1), (2, 1), (210, 1), (82, 1), (159, 1), (14, 1), (417, 1), (481, 1), (122, 1), (151, 1), (214, 1), (277, 1), (76, 1), (328, 1), (195, 1), (4, 1), (189, 1), (261, 1), (197, 1), (257, 1), (371, 1), (402, 1), (60, 1), (363, 1), (123, 1), (42, 1), (62, 1), (65, 1), (420, 1), (201, 1), (205, 1), (458, 1), (353, 1), (130, 1), (186, 1), (445, 1), (309, 1), (356, 1), (377, 1), (229, 1), (95, 1), (112, 1), (322, 1), (85, 1), (476, 1), (36, 1), (400, 1), (419, 1), (97, 1), (359, 1), (306, 1)]\n",
      "samples:\n",
      "(1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1) 414\n",
      "(1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1) 346\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0) 63\n",
      "(0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0) 302\n",
      "(1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1) 400\n"
     ]
    }
   ],
   "source": [
    "# Generate datasets\n",
    "def gen_counting_data(len_context=9, num_train=20, num_val=5, num_test=5, seed=42):\n",
    "    \n",
    "    def map_count_to_scenes(counts):\n",
    "        count_to_scene_idx = {ct:set() for ct in range(len_context+1)}\n",
    "        for idx, ct in enumerate(counts):\n",
    "            count_to_scene_idx[ct].add(idx)\n",
    "        return count_to_scene_idx\n",
    "    \n",
    "    data = {}\n",
    "    num_rows = num_train + num_val + num_test\n",
    "    X = np.random.rand(num_rows, len_context)\n",
    "    cutoffs = np.expand_dims(np.random.rand(num_rows),1)\n",
    "    X_scenes = (X > cutoffs).astype(int)\n",
    "    X_scenes = list(set(tuple(x) for x in X_scenes.tolist()))\n",
    "    random.shuffle(X_scenes)\n",
    "    counts = np.sum(X_scenes, axis=-1)\n",
    "\n",
    "    train_X_scenes, train_counts = X_scenes[num_test+num_val:], counts[num_test+num_val:]\n",
    "    valid_X_scenes, valid_counts = X_scenes[num_test:num_test+num_val], counts[num_test:num_test+num_val]\n",
    "    test_X_scenes, test_counts = X_scenes[:num_test], counts[:num_test]\n",
    "\n",
    "    data = {\n",
    "        'train':{'X_scenes':train_X_scenes, 'counts':train_counts, 'count_to_scenes':map_count_to_scenes(train_counts)},\n",
    "        'valid':{'X_scenes':valid_X_scenes, 'counts':valid_counts, 'count_to_scenes':map_count_to_scenes(valid_counts)},\n",
    "        'test':{'X_scenes':test_X_scenes, 'counts':test_counts, 'count_to_scenes':map_count_to_scenes(test_counts)}\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = gen_counting_data(len_context=500, num_train=50000, num_val=1000, num_test=1000)\n",
    "\n",
    "print('count distribution:')\n",
    "print(f'train {len(data[\"train\"][\"counts\"])} scenes \\n:', collections.Counter(data['train']['counts']).most_common())\n",
    "print(f'valid {len(data[\"valid\"][\"counts\"])} scenes \\n:', collections.Counter(data['valid']['counts']).most_common())\n",
    "print(f'test {len(data[\"test\"][\"counts\"])} scenes \\n:', collections.Counter(data['test']['counts']).most_common())\n",
    "\n",
    "print('samples:')\n",
    "for i in range(5):\n",
    "    print(data['train']['X_scenes'][i], data['train']['counts'][i])\n",
    "    \n",
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 39406\n",
      "227 227\n",
      "---------------------------\n",
      "tensor([2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0])\n",
      "---------------------------\n",
      "tensor([2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "         0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "         1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "         0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "         1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "         0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "         1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]),\n",
       " tensor([2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "         0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "         0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "         1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "         1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "         0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "         1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "         0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "         0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "         0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "         0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CountingDataset(Dataset):\n",
    "    '''Scene and Query Dataset.'''\n",
    "\n",
    "    def __init__(self, data, split, debug=False):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        # doesn't inlcude any <<go>>, <<stop>> or <<pad>>\n",
    "        self.X_scenes = data[split]['X_scenes']\n",
    "        self.counts = data[split]['counts']\n",
    "        self.count_to_scenes = data[split]['count_to_scenes']\n",
    "        self.cls_idx = 2\n",
    "        self.all_scenes = set(range(len(self.X_scenes))) \n",
    "        self.debug = debug\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_scenes)\n",
    "       \n",
    "    def sample_positive_key(self, idx):\n",
    "        '''\n",
    "        Returns:\n",
    "            positive_key_scene: 1 query scene (randomly drawn)\n",
    "            matching_scenes: pool of all positive key scenes.\n",
    "        '''\n",
    "        query_count = self.counts[idx]\n",
    "        matching_scenes = self.count_to_scenes[query_count]\n",
    "        positive_key_scene = idx\n",
    "        while positive_key_scene == idx:\n",
    "            positive_key_scene = random.sample(matching_scenes, 1)        \n",
    "        return positive_key_scene[0], matching_scenes\n",
    "    \n",
    "    def __getitem__(self, key_idx):\n",
    "        \n",
    "        # get the query and matching scene\n",
    "        positive_key_scene_idx, _ = self.sample_positive_key(key_idx)\n",
    "        \n",
    "        # shape (len context, )\n",
    "        x_query_scene = torch.tensor([self.cls_idx] + list(self.X_scenes[key_idx])).long()\n",
    "        # shape (len context, )\n",
    "        x_key_scene_pos = torch.tensor([self.cls_idx] + list(self.X_scenes[positive_key_scene_idx])).long()\n",
    "        \n",
    "#         # shape (len context, )\n",
    "#         x_query_scene = torch.tensor(list(self.X_scenes[key_idx])).long()\n",
    "#         # shape (len context, )\n",
    "#         x_key_scene_pos = torch.tensor(list(self.X_scenes[positive_key_scene_idx])).long()\n",
    "        \n",
    "        if self.debug:\n",
    "            print(key_idx, positive_key_scene_idx)\n",
    "            print(self.counts[key_idx],self.counts[positive_key_scene_idx])\n",
    "            print('---------------------------')\n",
    "            print(x_query_scene)\n",
    "            print('---------------------------')\n",
    "            print(x_key_scene_pos)\n",
    "        \n",
    "        #####################################################################################\n",
    "        \n",
    "        return x_query_scene, x_key_scene_pos\n",
    "    \n",
    "train_set = CountingDataset(data, 'train', debug=True)\n",
    "train_set[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountingDataModule(pl.LightningDataModule):\n",
    "    # https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "    \n",
    "    def __init__(self, batch_size, data):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train = CountingDataset(\n",
    "                self.data, 'train'\n",
    "            )\n",
    "            self.val = CountingDataset(\n",
    "                self.data, 'valid'\n",
    "            )\n",
    "#             self.val = self.train\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test = CountingDataset(\n",
    "                self.data, 'test'\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(\n",
    "            self.val, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        return val_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(\n",
    "            self.test, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Name                                                              | Type                   | Params\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EncoderPredictor       | 441 K \n",
      "1   | model.encoder_query                                               | Encoder                | 212 K \n",
      "2   | model.encoder_query.encoder_layers                                | ModuleList             | 212 K \n",
      "3   | model.encoder_query.encoder_layers.0                              | EncoderLayer           | 70.9 K\n",
      "4   | model.encoder_query.encoder_layers.0.poswise_ff                   | Positiontwise_FF       | 66.6 K\n",
      "5   | model.encoder_query.encoder_layers.0.poswise_ff.linear1           | Linear                 | 33.8 K\n",
      "6   | model.encoder_query.encoder_layers.0.poswise_ff.linear2           | Linear                 | 32.8 K\n",
      "7   | model.encoder_query.encoder_layers.0.self_attn                    | MultiHeadAttention     | 4.2 K \n",
      "8   | model.encoder_query.encoder_layers.0.self_attn.projections_QKVO   | ModuleList             | 4.2 K \n",
      "9   | model.encoder_query.encoder_layers.0.self_attn.projections_QKVO.0 | Linear                 | 1.1 K \n",
      "10  | model.encoder_query.encoder_layers.0.self_attn.projections_QKVO.1 | Linear                 | 1.1 K \n",
      "11  | model.encoder_query.encoder_layers.0.self_attn.projections_QKVO.2 | Linear                 | 1.1 K \n",
      "12  | model.encoder_query.encoder_layers.0.self_attn.projections_QKVO.3 | Linear                 | 1.1 K \n",
      "13  | model.encoder_query.encoder_layers.0.self_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "14  | model.encoder_query.encoder_layers.0.layer_norms                  | ModuleList             | 128   \n",
      "15  | model.encoder_query.encoder_layers.0.layer_norms.0                | LayerNorm              | 64    \n",
      "16  | model.encoder_query.encoder_layers.0.layer_norms.1                | LayerNorm              | 64    \n",
      "17  | model.encoder_query.encoder_layers.0.heads_dropout                | Dropout                | 0     \n",
      "18  | model.encoder_query.encoder_layers.0.pff_dropout                  | Dropout                | 0     \n",
      "19  | model.encoder_query.encoder_layers.1                              | EncoderLayer           | 70.9 K\n",
      "20  | model.encoder_query.encoder_layers.1.poswise_ff                   | Positiontwise_FF       | 66.6 K\n",
      "21  | model.encoder_query.encoder_layers.1.poswise_ff.linear1           | Linear                 | 33.8 K\n",
      "22  | model.encoder_query.encoder_layers.1.poswise_ff.linear2           | Linear                 | 32.8 K\n",
      "23  | model.encoder_query.encoder_layers.1.self_attn                    | MultiHeadAttention     | 4.2 K \n",
      "24  | model.encoder_query.encoder_layers.1.self_attn.projections_QKVO   | ModuleList             | 4.2 K \n",
      "25  | model.encoder_query.encoder_layers.1.self_attn.projections_QKVO.0 | Linear                 | 1.1 K \n",
      "26  | model.encoder_query.encoder_layers.1.self_attn.projections_QKVO.1 | Linear                 | 1.1 K \n",
      "27  | model.encoder_query.encoder_layers.1.self_attn.projections_QKVO.2 | Linear                 | 1.1 K \n",
      "28  | model.encoder_query.encoder_layers.1.self_attn.projections_QKVO.3 | Linear                 | 1.1 K \n",
      "29  | model.encoder_query.encoder_layers.1.self_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "30  | model.encoder_query.encoder_layers.1.layer_norms                  | ModuleList             | 128   \n",
      "31  | model.encoder_query.encoder_layers.1.layer_norms.0                | LayerNorm              | 64    \n",
      "32  | model.encoder_query.encoder_layers.1.layer_norms.1                | LayerNorm              | 64    \n",
      "33  | model.encoder_query.encoder_layers.1.heads_dropout                | Dropout                | 0     \n",
      "34  | model.encoder_query.encoder_layers.1.pff_dropout                  | Dropout                | 0     \n",
      "35  | model.encoder_query.encoder_layers.2                              | EncoderLayer           | 70.9 K\n",
      "36  | model.encoder_query.encoder_layers.2.poswise_ff                   | Positiontwise_FF       | 66.6 K\n",
      "37  | model.encoder_query.encoder_layers.2.poswise_ff.linear1           | Linear                 | 33.8 K\n",
      "38  | model.encoder_query.encoder_layers.2.poswise_ff.linear2           | Linear                 | 32.8 K\n",
      "39  | model.encoder_query.encoder_layers.2.self_attn                    | MultiHeadAttention     | 4.2 K \n",
      "40  | model.encoder_query.encoder_layers.2.self_attn.projections_QKVO   | ModuleList             | 4.2 K \n",
      "41  | model.encoder_query.encoder_layers.2.self_attn.projections_QKVO.0 | Linear                 | 1.1 K \n",
      "42  | model.encoder_query.encoder_layers.2.self_attn.projections_QKVO.1 | Linear                 | 1.1 K \n",
      "43  | model.encoder_query.encoder_layers.2.self_attn.projections_QKVO.2 | Linear                 | 1.1 K \n",
      "44  | model.encoder_query.encoder_layers.2.self_attn.projections_QKVO.3 | Linear                 | 1.1 K \n",
      "45  | model.encoder_query.encoder_layers.2.self_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "46  | model.encoder_query.encoder_layers.2.layer_norms                  | ModuleList             | 128   \n",
      "47  | model.encoder_query.encoder_layers.2.layer_norms.0                | LayerNorm              | 64    \n",
      "48  | model.encoder_query.encoder_layers.2.layer_norms.1                | LayerNorm              | 64    \n",
      "49  | model.encoder_query.encoder_layers.2.heads_dropout                | Dropout                | 0     \n",
      "50  | model.encoder_query.encoder_layers.2.pff_dropout                  | Dropout                | 0     \n",
      "51  | model.encoder_key                                                 | Encoder                | 212 K \n",
      "52  | model.encoder_key.encoder_layers                                  | ModuleList             | 212 K \n",
      "53  | model.encoder_key.encoder_layers.0                                | EncoderLayer           | 70.9 K\n",
      "54  | model.encoder_key.encoder_layers.0.poswise_ff                     | Positiontwise_FF       | 66.6 K\n",
      "55  | model.encoder_key.encoder_layers.0.poswise_ff.linear1             | Linear                 | 33.8 K\n",
      "56  | model.encoder_key.encoder_layers.0.poswise_ff.linear2             | Linear                 | 32.8 K\n",
      "57  | model.encoder_key.encoder_layers.0.self_attn                      | MultiHeadAttention     | 4.2 K \n",
      "58  | model.encoder_key.encoder_layers.0.self_attn.projections_QKVO     | ModuleList             | 4.2 K \n",
      "59  | model.encoder_key.encoder_layers.0.self_attn.projections_QKVO.0   | Linear                 | 1.1 K \n",
      "60  | model.encoder_key.encoder_layers.0.self_attn.projections_QKVO.1   | Linear                 | 1.1 K \n",
      "61  | model.encoder_key.encoder_layers.0.self_attn.projections_QKVO.2   | Linear                 | 1.1 K \n",
      "62  | model.encoder_key.encoder_layers.0.self_attn.projections_QKVO.3   | Linear                 | 1.1 K \n",
      "63  | model.encoder_key.encoder_layers.0.self_attn.attn_wt_dropout      | Dropout                | 0     \n",
      "64  | model.encoder_key.encoder_layers.0.layer_norms                    | ModuleList             | 128   \n",
      "65  | model.encoder_key.encoder_layers.0.layer_norms.0                  | LayerNorm              | 64    \n",
      "66  | model.encoder_key.encoder_layers.0.layer_norms.1                  | LayerNorm              | 64    \n",
      "67  | model.encoder_key.encoder_layers.0.heads_dropout                  | Dropout                | 0     \n",
      "68  | model.encoder_key.encoder_layers.0.pff_dropout                    | Dropout                | 0     \n",
      "69  | model.encoder_key.encoder_layers.1                                | EncoderLayer           | 70.9 K\n",
      "70  | model.encoder_key.encoder_layers.1.poswise_ff                     | Positiontwise_FF       | 66.6 K\n",
      "71  | model.encoder_key.encoder_layers.1.poswise_ff.linear1             | Linear                 | 33.8 K\n",
      "72  | model.encoder_key.encoder_layers.1.poswise_ff.linear2             | Linear                 | 32.8 K\n",
      "73  | model.encoder_key.encoder_layers.1.self_attn                      | MultiHeadAttention     | 4.2 K \n",
      "74  | model.encoder_key.encoder_layers.1.self_attn.projections_QKVO     | ModuleList             | 4.2 K \n",
      "75  | model.encoder_key.encoder_layers.1.self_attn.projections_QKVO.0   | Linear                 | 1.1 K \n",
      "76  | model.encoder_key.encoder_layers.1.self_attn.projections_QKVO.1   | Linear                 | 1.1 K \n",
      "77  | model.encoder_key.encoder_layers.1.self_attn.projections_QKVO.2   | Linear                 | 1.1 K \n",
      "78  | model.encoder_key.encoder_layers.1.self_attn.projections_QKVO.3   | Linear                 | 1.1 K \n",
      "79  | model.encoder_key.encoder_layers.1.self_attn.attn_wt_dropout      | Dropout                | 0     \n",
      "80  | model.encoder_key.encoder_layers.1.layer_norms                    | ModuleList             | 128   \n",
      "81  | model.encoder_key.encoder_layers.1.layer_norms.0                  | LayerNorm              | 64    \n",
      "82  | model.encoder_key.encoder_layers.1.layer_norms.1                  | LayerNorm              | 64    \n",
      "83  | model.encoder_key.encoder_layers.1.heads_dropout                  | Dropout                | 0     \n",
      "84  | model.encoder_key.encoder_layers.1.pff_dropout                    | Dropout                | 0     \n",
      "85  | model.encoder_key.encoder_layers.2                                | EncoderLayer           | 70.9 K\n",
      "86  | model.encoder_key.encoder_layers.2.poswise_ff                     | Positiontwise_FF       | 66.6 K\n",
      "87  | model.encoder_key.encoder_layers.2.poswise_ff.linear1             | Linear                 | 33.8 K\n",
      "88  | model.encoder_key.encoder_layers.2.poswise_ff.linear2             | Linear                 | 32.8 K\n",
      "89  | model.encoder_key.encoder_layers.2.self_attn                      | MultiHeadAttention     | 4.2 K \n",
      "90  | model.encoder_key.encoder_layers.2.self_attn.projections_QKVO     | ModuleList             | 4.2 K \n",
      "91  | model.encoder_key.encoder_layers.2.self_attn.projections_QKVO.0   | Linear                 | 1.1 K \n",
      "92  | model.encoder_key.encoder_layers.2.self_attn.projections_QKVO.1   | Linear                 | 1.1 K \n",
      "93  | model.encoder_key.encoder_layers.2.self_attn.projections_QKVO.2   | Linear                 | 1.1 K \n",
      "94  | model.encoder_key.encoder_layers.2.self_attn.projections_QKVO.3   | Linear                 | 1.1 K \n",
      "95  | model.encoder_key.encoder_layers.2.self_attn.attn_wt_dropout      | Dropout                | 0     \n",
      "96  | model.encoder_key.encoder_layers.2.layer_norms                    | ModuleList             | 128   \n",
      "97  | model.encoder_key.encoder_layers.2.layer_norms.0                  | LayerNorm              | 64    \n",
      "98  | model.encoder_key.encoder_layers.2.layer_norms.1                  | LayerNorm              | 64    \n",
      "99  | model.encoder_key.encoder_layers.2.heads_dropout                  | Dropout                | 0     \n",
      "100 | model.encoder_key.encoder_layers.2.pff_dropout                    | Dropout                | 0     \n",
      "101 | model.inp_query_layer                                             | Sequential             | 16.1 K\n",
      "102 | model.inp_query_layer.scaled_embed                                | ScaledEmbedding        | 96    \n",
      "103 | model.inp_query_layer.scaled_embed.embedding                      | Embedding              | 96    \n",
      "104 | model.inp_query_layer.position_encoder                            | LearnedPositionEncoder | 16.0 K\n",
      "105 | model.inp_query_layer.embed_dropout                               | Dropout                | 0     \n",
      "106 | model.inp_key_layer                                               | Sequential             | 16.1 K\n",
      "107 | loss_criterion                                                    | InfoCELoss             | 0     \n",
      "108 | loss_criterion.CE_loss                                            | CrossEntropyLoss       | 0     \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "441 K     Trainable params\n",
      "0         Non-trainable params\n",
      "441 K     Total params \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-99138a24815c>:62: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">context500-batch128</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chucooleg/ContrastiveLearning-CountOnes-InfoNCELoss\" target=\"_blank\">https://wandb.ai/chucooleg/ContrastiveLearning-CountOnes-InfoNCELoss</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chucooleg/ContrastiveLearning-CountOnes-InfoNCELoss/runs/35drw8y0\" target=\"_blank\">https://wandb.ai/chucooleg/ContrastiveLearning-CountOnes-InfoNCELoss/runs/35drw8y0</a><br/>\n",
       "                Run data is saved locally in <code>/app/Contrastive-Learning-Benchmarking/models/wandb/run-20210108_022950-35drw8y0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | model          | EncoderPredictor | 441 K \n",
      "1 | loss_criterion | InfoCELoss       | 0     \n",
      "----------------------------------------------------\n",
      "441 K     Trainable params\n",
      "0         Non-trainable params\n",
      "441 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation sanity check: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/397 [00:00<?, ?it/s]                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/torch/cuda/memory.py:231: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  98%|| 389/397 [02:24<00:02,  2.69it/s, loss=525, v_num=w8y0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  99%|| 393/397 [02:24<00:01,  2.72it/s, loss=525, v_num=w8y0]\n",
      "Epoch 0: 100%|| 397/397 [02:24<00:00,  2.74it/s, loss=525, v_num=w8y0]\n",
      "Epoch 1:  98%|| 389/397 [02:24<00:02,  2.70it/s, loss=239, v_num=w8y0]\n",
      "Epoch 1:  99%|| 392/397 [02:24<00:01,  2.72it/s, loss=239, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 23.37it/s]\u001b[A\n",
      "Epoch 1: 100%|| 397/397 [02:24<00:00,  2.75it/s, loss=239, v_num=w8y0]\n",
      "Epoch 2:  98%|| 389/397 [02:24<00:02,  2.69it/s, loss=190, v_num=w8y0]\n",
      "Epoch 2:  99%|| 392/397 [02:24<00:01,  2.71it/s, loss=190, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.62it/s]\u001b[A\n",
      "Epoch 2: 100%|| 397/397 [02:24<00:00,  2.74it/s, loss=190, v_num=w8y0]\n",
      "Epoch 3:  98%|| 389/397 [02:23<00:02,  2.71it/s, loss=162, v_num=w8y0]\n",
      "Epoch 3:  99%|| 392/397 [02:23<00:01,  2.73it/s, loss=162, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 23.54it/s]\u001b[A\n",
      "Epoch 3: 100%|| 397/397 [02:23<00:00,  2.76it/s, loss=162, v_num=w8y0]\n",
      "Epoch 4:  98%|| 389/397 [02:23<00:02,  2.71it/s, loss=188, v_num=w8y0]\n",
      "Epoch 4:  99%|| 392/397 [02:23<00:01,  2.73it/s, loss=188, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 23.68it/s]\u001b[A\n",
      "Epoch 4: 100%|| 397/397 [02:23<00:00,  2.76it/s, loss=188, v_num=w8y0]\n",
      "Epoch 5:  98%|| 389/397 [02:23<00:02,  2.72it/s, loss=157, v_num=w8y0]\n",
      "Epoch 5:  99%|| 392/397 [02:23<00:01,  2.74it/s, loss=157, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.69it/s]\u001b[A\n",
      "Epoch 5: 100%|| 397/397 [02:23<00:00,  2.77it/s, loss=157, v_num=w8y0]\n",
      "Epoch 6:  98%|| 389/397 [02:22<00:02,  2.72it/s, loss=139, v_num=w8y0]\n",
      "Epoch 6:  99%|| 392/397 [02:23<00:01,  2.74it/s, loss=139, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.90it/s]\u001b[A\n",
      "Epoch 6: 100%|| 397/397 [02:23<00:00,  2.77it/s, loss=139, v_num=w8y0]\n",
      "Epoch 7:  98%|| 389/397 [02:23<00:02,  2.71it/s, loss=127, v_num=w8y0]\n",
      "Epoch 7:  99%|| 392/397 [02:23<00:01,  2.73it/s, loss=127, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.69it/s]\u001b[A\n",
      "Epoch 7: 100%|| 397/397 [02:23<00:00,  2.76it/s, loss=127, v_num=w8y0]\n",
      "Epoch 8:  98%|| 389/397 [02:24<00:02,  2.69it/s, loss=130, v_num=w8y0]\n",
      "Epoch 8:  99%|| 392/397 [02:24<00:01,  2.71it/s, loss=130, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.34it/s]\u001b[A\n",
      "Epoch 8: 100%|| 397/397 [02:24<00:00,  2.74it/s, loss=130, v_num=w8y0]\n",
      "Epoch 9:  98%|| 389/397 [02:23<00:02,  2.70it/s, loss=108, v_num=w8y0]\n",
      "Epoch 9:  99%|| 392/397 [02:24<00:01,  2.72it/s, loss=108, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.70it/s]\u001b[A\n",
      "Epoch 9: 100%|| 397/397 [02:24<00:00,  2.75it/s, loss=108, v_num=w8y0]\n",
      "Epoch 10:  98%|| 389/397 [02:24<00:02,  2.69it/s, loss=130, v_num=w8y0]\n",
      "Epoch 10:  99%|| 392/397 [02:24<00:01,  2.71it/s, loss=130, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.47it/s]\u001b[A\n",
      "Epoch 10: 100%|| 397/397 [02:24<00:00,  2.74it/s, loss=130, v_num=w8y0]\n",
      "Epoch 11:  98%|| 389/397 [02:23<00:02,  2.71it/s, loss=128, v_num=w8y0]\n",
      "Epoch 11:  99%|| 392/397 [02:23<00:01,  2.72it/s, loss=128, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.68it/s]\u001b[A\n",
      "Epoch 11: 100%|| 397/397 [02:24<00:00,  2.75it/s, loss=128, v_num=w8y0]\n",
      "Epoch 12:  98%|| 389/397 [02:23<00:02,  2.71it/s, loss=142, v_num=w8y0] \n",
      "Epoch 12:  99%|| 392/397 [02:23<00:01,  2.73it/s, loss=142, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 23.47it/s]\u001b[A\n",
      "Epoch 12: 100%|| 397/397 [02:23<00:00,  2.76it/s, loss=142, v_num=w8y0]\n",
      "Epoch 13:  98%|| 389/397 [02:23<00:02,  2.70it/s, loss=106, v_num=w8y0] \n",
      "Epoch 13:  99%|| 392/397 [02:23<00:01,  2.72it/s, loss=106, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.73it/s]\u001b[A\n",
      "Epoch 13: 100%|| 397/397 [02:24<00:00,  2.75it/s, loss=106, v_num=w8y0]\n",
      "Epoch 14:  98%|| 389/397 [02:23<00:02,  2.70it/s, loss=94.4, v_num=w8y0]\n",
      "Epoch 14:  99%|| 392/397 [02:23<00:01,  2.72it/s, loss=94.4, v_num=w8y0]\n",
      "Validating:  38%|      | 3/8 [00:00<00:00, 24.76it/s]\u001b[A\n",
      "Epoch 14: 100%|| 397/397 [02:24<00:00,  2.75it/s, loss=94.4, v_num=w8y0]\n",
      "Epoch 15:  15%|        | 59/397 [00:21<02:05,  2.69it/s, loss=135, v_num=w8y0]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## W&B References\n",
    "# https://docs.wandb.com/library/integrations/lightning\n",
    "# colab example\n",
    "# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch-lightning/Supercharge_your_Training_with_Pytorch_Lightning_%2B_Weights_%26_Biases.ipynb\n",
    "# step by step guide\n",
    "# https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    'd_model': 32,\n",
    "    'd_ff': 1024,\n",
    "    'max_len': 501, #!\n",
    "#     'grid_dim': 3, #!\n",
    "    'num_heads': 1,\n",
    "    'embed_dropout': 0.0,\n",
    "    'attn_wt_dropout': 0.0,\n",
    "    'heads_dropout': 0.0,\n",
    "    'pff_dropout': 0.0,\n",
    "    'N_enc': 3,\n",
    "#     'N_dec': 2,\n",
    "#     'start_idx_scene': fkdat_human_vocab['<go>'], #!\n",
    "    'padding_idx_query': 3,#! \n",
    "#     'stop_idx_scene': fkdat_human_vocab['<stop>'],   #!\n",
    "#     'start_idx_query': fkdat_machine_vocab['<go>'], #!\n",
    "    'padding_idx_key': 3,#! \n",
    "#     'stop_idx_query': fkdat_machine_vocab['<stop>'],   #!\n",
    "#     'smoothing_const': 0.1,\n",
    "    'loss_temperature_const': 1.0,\n",
    "    'lr_decay_step_size': 5,\n",
    "    'lr_decay_gamma': 0.1,\n",
    "    'temperature_const': 1.0,\n",
    "    'adam_beta1': 0.9,\n",
    "    'adam_beta2': 0.98,\n",
    "    'adam_epsilon': 1e-9,\n",
    "    'warmup_steps': 24000,\n",
    "    'vocab_size': 3,#!\n",
    "    'representation_pos': 0 #\n",
    "#     'vocab_size_query': len(fkdat_machine_vocab), #!\n",
    "}\n",
    "\n",
    "# model\n",
    "my_transformer = Transformer(hparams)\n",
    "print(pl.core.memory.ModelSummary(my_transformer, mode='full'),'\\n')\n",
    "\n",
    "# data \n",
    "countOnes_data = CountingDataModule(\n",
    "    batch_size=128, \n",
    "    data=data\n",
    ")\n",
    "\n",
    "# logger\n",
    "wd_logger = WandbLogger(name=\"context500-batch128\",project='ContrastiveLearning-CountOnes-InfoNCELoss')\n",
    "# wd_logger = WandbLogger(name=\"test-dummy-7\",project='ContrastiveLearning-CountOnes')\n",
    "\n",
    "# trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=[1], min_epochs=2, max_epochs=10000, \n",
    "    logger=wd_logger,log_gpu_memory='all',\n",
    "    precision=32, gradient_clip_val=0.5)\n",
    "\n",
    "# fit!\n",
    "with torch.autograd.detect_anomaly():\n",
    "    trainer.fit(my_transformer, countOnes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
