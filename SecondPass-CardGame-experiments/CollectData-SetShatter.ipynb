{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "physical-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from dataraw_sampling_SETShatter import (sample_queries, \n",
    "                                         sample_one_training_datapoint, \n",
    "                                         construct_cardpair_answer_lookup, \n",
    "                                         sample_queries_simple_shatter, resolve_eval_expression, \n",
    "                                         decode_key_to_vocab_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-arnold",
   "metadata": {},
   "source": [
    "## SET Shatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Shatter\n",
    "\n",
    "num_attributes=2; num_attr_vals=3; query_length_multiplier=1; nest_depth_int=1; multiple_OR_sets_bool=True\n",
    "N_train=0; N_val=5120; N_test=5120\n",
    "\n",
    "expression_resolve_fn = resolve_eval_expression\n",
    "\n",
    "sample_start_time = time.time()\n",
    "data, stats = sample_queries(\n",
    "    num_attributes, query_length_multiplier, nest_depth_int, multiple_OR_sets_bool, \n",
    "    expression_resolve_fn,\n",
    "    N_train, N_val, N_test,\n",
    "    validate=True,\n",
    "    debug=False)\n",
    "sample_end_time = time.time()\n",
    "\n",
    "print(f'Sample Time for {N_train+N_val+N_test} datapoints = {sample_end_time-sample_start_time} seconds')\n",
    "\n",
    "\n",
    "save_start_time = time.time()\n",
    "filename1 = '../Raw_Datasets/SET/SimpleShatter-{}Attr-{}Vals-{}LenMultiplier-{}NestDepth-{}Train-{}Val-{}Test.json'.format(\n",
    "    num_attributes, num_attr_vals, query_length_multiplier, nest_depth_int, N_train, N_val, N_test)\n",
    "with open(filename1, 'w') as f:\n",
    "    json.dump(data, f)\n",
    "save_end_time = time.time()\n",
    "\n",
    "filename = '../Raw_Datasets/SET/SimpleShatter-{}Attr-{}Vals-{}LenMultiplier-{}NestDepth-{}Train-{}Val-{}Test-Stats.json'.format(\n",
    "    num_attributes, num_attr_vals, query_length_multiplier, nest_depth_int, N_train, N_val, N_test)\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(stats, f)\n",
    "save_end_time = time.time()\n",
    "\n",
    "print(f'Saving Time for {N_train+N_val+N_test} datapoints = {save_end_time-save_start_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-poland",
   "metadata": {},
   "source": [
    "## SET Shatter - one datapoint only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "approved-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gt_keys_idx [3, 7]\n",
      "\n",
      "gt key properties [array([1, 0]), array([2, 1])]\n",
      "\n",
      "flat_card_indices [1, 3, 8, 'DERIVE', 8, 1, 0, 4]\n",
      "\n",
      "query_eval_expression ['AND', 1, 3, 8, 'DERIVE', 8, 1, 0, 4]\n",
      "\n",
      "query_input_expression ['(', 1, '&', 3, '&', 8, '&', 'DERIVE', '&', 8, '&', 1, '&', 0, '&', 4, ')']\n",
      "lhs_expression ['AND', 1, 3, 8, 'DERIVE', 8, 1, 0, 4]\n",
      "right_of_derive: [8, 1, 0, 4]\n",
      "rhs after solving right_of_derive: ['OR', 0, 4]\n",
      "left_of_derive: ['AND', 1, 3, 8]\n",
      "left_evaluated: 8\n",
      "rhs after solving rhs with left_of_derive: ['OR', 4, 0]\n",
      "\n",
      "query_eval_expression ['AND', 1, 3, 8, 'DERIVE', 8, 1, 0, 4]\n",
      "\n",
      "query_input_expression ['(', 1, '&', 3, '&', 8, '&', 'DERIVE', '&', 8, '&', 1, '&', 0, '&', 4, ')']\n",
      "\n",
      "DERIVE ['OR', 4, 0]\n",
      "\n",
      "substituted query_input_expression (1&3&8&(4|0)&8&1&0&4)\n",
      "\n",
      "eval_expression_properties ['AND', array([0, 1]), array([1, 0]), array([2, 2]), ['OR', array([1, 1]), array([0, 0])], array([2, 2]), array([0, 1]), array([0, 0]), array([1, 1])]\n",
      "\n",
      "query_for_input_vocab_tokens [9, 1, 17, 3, 17, 8, 17, 9, 4, 18, 0, 10, 17, 8, 17, 1, 17, 0, 17, 4, 10]\n"
     ]
    }
   ],
   "source": [
    "num_attributes=2; num_attr_vals=3; query_length_multiplier=1; nest_depth_int=1; multiple_OR_sets_bool=True\n",
    "N_train=0; N_val=5120; N_test=5120\n",
    "\n",
    "cardpair_answer_lookup = construct_cardpair_answer_lookup(num_attributes, num_attr_vals)\n",
    "base_vocab_size =  num_attr_vals ** num_attributes\n",
    "symbol_vocab_token_lookup = {\n",
    "    '(': base_vocab_size,\n",
    "    ')': base_vocab_size + 1,\n",
    "    'NULL': base_vocab_size + 2,\n",
    "    'SEP': base_vocab_size + 3,\n",
    "    'SOS': base_vocab_size + 4,\n",
    "    'EOS': base_vocab_size + 5,\n",
    "    'PAD': base_vocab_size + 6,\n",
    "    'PLH': base_vocab_size + 7,\n",
    "    '&': base_vocab_size + 8,\n",
    "    '|': base_vocab_size + 9,\n",
    "}\n",
    "\n",
    "\n",
    "q_tokens, k_idx = sample_one_training_datapoint(\n",
    "    2, \n",
    "    num_attributes, \n",
    "    num_attr_vals, \n",
    "    query_length_multiplier, \n",
    "    nest_depth_int, \n",
    "    multiple_OR_sets_bool,\n",
    "    cardpair_answer_lookup, \n",
    "    symbol_vocab_token_lookup,\n",
    "    validate=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-hayes",
   "metadata": {},
   "source": [
    "## Simple Shatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comic-venture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10240/10240 [00:00<00:00, 11404.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Time for 10240 datapoints = 0.9034569263458252 seconds\n",
      "Saving Time for 10240 datapoints = 0.20998454093933105 seconds\n"
     ]
    }
   ],
   "source": [
    "# Simple Shatter\n",
    "\n",
    "num_attributes=3; num_attr_vals=3; query_length_multiplier=1; nest_depth_int=1; multiple_OR_sets_bool=True\n",
    "N_train=0; N_val=5120; N_test=5120\n",
    "\n",
    "expression_resolve_fn = resolve_eval_expression\n",
    "\n",
    "sample_start_time = time.time()\n",
    "data, stats = sample_queries_simple_shatter(\n",
    "    num_attributes, query_length_multiplier, nest_depth_int, multiple_OR_sets_bool, \n",
    "    expression_resolve_fn,\n",
    "    N_train, N_val, N_test,\n",
    "    validate=True,\n",
    "    debug=False)\n",
    "sample_end_time = time.time()\n",
    "\n",
    "print(f'Sample Time for {N_train+N_val+N_test} datapoints = {sample_end_time-sample_start_time} seconds')\n",
    "\n",
    "\n",
    "save_start_time = time.time()\n",
    "filename1 = '../Raw_Datasets/SET/SimpleShatter-{}Attr-{}Vals-{}LenMultiplier-{}NestDepth-{}Train-{}Val-{}Test.json'.format(\n",
    "    num_attributes, num_attr_vals, query_length_multiplier, nest_depth_int, N_train, N_val, N_test)\n",
    "with open(filename1, 'w') as f:\n",
    "    json.dump(data, f)\n",
    "save_end_time = time.time()\n",
    "\n",
    "filename = '../Raw_Datasets/SET/SimpleShatter-{}Attr-{}Vals-{}LenMultiplier-{}NestDepth-{}Train-{}Val-{}Test-Stats.json'.format(\n",
    "    num_attributes, num_attr_vals, query_length_multiplier, nest_depth_int, N_train, N_val, N_test)\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(stats, f)\n",
    "save_end_time = time.time()\n",
    "\n",
    "print(f'Saving Time for {N_train+N_val+N_test} datapoints = {save_end_time-save_start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "correct-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Raw_Datasets/SET/SimpleShatter-3Attr-3Vals-1LenMultiplier-1NestDepth-0Train-5120Val-5120Test.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-registration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
