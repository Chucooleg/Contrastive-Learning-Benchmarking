{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "general-tribe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.8.3 (default, May 19 2020, 18:47:26) \n",
      "[GCC 7.3.0]\n",
      "__pyTorch VERSION: 1.7.0\n",
      "__CUDA VERSION\n",
      "/usr/bin/sh: 1: nvcc: not found\n",
      "__CUDNN VERSION: 8003\n",
      "__Number CUDA Devices: 2\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  2\n",
      "Current cuda device  0\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/i-have-3-gpu-why-torch-cuda-device-count-only-return-1/7245/4\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solar-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import main\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.project_name = 'ContrastiveLearning-SET-Wildcard-Expand-Union-27'\n",
    "args.data_path = '../Raw_Datasets/SET/WildCardSETidxUnion-3Attr-3Vals-8Pairs-0Train-5120Val-5120Test.json'\n",
    "args.mode = 'test'\n",
    "args.resume_checkpoint_dir = 'checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210331-140055-Con;Vec512;L8H8Lk4Hk2;scheduledAdamW72000;17145.88Kparams_runId_337q537l'\n",
    "args.ckpt_name = 'last.ckpt'\n",
    "args.runID = '337q537l'\n",
    "args.gpu = 1\n",
    "args.approve_before_training = False\n",
    "args.aml = False\n",
    "args.dataset_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "particular-remedy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "key_support_size : 27\n",
      "N_pairs : 8\n",
      "union_only : True\n",
      "max_len_q : 16\n",
      "len_k : 1\n",
      "train_gt_idxs length : 0\n",
      "val_gt_idxs length : 5120\n",
      "test_gt_idxs length : 5120\n",
      "train_tokens length : 0\n",
      "val_tokens length : 5120\n",
      "test_tokens length : 5120\n",
      "test_marginal_gt_idxs length : 5120\n",
      "test_marginal_tokens length : 5120\n",
      "vocab_size : 74\n",
      "symbol_vocab_token_lookup : {'(': 64, ')': 65, 'NULL': 66, 'SEP': 67, 'SOS': 68, 'EOS': 69, 'PAD': 70, 'PLH': 71, '|': 72, '!': 73}\n",
      "vocab_by_property : False\n",
      "-----------------------\n",
      "----------hparams----------\n",
      "seed : 42\n",
      "batch_size : 1024\n",
      "max_epochs : 20000000000\n",
      "val_every_n_epoch : 200\n",
      "d_model : 512\n",
      "embed_dropout : 0.0\n",
      "vec_repr : 512\n",
      "model : contrastive\n",
      "d_ff : 1024\n",
      "N_enc : 8\n",
      "num_heads : 8\n",
      "N_enc_key : 4\n",
      "num_heads_key : 2\n",
      "attn_wt_tying_scheme : untie_QKVO\n",
      "attn_wt_dropout : 0.0\n",
      "heads_dropout : 0.0\n",
      "pff_dropout : 0.0\n",
      "representation_pos : 0\n",
      "dotproduct_bottleneck : True\n",
      "normalize_dotproduct : False\n",
      "contrastive_use_infoNCE : True\n",
      "loss_temperature_const : 1.0\n",
      "loss_smoothing_const : 0.1\n",
      "nonlinear_classifier_scale_down_factor : [1, 1, 1]\n",
      "contrastive_optimizer : scheduled_adam\n",
      "cosine_annealing_T_max : 30\n",
      "adam_lr : 1e-05\n",
      "adam_beta1 : 0.9\n",
      "adam_beta2 : 0.999\n",
      "adam_epsilon : 1e-08\n",
      "adam_weight_decay : 0\n",
      "sgd_lr : 0.001\n",
      "sgd_momentum : 0\n",
      "scheduled_adam_beta1 : 0.9\n",
      "scheduled_adam_beta2 : 0.98\n",
      "scheduled_adam_epsilon : 1e-06\n",
      "scheduled_adam_warmup_steps : 36000\n",
      "additional_lr_decay : True\n",
      "additional_lr_decay_gamma : 0.9\n",
      "decay_lr_starts : 36000\n",
      "decay_lr_stops : 80000\n",
      "decay_lr_interval : 2000\n",
      "generative_overall_lr_scale : 1.0\n",
      "contrastive_overall_lr_scale : 1.0\n",
      "gradient_clip_val : 0.0\n",
      "debug : False\n",
      "extra_monitors : False\n",
      "mode : test\n",
      "key_support_size : 27\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "union_only : True\n",
      "vocab_size : 74\n",
      "vocab_by_property : False\n",
      "( : 64\n",
      ") : 65\n",
      "NULL : 66\n",
      "SEP : 67\n",
      "SOS : 68\n",
      "EOS : 69\n",
      "PAD : 70\n",
      "PLH : 71\n",
      "| : 72\n",
      "! : 73\n",
      "max_len_q : 16\n",
      "N_pairs : 8\n",
      "len_k : 1\n",
      "resume_checkpoint_dir : checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210331-140055-Con;Vec512;L8H8Lk4Hk2;scheduledAdamW72000;17145.88Kparams_runId_337q537l\n",
      "---------------------------\n",
      "    | Name                                                              | Type                    | Params\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "0   | metrics                                                           | ThresholdedMetrics      | 0     \n",
      "1   | KLdiv_criterion                                                   | KLdivLoss               | 0     \n",
      "2   | KLdiv_criterion.KLdiv_criterion                                   | KLDivLoss               | 0     \n",
      "3   | KLdiv_criterion.KLdiv_criterion_full                              | KLDivLoss               | 0     \n",
      "4   | KLdiv_criterion.logprob                                           | LogSoftmax              | 0     \n",
      "5   | model                                                             | EncoderPredictor        | 17.1 M\n",
      "6   | model.inp_query_layer                                             | Sequential              | 47.1 K\n",
      "7   | model.inp_query_layer.scaled_embed                                | ScaledEmbedding         | 37.9 K\n",
      "8   | model.inp_query_layer.scaled_embed.embedding                      | Embedding               | 37.9 K\n",
      "9   | model.inp_query_layer.position_encoder                            | LearnedPositionEncoder  | 9.2 K \n",
      "10  | model.inp_query_layer.embed_dropout                               | Dropout                 | 0     \n",
      "11  | model.inp_key_layer                                               | Sequential              | 13.8 K\n",
      "12  | model.inp_key_layer.scaled_embed                                  | ScaledEmbedding         | 13.8 K\n",
      "13  | model.inp_key_layer.scaled_embed.embedding                        | Embedding               | 13.8 K\n",
      "14  | model.query_encoder                                               | Encoder                 | 16.8 M\n",
      "15  | model.query_encoder.encoder_layers                                | ModuleList              | 16.8 M\n",
      "16  | model.query_encoder.encoder_layers.0                              | EncoderLayer            | 2.1 M \n",
      "17  | model.query_encoder.encoder_layers.0.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "18  | model.query_encoder.encoder_layers.0.poswise_ff.linear1           | Linear                  | 525 K \n",
      "19  | model.query_encoder.encoder_layers.0.poswise_ff.linear2           | Linear                  | 524 K \n",
      "20  | model.query_encoder.encoder_layers.0.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "21  | model.query_encoder.encoder_layers.0.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "22  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "23  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "24  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "25  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "26  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "27  | model.query_encoder.encoder_layers.0.layer_norms                  | ModuleList              | 2.0 K \n",
      "28  | model.query_encoder.encoder_layers.0.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "29  | model.query_encoder.encoder_layers.0.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "30  | model.query_encoder.encoder_layers.0.heads_dropout                | Dropout                 | 0     \n",
      "31  | model.query_encoder.encoder_layers.0.pff_dropout                  | Dropout                 | 0     \n",
      "32  | model.query_encoder.encoder_layers.1                              | EncoderLayer            | 2.1 M \n",
      "33  | model.query_encoder.encoder_layers.1.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "34  | model.query_encoder.encoder_layers.1.poswise_ff.linear1           | Linear                  | 525 K \n",
      "35  | model.query_encoder.encoder_layers.1.poswise_ff.linear2           | Linear                  | 524 K \n",
      "36  | model.query_encoder.encoder_layers.1.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "37  | model.query_encoder.encoder_layers.1.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "38  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "39  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "40  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "41  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "42  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "43  | model.query_encoder.encoder_layers.1.layer_norms                  | ModuleList              | 2.0 K \n",
      "44  | model.query_encoder.encoder_layers.1.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "45  | model.query_encoder.encoder_layers.1.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "46  | model.query_encoder.encoder_layers.1.heads_dropout                | Dropout                 | 0     \n",
      "47  | model.query_encoder.encoder_layers.1.pff_dropout                  | Dropout                 | 0     \n",
      "48  | model.query_encoder.encoder_layers.2                              | EncoderLayer            | 2.1 M \n",
      "49  | model.query_encoder.encoder_layers.2.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "50  | model.query_encoder.encoder_layers.2.poswise_ff.linear1           | Linear                  | 525 K \n",
      "51  | model.query_encoder.encoder_layers.2.poswise_ff.linear2           | Linear                  | 524 K \n",
      "52  | model.query_encoder.encoder_layers.2.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "53  | model.query_encoder.encoder_layers.2.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "54  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "55  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "56  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "57  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "58  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "59  | model.query_encoder.encoder_layers.2.layer_norms                  | ModuleList              | 2.0 K \n",
      "60  | model.query_encoder.encoder_layers.2.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "61  | model.query_encoder.encoder_layers.2.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "62  | model.query_encoder.encoder_layers.2.heads_dropout                | Dropout                 | 0     \n",
      "63  | model.query_encoder.encoder_layers.2.pff_dropout                  | Dropout                 | 0     \n",
      "64  | model.query_encoder.encoder_layers.3                              | EncoderLayer            | 2.1 M \n",
      "65  | model.query_encoder.encoder_layers.3.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "66  | model.query_encoder.encoder_layers.3.poswise_ff.linear1           | Linear                  | 525 K \n",
      "67  | model.query_encoder.encoder_layers.3.poswise_ff.linear2           | Linear                  | 524 K \n",
      "68  | model.query_encoder.encoder_layers.3.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "69  | model.query_encoder.encoder_layers.3.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "70  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "71  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "72  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "73  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "74  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "75  | model.query_encoder.encoder_layers.3.layer_norms                  | ModuleList              | 2.0 K \n",
      "76  | model.query_encoder.encoder_layers.3.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "77  | model.query_encoder.encoder_layers.3.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "78  | model.query_encoder.encoder_layers.3.heads_dropout                | Dropout                 | 0     \n",
      "79  | model.query_encoder.encoder_layers.3.pff_dropout                  | Dropout                 | 0     \n",
      "80  | model.query_encoder.encoder_layers.4                              | EncoderLayer            | 2.1 M \n",
      "81  | model.query_encoder.encoder_layers.4.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "82  | model.query_encoder.encoder_layers.4.poswise_ff.linear1           | Linear                  | 525 K \n",
      "83  | model.query_encoder.encoder_layers.4.poswise_ff.linear2           | Linear                  | 524 K \n",
      "84  | model.query_encoder.encoder_layers.4.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "85  | model.query_encoder.encoder_layers.4.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "86  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "87  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "88  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "89  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "90  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "91  | model.query_encoder.encoder_layers.4.layer_norms                  | ModuleList              | 2.0 K \n",
      "92  | model.query_encoder.encoder_layers.4.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "93  | model.query_encoder.encoder_layers.4.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "94  | model.query_encoder.encoder_layers.4.heads_dropout                | Dropout                 | 0     \n",
      "95  | model.query_encoder.encoder_layers.4.pff_dropout                  | Dropout                 | 0     \n",
      "96  | model.query_encoder.encoder_layers.5                              | EncoderLayer            | 2.1 M \n",
      "97  | model.query_encoder.encoder_layers.5.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "98  | model.query_encoder.encoder_layers.5.poswise_ff.linear1           | Linear                  | 525 K \n",
      "99  | model.query_encoder.encoder_layers.5.poswise_ff.linear2           | Linear                  | 524 K \n",
      "100 | model.query_encoder.encoder_layers.5.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "101 | model.query_encoder.encoder_layers.5.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "102 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "103 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "104 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "105 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "106 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "107 | model.query_encoder.encoder_layers.5.layer_norms                  | ModuleList              | 2.0 K \n",
      "108 | model.query_encoder.encoder_layers.5.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "109 | model.query_encoder.encoder_layers.5.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "110 | model.query_encoder.encoder_layers.5.heads_dropout                | Dropout                 | 0     \n",
      "111 | model.query_encoder.encoder_layers.5.pff_dropout                  | Dropout                 | 0     \n",
      "112 | model.query_encoder.encoder_layers.6                              | EncoderLayer            | 2.1 M \n",
      "113 | model.query_encoder.encoder_layers.6.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "114 | model.query_encoder.encoder_layers.6.poswise_ff.linear1           | Linear                  | 525 K \n",
      "115 | model.query_encoder.encoder_layers.6.poswise_ff.linear2           | Linear                  | 524 K \n",
      "116 | model.query_encoder.encoder_layers.6.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "117 | model.query_encoder.encoder_layers.6.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "118 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "119 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "120 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "121 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "122 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "123 | model.query_encoder.encoder_layers.6.layer_norms                  | ModuleList              | 2.0 K \n",
      "124 | model.query_encoder.encoder_layers.6.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "125 | model.query_encoder.encoder_layers.6.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "126 | model.query_encoder.encoder_layers.6.heads_dropout                | Dropout                 | 0     \n",
      "127 | model.query_encoder.encoder_layers.6.pff_dropout                  | Dropout                 | 0     \n",
      "128 | model.query_encoder.encoder_layers.7                              | EncoderLayer            | 2.1 M \n",
      "129 | model.query_encoder.encoder_layers.7.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "130 | model.query_encoder.encoder_layers.7.poswise_ff.linear1           | Linear                  | 525 K \n",
      "131 | model.query_encoder.encoder_layers.7.poswise_ff.linear2           | Linear                  | 524 K \n",
      "132 | model.query_encoder.encoder_layers.7.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "133 | model.query_encoder.encoder_layers.7.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "134 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "135 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "136 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "137 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "138 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "139 | model.query_encoder.encoder_layers.7.layer_norms                  | ModuleList              | 2.0 K \n",
      "140 | model.query_encoder.encoder_layers.7.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "141 | model.query_encoder.encoder_layers.7.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "142 | model.query_encoder.encoder_layers.7.heads_dropout                | Dropout                 | 0     \n",
      "143 | model.query_encoder.encoder_layers.7.pff_dropout                  | Dropout                 | 0     \n",
      "144 | model.query_projection                                            | Linear                  | 262 K \n",
      "145 | CE_criterion                                                      | CELoss                  | 0     \n",
      "146 | CE_criterion.CE_loss                                              | CrossEntropyLoss        | 0     \n",
      "147 | loss_criterion                                                    | InfoCELoss              | 0     \n",
      "148 | loss_criterion.CE_loss                                            | CrossEntropyLoss        | 0     \n",
      "149 | debug_metrics                                                     | ContrastiveDebugMetrics | 0     \n",
      "150 | softmax                                                           | Softmax                 | 0     \n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "17.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.1 M    Total params\n",
      "68.584    Total estimated model params size (MB) \n",
      "\n",
      "RUN NAME :\n",
      " Con;Vec512;L8H8Lk4Hk2;scheduledAdamW36000;17145.88Kparams\n",
      "Resuming From and Saving to Checkpoint Path:\n",
      " checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210331-140055-Con;Vec512;L8H8Lk4Hk2;scheduledAdamW72000;17145.88Kparams_runId_337q537l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]{0.0048762718215584755, 0.9136935472488403, 1.0, 0.9134174585342407, 4.993302345275879, 0.9443569183349609, 0.8783836364746094, 0.9352416396141052, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 21.93222427368164, 23.215871810913086, 22.706003189086914, 22.828176498413086, 0.05873812362551689, 0.03703700006008148, 0.04541846364736557, 0.06240056827664375, 0.11087169498205185, 0.0499463714659214, 0.09071008116006851, 0.052568454295396805, 0.0831642597913742, 1024.0, 14.881451606750488, 17.997802734375, 18.997222900390625, 19.990631103515625, 19.149999618530273, 20.986791610717773, 0.0001197049641632475, 0.00015322536637540907, 0.00013526853581424803, 0.000156689653522335, 0.0001378392189508304, 0.066554956138134, 0.043448206037282944, 0.00014810333959758282, 0.04757428169250488, nan, 0.07677433639764786, 0.04164484888315201, 0.055481504648923874, 0.03998405858874321, 0.03845120966434479, 0.000144627207191661, 0.00017455944907851517, 0.0001992811739910394, 0.00014518741227220744, 0.07129927724599838, 0.09976568073034286, 0.12469198554754257, 0.0001728257047943771, 0.0001587684528203681, 0.00013682253484148532, 0.00013964234676677734, 0.00012969046656508, 0.00013924941595178097, 0.0001499326026532799, 0.00026859427453018725, 0.00013811785902362317}\n",
      "Also saved to : checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210331-140055-Con;Vec512;L8H8Lk4Hk2;scheduledAdamW72000;17145.88Kparams_runId_337q537l/test_metrics.json\n",
      "Testing: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_batch_size': 1024.0,\n",
      " 'avg_test_KL_loss': 4.993302345275879,\n",
      " 'avg_test_KL_loss_per_example': 0.0048762718215584755,\n",
      " 'avg_test_accuracy_by_Query': 0.9136935472488403,\n",
      " 'avg_test_accuracy_by_QueryKey': 0.9136935472488403,\n",
      " 'avg_test_f1_by_Query': 0.9443569183349609,\n",
      " 'avg_test_f1_by_QueryKey': 0.9352416396141052,\n",
      " 'avg_test_gt10;gt_logits_above_threshold_count': 10.0,\n",
      " 'avg_test_gt10;gt_pred_scores': 0.09976568073034286,\n",
      " 'avg_test_gt10;not_gt_pred_scores': 0.0001378392189508304,\n",
      " 'avg_test_gt10;top10_overlap_count': 10.0,\n",
      " 'avg_test_gt10;top10_pred_above_threshold_count': 10.0,\n",
      " 'avg_test_gt10;total_pred_above_threshold_count': 10.0,\n",
      " 'avg_test_gt11;gt_logits_above_threshold_count': 11.0,\n",
      " 'avg_test_gt11;gt_pred_scores': 0.09071008116006851,\n",
      " 'avg_test_gt11;not_gt_pred_scores': 0.00013682253484148532,\n",
      " 'avg_test_gt11;top11_overlap_count': 11.0,\n",
      " 'avg_test_gt11;top11_pred_above_threshold_count': 11.0,\n",
      " 'avg_test_gt11;total_pred_above_threshold_count': 11.0,\n",
      " 'avg_test_gt12;gt_logits_above_threshold_count': 12.0,\n",
      " 'avg_test_gt12;gt_pred_scores': 0.0831642597913742,\n",
      " 'avg_test_gt12;not_gt_pred_scores': 0.00013526853581424803,\n",
      " 'avg_test_gt12;top12_overlap_count': 12.0,\n",
      " 'avg_test_gt12;top12_pred_above_threshold_count': 12.0,\n",
      " 'avg_test_gt12;total_pred_above_threshold_count': 12.0,\n",
      " 'avg_test_gt13;gt_logits_above_threshold_count': 13.0,\n",
      " 'avg_test_gt13;gt_pred_scores': 0.07677433639764786,\n",
      " 'avg_test_gt13;not_gt_pred_scores': 0.00013811785902362317,\n",
      " 'avg_test_gt13;top13_overlap_count': 13.0,\n",
      " 'avg_test_gt13;top13_pred_above_threshold_count': 13.0,\n",
      " 'avg_test_gt13;total_pred_above_threshold_count': 13.0,\n",
      " 'avg_test_gt14;gt_logits_above_threshold_count': 14.0,\n",
      " 'avg_test_gt14;gt_pred_scores': 0.07129927724599838,\n",
      " 'avg_test_gt14;not_gt_pred_scores': 0.00013924941595178097,\n",
      " 'avg_test_gt14;top14_overlap_count': 14.0,\n",
      " 'avg_test_gt14;top14_pred_above_threshold_count': 14.0,\n",
      " 'avg_test_gt14;total_pred_above_threshold_count': 14.0,\n",
      " 'avg_test_gt15;gt_logits_above_threshold_count': 15.0,\n",
      " 'avg_test_gt15;gt_pred_scores': 0.066554956138134,\n",
      " 'avg_test_gt15;not_gt_pred_scores': 0.00013964234676677734,\n",
      " 'avg_test_gt15;top15_overlap_count': 15.0,\n",
      " 'avg_test_gt15;top15_pred_above_threshold_count': 15.0,\n",
      " 'avg_test_gt15;total_pred_above_threshold_count': 15.0,\n",
      " 'avg_test_gt16;gt_logits_above_threshold_count': 16.0,\n",
      " 'avg_test_gt16;gt_pred_scores': 0.06240056827664375,\n",
      " 'avg_test_gt16;not_gt_pred_scores': 0.000144627207191661,\n",
      " 'avg_test_gt16;top16_overlap_count': 16.0,\n",
      " 'avg_test_gt16;top16_pred_above_threshold_count': 16.0,\n",
      " 'avg_test_gt16;total_pred_above_threshold_count': 16.0,\n",
      " 'avg_test_gt17;gt_logits_above_threshold_count': 17.0,\n",
      " 'avg_test_gt17;gt_pred_scores': 0.05873812362551689,\n",
      " 'avg_test_gt17;not_gt_pred_scores': 0.00014518741227220744,\n",
      " 'avg_test_gt17;top17_overlap_count': 17.0,\n",
      " 'avg_test_gt17;top17_pred_above_threshold_count': 17.0,\n",
      " 'avg_test_gt17;total_pred_above_threshold_count': 17.0,\n",
      " 'avg_test_gt18;gt_logits_above_threshold_count': 17.997802734375,\n",
      " 'avg_test_gt18;gt_pred_scores': 0.055481504648923874,\n",
      " 'avg_test_gt18;not_gt_pred_scores': 0.00014810333959758282,\n",
      " 'avg_test_gt18;top18_overlap_count': 18.0,\n",
      " 'avg_test_gt18;top18_pred_above_threshold_count': 17.997802734375,\n",
      " 'avg_test_gt18;total_pred_above_threshold_count': 17.997802734375,\n",
      " 'avg_test_gt19;gt_logits_above_threshold_count': 18.997222900390625,\n",
      " 'avg_test_gt19;gt_pred_scores': 0.052568454295396805,\n",
      " 'avg_test_gt19;not_gt_pred_scores': 0.0001499326026532799,\n",
      " 'avg_test_gt19;top19_overlap_count': 19.0,\n",
      " 'avg_test_gt19;top19_pred_above_threshold_count': 18.997222900390625,\n",
      " 'avg_test_gt19;total_pred_above_threshold_count': 18.997222900390625,\n",
      " 'avg_test_gt20;gt_logits_above_threshold_count': 19.990631103515625,\n",
      " 'avg_test_gt20;gt_pred_scores': 0.0499463714659214,\n",
      " 'avg_test_gt20;not_gt_pred_scores': 0.00015322536637540907,\n",
      " 'avg_test_gt20;top20_overlap_count': 20.0,\n",
      " 'avg_test_gt20;top20_pred_above_threshold_count': 19.990631103515625,\n",
      " 'avg_test_gt20;total_pred_above_threshold_count': 19.990631103515625,\n",
      " 'avg_test_gt21;gt_logits_above_threshold_count': 20.986791610717773,\n",
      " 'avg_test_gt21;gt_pred_scores': 0.04757428169250488,\n",
      " 'avg_test_gt21;not_gt_pred_scores': 0.000156689653522335,\n",
      " 'avg_test_gt21;top21_overlap_count': 21.0,\n",
      " 'avg_test_gt21;top21_pred_above_threshold_count': 20.986791610717773,\n",
      " 'avg_test_gt21;total_pred_above_threshold_count': 20.986791610717773,\n",
      " 'avg_test_gt22;gt_logits_above_threshold_count': 21.93222427368164,\n",
      " 'avg_test_gt22;gt_pred_scores': 0.04541846364736557,\n",
      " 'avg_test_gt22;not_gt_pred_scores': 0.0001587684528203681,\n",
      " 'avg_test_gt22;top22_overlap_count': 22.0,\n",
      " 'avg_test_gt22;top22_pred_above_threshold_count': 21.93222427368164,\n",
      " 'avg_test_gt22;total_pred_above_threshold_count': 21.93222427368164,\n",
      " 'avg_test_gt23;gt_logits_above_threshold_count': 22.706003189086914,\n",
      " 'avg_test_gt23;gt_pred_scores': 0.043448206037282944,\n",
      " 'avg_test_gt23;not_gt_pred_scores': 0.0001728257047943771,\n",
      " 'avg_test_gt23;top23_overlap_count': 23.0,\n",
      " 'avg_test_gt23;top23_pred_above_threshold_count': 22.706003189086914,\n",
      " 'avg_test_gt23;total_pred_above_threshold_count': 22.706003189086914,\n",
      " 'avg_test_gt24;gt_logits_above_threshold_count': 23.215871810913086,\n",
      " 'avg_test_gt24;gt_pred_scores': 0.04164484888315201,\n",
      " 'avg_test_gt24;not_gt_pred_scores': 0.00017455944907851517,\n",
      " 'avg_test_gt24;top24_overlap_count': 24.0,\n",
      " 'avg_test_gt24;top24_pred_above_threshold_count': 23.215871810913086,\n",
      " 'avg_test_gt24;total_pred_above_threshold_count': 23.215871810913086,\n",
      " 'avg_test_gt25;gt_logits_above_threshold_count': 22.828176498413086,\n",
      " 'avg_test_gt25;gt_pred_scores': 0.03998405858874321,\n",
      " 'avg_test_gt25;not_gt_pred_scores': 0.0001992811739910394,\n",
      " 'avg_test_gt25;top25_overlap_count': 25.0,\n",
      " 'avg_test_gt25;top25_pred_above_threshold_count': 22.828176498413086,\n",
      " 'avg_test_gt25;total_pred_above_threshold_count': 22.828176498413086,\n",
      " 'avg_test_gt26;gt_logits_above_threshold_count': 19.149999618530273,\n",
      " 'avg_test_gt26;gt_pred_scores': 0.03845120966434479,\n",
      " 'avg_test_gt26;not_gt_pred_scores': 0.00026859427453018725,\n",
      " 'avg_test_gt26;top26_overlap_count': 26.0,\n",
      " 'avg_test_gt26;top26_pred_above_threshold_count': 19.149999618530273,\n",
      " 'avg_test_gt26;total_pred_above_threshold_count': 19.149999618530273,\n",
      " 'avg_test_gt27;gt_logits_above_threshold_count': 14.881451606750488,\n",
      " 'avg_test_gt27;gt_pred_scores': 0.03703700006008148,\n",
      " 'avg_test_gt27;not_gt_pred_scores': nan,\n",
      " 'avg_test_gt27;top27_overlap_count': 27.0,\n",
      " 'avg_test_gt27;top27_pred_above_threshold_count': 14.881451606750488,\n",
      " 'avg_test_gt27;total_pred_above_threshold_count': 14.881451606750488,\n",
      " 'avg_test_gt8;gt_logits_above_threshold_count': 8.0,\n",
      " 'avg_test_gt8;gt_pred_scores': 0.12469198554754257,\n",
      " 'avg_test_gt8;not_gt_pred_scores': 0.00012969046656508,\n",
      " 'avg_test_gt8;top8_overlap_count': 8.0,\n",
      " 'avg_test_gt8;top8_pred_above_threshold_count': 8.0,\n",
      " 'avg_test_gt8;total_pred_above_threshold_count': 8.0,\n",
      " 'avg_test_gt9;gt_logits_above_threshold_count': 9.0,\n",
      " 'avg_test_gt9;gt_pred_scores': 0.11087169498205185,\n",
      " 'avg_test_gt9;not_gt_pred_scores': 0.0001197049641632475,\n",
      " 'avg_test_gt9;top9_overlap_count': 9.0,\n",
      " 'avg_test_gt9;top9_pred_above_threshold_count': 9.0,\n",
      " 'avg_test_gt9;total_pred_above_threshold_count': 9.0,\n",
      " 'avg_test_precision_by_Query': 1.0,\n",
      " 'avg_test_precision_by_QueryKey': 1.0,\n",
      " 'avg_test_recall_by_Query': 0.9134174585342407,\n",
      " 'avg_test_recall_by_QueryKey': 0.8783836364746094,\n",
      " 'avg_test_topK_overall_overlap_ratio': 1.0,\n",
      " 'test_KL_loss': 4.993302345275879,\n",
      " 'test_KL_loss_per_example': 0.0048762718215584755,\n",
      " 'test_accuracy_by_Query': 0.9136936068534851,\n",
      " 'test_accuracy_by_QueryKey': 0.9136936068534851,\n",
      " 'test_f1_by_Query': 0.9443569183349609,\n",
      " 'test_f1_by_QueryKey': 0.9352415800094604,\n",
      " 'test_gt10;gt_logits_above_threshold_count': 10.0,\n",
      " 'test_gt10;gt_pred_scores': 0.09976567327976227,\n",
      " 'test_gt10;not_gt_pred_scores': 0.00013783920439891517,\n",
      " 'test_gt10;top10_overlap_count': 10.0,\n",
      " 'test_gt10;top10_pred_above_threshold_count': 10.0,\n",
      " 'test_gt10;total_pred_above_threshold_count': 10.0,\n",
      " 'test_gt11;gt_logits_above_threshold_count': 11.0,\n",
      " 'test_gt11;gt_pred_scores': 0.09071008116006851,\n",
      " 'test_gt11;not_gt_pred_scores': 0.00013682253484148532,\n",
      " 'test_gt11;top11_overlap_count': 11.0,\n",
      " 'test_gt11;top11_pred_above_threshold_count': 11.0,\n",
      " 'test_gt11;total_pred_above_threshold_count': 11.0,\n",
      " 'test_gt12;gt_logits_above_threshold_count': 12.0,\n",
      " 'test_gt12;gt_pred_scores': 0.08316425234079361,\n",
      " 'test_gt12;not_gt_pred_scores': 0.00013526855036616325,\n",
      " 'test_gt12;top12_overlap_count': 12.0,\n",
      " 'test_gt12;top12_pred_above_threshold_count': 12.0,\n",
      " 'test_gt12;total_pred_above_threshold_count': 12.0,\n",
      " 'test_gt13;gt_logits_above_threshold_count': 13.0,\n",
      " 'test_gt13;gt_pred_scores': 0.07677433639764786,\n",
      " 'test_gt13;not_gt_pred_scores': 0.00013811785902362317,\n",
      " 'test_gt13;top13_overlap_count': 13.0,\n",
      " 'test_gt13;top13_pred_above_threshold_count': 13.0,\n",
      " 'test_gt13;total_pred_above_threshold_count': 13.0,\n",
      " 'test_gt14;gt_logits_above_threshold_count': 14.0,\n",
      " 'test_gt14;gt_pred_scores': 0.07129926979541779,\n",
      " 'test_gt14;not_gt_pred_scores': 0.00013924941595178097,\n",
      " 'test_gt14;top14_overlap_count': 14.0,\n",
      " 'test_gt14;top14_pred_above_threshold_count': 14.0,\n",
      " 'test_gt14;total_pred_above_threshold_count': 14.0,\n",
      " 'test_gt15;gt_logits_above_threshold_count': 15.0,\n",
      " 'test_gt15;gt_pred_scores': 0.066554956138134,\n",
      " 'test_gt15;not_gt_pred_scores': 0.00013964234676677734,\n",
      " 'test_gt15;top15_overlap_count': 15.0,\n",
      " 'test_gt15;top15_pred_above_threshold_count': 15.0,\n",
      " 'test_gt15;total_pred_above_threshold_count': 15.0,\n",
      " 'test_gt16;gt_logits_above_threshold_count': 16.0,\n",
      " 'test_gt16;gt_pred_scores': 0.06240056827664375,\n",
      " 'test_gt16;not_gt_pred_scores': 0.000144627207191661,\n",
      " 'test_gt16;top16_overlap_count': 16.0,\n",
      " 'test_gt16;top16_pred_above_threshold_count': 16.0,\n",
      " 'test_gt16;total_pred_above_threshold_count': 16.0,\n",
      " 'test_gt17;gt_logits_above_threshold_count': 17.0,\n",
      " 'test_gt17;gt_pred_scores': 0.05873812362551689,\n",
      " 'test_gt17;not_gt_pred_scores': 0.00014518741227220744,\n",
      " 'test_gt17;top17_overlap_count': 17.0,\n",
      " 'test_gt17;top17_pred_above_threshold_count': 17.0,\n",
      " 'test_gt17;total_pred_above_threshold_count': 17.0,\n",
      " 'test_gt18;gt_logits_above_threshold_count': 17.997802734375,\n",
      " 'test_gt18;gt_pred_scores': 0.055481504648923874,\n",
      " 'test_gt18;not_gt_pred_scores': 0.0001481033250456676,\n",
      " 'test_gt18;top18_overlap_count': 18.0,\n",
      " 'test_gt18;top18_pred_above_threshold_count': 17.997802734375,\n",
      " 'test_gt18;total_pred_above_threshold_count': 17.997802734375,\n",
      " 'test_gt19;gt_logits_above_threshold_count': 18.997222900390625,\n",
      " 'test_gt19;gt_pred_scores': 0.052568454295396805,\n",
      " 'test_gt19;not_gt_pred_scores': 0.0001499326026532799,\n",
      " 'test_gt19;top19_overlap_count': 19.0,\n",
      " 'test_gt19;top19_pred_above_threshold_count': 18.997222900390625,\n",
      " 'test_gt19;total_pred_above_threshold_count': 18.997222900390625,\n",
      " 'test_gt20;gt_logits_above_threshold_count': 19.990629196166992,\n",
      " 'test_gt20;gt_pred_scores': 0.0499463714659214,\n",
      " 'test_gt20;not_gt_pred_scores': 0.00015322536637540907,\n",
      " 'test_gt20;top20_overlap_count': 20.0,\n",
      " 'test_gt20;top20_pred_above_threshold_count': 19.990629196166992,\n",
      " 'test_gt20;total_pred_above_threshold_count': 19.990629196166992,\n",
      " 'test_gt21;gt_logits_above_threshold_count': 20.986791610717773,\n",
      " 'test_gt21;gt_pred_scores': 0.04757428169250488,\n",
      " 'test_gt21;not_gt_pred_scores': 0.00015668963897041976,\n",
      " 'test_gt21;top21_overlap_count': 21.0,\n",
      " 'test_gt21;top21_pred_above_threshold_count': 20.986791610717773,\n",
      " 'test_gt21;total_pred_above_threshold_count': 20.986791610717773,\n",
      " 'test_gt22;gt_logits_above_threshold_count': 21.93222427368164,\n",
      " 'test_gt22;gt_pred_scores': 0.04541846364736557,\n",
      " 'test_gt22;not_gt_pred_scores': 0.0001587684528203681,\n",
      " 'test_gt22;top22_overlap_count': 22.0,\n",
      " 'test_gt22;top22_pred_above_threshold_count': 21.93222427368164,\n",
      " 'test_gt22;total_pred_above_threshold_count': 21.93222427368164,\n",
      " 'test_gt23;gt_logits_above_threshold_count': 22.706003189086914,\n",
      " 'test_gt23;gt_pred_scores': 0.043448202311992645,\n",
      " 'test_gt23;not_gt_pred_scores': 0.0001728257047943771,\n",
      " 'test_gt23;top23_overlap_count': 23.0,\n",
      " 'test_gt23;top23_pred_above_threshold_count': 22.706003189086914,\n",
      " 'test_gt23;total_pred_above_threshold_count': 22.706003189086914,\n",
      " 'test_gt24;gt_logits_above_threshold_count': 23.215871810913086,\n",
      " 'test_gt24;gt_pred_scores': 0.04164484888315201,\n",
      " 'test_gt24;not_gt_pred_scores': 0.00017455944907851517,\n",
      " 'test_gt24;top24_overlap_count': 24.0,\n",
      " 'test_gt24;top24_pred_above_threshold_count': 23.215871810913086,\n",
      " 'test_gt24;total_pred_above_threshold_count': 23.215871810913086,\n",
      " 'test_gt25;gt_logits_above_threshold_count': 22.828174591064453,\n",
      " 'test_gt25;gt_pred_scores': 0.03998405486345291,\n",
      " 'test_gt25;not_gt_pred_scores': 0.0001992811739910394,\n",
      " 'test_gt25;top25_overlap_count': 25.0,\n",
      " 'test_gt25;top25_pred_above_threshold_count': 22.828174591064453,\n",
      " 'test_gt25;total_pred_above_threshold_count': 22.828174591064453,\n",
      " 'test_gt26;gt_logits_above_threshold_count': 19.149999618530273,\n",
      " 'test_gt26;gt_pred_scores': 0.03845120966434479,\n",
      " 'test_gt26;not_gt_pred_scores': 0.00026859427453018725,\n",
      " 'test_gt26;top26_overlap_count': 26.0,\n",
      " 'test_gt26;top26_pred_above_threshold_count': 19.149999618530273,\n",
      " 'test_gt26;total_pred_above_threshold_count': 19.149999618530273,\n",
      " 'test_gt27;gt_logits_above_threshold_count': 14.881451606750488,\n",
      " 'test_gt27;gt_pred_scores': 0.03703700006008148,\n",
      " 'test_gt27;not_gt_pred_scores': nan,\n",
      " 'test_gt27;top27_overlap_count': 27.0,\n",
      " 'test_gt27;top27_pred_above_threshold_count': 14.881451606750488,\n",
      " 'test_gt27;total_pred_above_threshold_count': 14.881451606750488,\n",
      " 'test_gt6;gt_logits_above_threshold_count': 6.0,\n",
      " 'test_gt6;gt_pred_scores': 0.16605910658836365,\n",
      " 'test_gt6;not_gt_pred_scores': 0.0001735896075842902,\n",
      " 'test_gt6;top6_overlap_count': 6.0,\n",
      " 'test_gt6;top6_pred_above_threshold_count': 6.0,\n",
      " 'test_gt6;total_pred_above_threshold_count': 6.0,\n",
      " 'test_gt7;gt_logits_above_threshold_count': 7.0,\n",
      " 'test_gt7;gt_pred_scores': 0.14212918281555176,\n",
      " 'test_gt7;not_gt_pred_scores': 0.0002547877375036478,\n",
      " 'test_gt7;top7_overlap_count': 7.0,\n",
      " 'test_gt7;top7_pred_above_threshold_count': 7.0,\n",
      " 'test_gt7;total_pred_above_threshold_count': 7.0,\n",
      " 'test_gt8;gt_logits_above_threshold_count': 8.0,\n",
      " 'test_gt8;gt_pred_scores': 0.12469198554754257,\n",
      " 'test_gt8;not_gt_pred_scores': 0.00012969046656508,\n",
      " 'test_gt8;top8_overlap_count': 8.0,\n",
      " 'test_gt8;top8_pred_above_threshold_count': 8.0,\n",
      " 'test_gt8;total_pred_above_threshold_count': 8.0,\n",
      " 'test_gt9;gt_logits_above_threshold_count': 9.0,\n",
      " 'test_gt9;gt_pred_scores': 0.11087169498205185,\n",
      " 'test_gt9;not_gt_pred_scores': 0.0001197049641632475,\n",
      " 'test_gt9;top9_overlap_count': 9.0,\n",
      " 'test_gt9;top9_pred_above_threshold_count': 9.0,\n",
      " 'test_gt9;total_pred_above_threshold_count': 9.0,\n",
      " 'test_precision_by_Query': 1.0,\n",
      " 'test_precision_by_QueryKey': 1.0,\n",
      " 'test_recall_by_Query': 0.9134174585342407,\n",
      " 'test_recall_by_QueryKey': 0.8783836364746094,\n",
      " 'test_topK_overall_overlap_ratio': 1.0}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainmodule, game_datamodule = main.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-jefferson",
   "metadata": {},
   "source": [
    "## KL Loss Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prospective-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(np.array(x) - np.max(x, axis=-1).reshape(-1, 1))\n",
    "    return e_x / np.sum(e_x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def entropy(x):\n",
    "    return - np.sum(x * np.log2(x), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fancy-bhutan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 50th data indices by kl loss [ 968  637 4021  571  263 4502 3281  461 4530 3503 4867 2780  300 1118\n",
      " 1694 1500 4836 4938 4741 2974 1320 3052 4264 1115 1953 3868 2797 3896\n",
      " 2238 2083 4952 3747 1458 1920 3364 3987   82 4991 4669 4520 3895 1587\n",
      " 2822 2339  589  127  449  136 2446 1383]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1361., 1810., 1292.,  424.,  151.,   53.,   17.,    5.,    3.,\n",
       "           4.]),\n",
       " array([0.00049518, 0.00302723, 0.00555929, 0.00809135, 0.0106234 ,\n",
       "        0.01315546, 0.01568751, 0.01821957, 0.02075163, 0.02328368,\n",
       "        0.02581574]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 'checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210331-140055-Con;Vec512;L8H8Lk4Hk2;scheduledAdamW72000;17145.88Kparams_runId_337q537l/test_metrics.json'\n",
    "with open(p, 'r') as f:\n",
    "    res = json.load(f)\n",
    "    \n",
    "full_kl_loss = [row for batch in res['full_kl_loss'] for row in batch]\n",
    "full_logits = [row for batch in res['full_logits'] for row in batch]\n",
    "full_probs = softmax(full_logits)\n",
    "\n",
    "\n",
    "full_kl_loss_sum_row = np.sum(np.array(full_kl_loss), axis=-1)\n",
    "sorted_indices = np.argsort(full_kl_loss_sum_row)\n",
    "print('top 50th data indices by kl loss', sorted_indices[:50])\n",
    "\n",
    "plt.hist(full_kl_loss_sum_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "racial-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "key_support_size : 27\n",
      "N_pairs : 8\n",
      "union_only : True\n",
      "max_len_q : 16\n",
      "len_k : 1\n",
      "train_gt_idxs length : 0\n",
      "val_gt_idxs length : 5120\n",
      "test_gt_idxs length : 5120\n",
      "train_tokens length : 0\n",
      "val_tokens length : 5120\n",
      "test_tokens length : 5120\n",
      "test_marginal_gt_idxs length : 5120\n",
      "test_marginal_tokens length : 5120\n",
      "vocab_size : 74\n",
      "symbol_vocab_token_lookup : {'(': 64, ')': 65, 'NULL': 66, 'SEP': 67, 'SOS': 68, 'EOS': 69, 'PAD': 70, 'PLH': 71, '|': 72, '!': 73}\n",
      "vocab_by_property : False\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "game_data = main.load_data(args.data_path)\n",
    "gt_counts = np.array([len(gt_idxs) for gt_idxs in game_data['test_gt_idxs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_counts[sorted_indices].tolist()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_logits[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data['test_tokens'][373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.exp(full_logits[1207]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.exp(full_probs[1207]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_probs[373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([str(idx) for idx in gt_idxs_373], full_probs[373][gt_idxs_373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([str(idx) for idx in not_gt_idxs_373], full_probs[373][not_gt_idxs_373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_idxs_373 = sorted(game_data['test_gt_idxs'][373])\n",
    "not_gt_idxs_373 = [i for i in range(27) if not i in gt_idxs_373]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.ylim(0.0, 0.1)\n",
    "\n",
    "plt.axhline(y=1./gt_counts[373], color='r', linestyle='-')\n",
    "\n",
    "plt.bar(\n",
    "    [str(idx) for idx in gt_idxs_373] + [' '] + [str(idx) for idx in not_gt_idxs_373],  \n",
    "    [1./gt_counts[373]] * 13 + [0.] * 15,\n",
    "    color='k'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_idxs_373 = sorted(game_data['test_gt_idxs'][373])\n",
    "not_gt_idxs_373 = [i for i in range(27) if not i in gt_idxs_373]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.ylim(0.0, 0.1)\n",
    "\n",
    "plt.axhline(y=1./gt_counts[373], color='r', linestyle='-')\n",
    "\n",
    "plt.bar(\n",
    "    [str(idx) for idx in gt_idxs_373] + [' '] + [str(idx) for idx in not_gt_idxs_373],  \n",
    "    [1./27] * 13 + [0.] + [1./27] * 14,\n",
    "    color='k'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_idxs_373 = sorted(game_data['test_gt_idxs'][373])\n",
    "not_gt_idxs_373 = [i for i in range(27) if not i in gt_idxs_373]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.ylim(0.0, 0.1)\n",
    "\n",
    "plt.axhline(y=1./gt_counts[373], color='r', linestyle='-')\n",
    "\n",
    "plt.bar(\n",
    "    [str(idx) for idx in gt_idxs_373] + [' '] + [str(idx) for idx in not_gt_idxs_373],  \n",
    "    list(full_probs[373][gt_idxs_373]) + [0] + list(full_probs[373][not_gt_idxs_373]),\n",
    "    color='k'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(gt_idxs_373, full_probs[373][gt_idxs_373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_idxs_373 = sorted(game_data['test_gt_idxs'][373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_gt_idxs_373 = [i for i in range(27) if not i in gt_idxs_373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-jumping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_counts[373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-gnome",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(full_probs[3834]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "standing-matrix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7097156625947445"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(full_probs[373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(entropy(full_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ambient-stockholm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.711435771119248"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_probs_13 = np.array(full_probs)[(gt_counts == 13)]\n",
    "np.mean(entropy(full_probs_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exempt-oxygen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.97790803259623"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_probs_10_20 = np.array(full_probs)[(gt_counts > 10) & (gt_counts <20)]\n",
    "np.mean(entropy(full_probs_10_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "restricted-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.155603819998225"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_probs_12_15 = np.array(full_probs)[(gt_counts > 12) & (gt_counts <25)]\n",
    "np.mean(entropy(full_probs_12_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-karen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-meditation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "legal-consideration",
   "metadata": {},
   "source": [
    "## Embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "every-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import BatchFetcher\n",
    "from metrics import find_nn, analogy, find_cos, find_dotproduct, find_euclidean\n",
    "from dataraw_sampling import construct_card_idx_lookup\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statewide-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "key_support_size : 27\n",
      "N_pairs : 8\n",
      "union_only : True\n",
      "max_len_q : 16\n",
      "len_k : 1\n",
      "train_gt_idxs length : 0\n",
      "val_gt_idxs length : 5120\n",
      "test_gt_idxs length : 5120\n",
      "train_tokens length : 0\n",
      "val_tokens length : 5120\n",
      "test_tokens length : 5120\n",
      "test_marginal_gt_idxs length : 5120\n",
      "test_marginal_tokens length : 5120\n",
      "vocab_size : 74\n",
      "symbol_vocab_token_lookup : {'(': 64, ')': 65, 'NULL': 66, 'SEP': 67, 'SOS': 68, 'EOS': 69, 'PAD': 70, 'PLH': 71, '|': 72, '!': 73}\n",
      "vocab_by_property : False\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "cuda_device = trainmodule.model._parameters['key_bias_terms'].device\n",
    "\n",
    "game_data = main.load_data(args.data_path)\n",
    "batch_fecther = BatchFetcher(\n",
    "    raw_data = game_data, device=cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "minimal-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [[(0,1,3),(0,0,0)], [(0,1,3),(1,2,0)]]\n",
    "keys = [[(0,0,0)],[(0,1,0)],[(2,2,2)]]\n",
    "X_query, X_key = batch_fecther.make_query_batch(X_query_properties=queries, X_key_properties=None, X_key=[i for i in range(game_data['key_support_size'])])\n",
    "query_repr, key_repr = trainmodule.pull_repr(X_query, X_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "center-assurance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16.0520,   7.5734,   0.9461,  -2.3650,  -1.6088,  -9.6629,  -1.0611,\n",
       "           6.2110,   1.5545,  -9.1536,   2.1053,   9.0129,  12.1637,   0.8489,\n",
       "          -7.5921,  -0.9510,  12.1858,  -5.7816,  -0.7349, -12.5901,   0.1043,\n",
       "           0.3320, -10.9779,  -0.1230,   5.2522,   3.9918,   6.1307],\n",
       "        [ 18.7069,  -0.4131,  -2.1271,   2.8310,   3.0094,  -9.6155,  -2.0812,\n",
       "           9.9261,   0.7530,  -8.7308,   1.5886,   5.2933,  13.3742,   3.2014,\n",
       "           0.9388,  -0.7415,   7.5635, -14.1845,   7.0459, -16.6190,  -3.9346,\n",
       "          -7.6409,   0.2007,  -3.9483,   8.3464,  -1.4086,   7.1514]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unique-produce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0796, -0.0752, -0.0946, -0.1759, -0.1973, -0.0511, -0.0078, -0.0213,\n",
       "         -0.0396, -0.1423,  0.0275,  0.0406, -0.1915,  0.1227, -0.1559,  0.0448,\n",
       "         -0.0668, -0.0715, -0.0630,  0.1548,  0.2194, -0.0153,  0.1015,  0.2050,\n",
       "          0.1224, -0.0886, -0.0916],\n",
       "        [-0.1105,  0.1271, -0.0168,  0.1096, -0.1569,  0.1784,  0.1657,  0.0555,\n",
       "          0.0832, -0.0355, -0.1577,  0.0570, -0.1655,  0.1863,  0.0719,  0.0632,\n",
       "          0.1194, -0.0047, -0.1264, -0.1706,  0.1934,  0.0974, -0.1436, -0.0734,\n",
       "         -0.1678,  0.0156, -0.0255],\n",
       "        [ 0.0391, -0.0548, -0.1014, -0.1172, -0.1366,  0.1293, -0.1258,  0.1053,\n",
       "          0.1206,  0.1456,  0.2688, -0.0827,  0.0552,  0.0469,  0.0186,  0.1834,\n",
       "          0.0498, -0.0990, -0.1653,  0.0606,  0.1213,  0.0900, -0.1319, -0.0397,\n",
       "          0.1680, -0.0195, -0.0487],\n",
       "        [-0.1474, -0.1503,  0.0864, -0.0445, -0.0476,  0.1852,  0.0725, -0.0681,\n",
       "         -0.0272, -0.0397,  0.2288, -0.1121, -0.0085, -0.0052, -0.0668, -0.1025,\n",
       "          0.0357,  0.1208,  0.0404, -0.1233, -0.1376, -0.1014, -0.0771, -0.1117,\n",
       "         -0.0681,  0.0049, -0.1784],\n",
       "        [-0.1427, -0.0765,  0.1349, -0.0037,  0.1386, -0.0160,  0.1671, -0.1175,\n",
       "         -0.1561,  0.2067,  0.0063,  0.1162, -0.0426, -0.1920,  0.1304, -0.0298,\n",
       "          0.1533, -0.0484,  0.0206, -0.0611,  0.1380, -0.0699, -0.1009,  0.1285,\n",
       "         -0.1050, -0.0298, -0.1057],\n",
       "        [-0.1444,  0.0969, -0.0357,  0.0047,  0.0320,  0.0874,  0.0977,  0.0310,\n",
       "         -0.0735,  0.0185, -0.0604, -0.2521, -0.0096,  0.1821, -0.1010,  0.0019,\n",
       "          0.1994, -0.1358, -0.0484,  0.0610,  0.0635, -0.1362, -0.0846, -0.1290,\n",
       "          0.1548, -0.0178, -0.1587],\n",
       "        [ 0.0964,  0.0643,  0.2006,  0.0830,  0.0836,  0.1673, -0.1653, -0.1555,\n",
       "         -0.0542,  0.0008,  0.1589,  0.0558, -0.0944,  0.1569,  0.0191, -0.1105,\n",
       "         -0.1450, -0.0644,  0.0536,  0.1196,  0.0744, -0.1677, -0.0351,  0.1449,\n",
       "         -0.1135,  0.1755,  0.0361],\n",
       "        [ 0.0350, -0.0270,  0.1234, -0.1490, -0.1399,  0.1617, -0.0601,  0.0917,\n",
       "         -0.0164,  0.1040, -0.0749,  0.0910,  0.1011, -0.1517,  0.1198,  0.0315,\n",
       "          0.1684,  0.1217,  0.0646,  0.0244,  0.0618, -0.0340,  0.0958, -0.1123,\n",
       "          0.0760,  0.1704, -0.1049],\n",
       "        [-0.1710, -0.0094,  0.0144,  0.0782,  0.1190,  0.1037, -0.0155,  0.1315,\n",
       "         -0.0182, -0.0756,  0.0443,  0.1926, -0.0185,  0.0841, -0.1416,  0.1126,\n",
       "          0.1474,  0.1743, -0.1681,  0.0695,  0.0852, -0.1461,  0.1249, -0.1660,\n",
       "         -0.0817,  0.0510,  0.0606],\n",
       "        [ 0.0672,  0.0502, -0.1601,  0.0654,  0.0425,  0.0154,  0.0272, -0.1369,\n",
       "         -0.1660,  0.0682,  0.0675, -0.1491,  0.0985, -0.1747, -0.0546,  0.1641,\n",
       "         -0.0907,  0.0718,  0.0950, -0.0617,  0.0802,  0.0943,  0.1252, -0.0005,\n",
       "         -0.1937,  0.0949, -0.1559],\n",
       "        [-0.0968,  0.0352,  0.0573, -0.1230,  0.0065,  0.0847,  0.0457, -0.0910,\n",
       "         -0.0354,  0.0934,  0.1039, -0.1737, -0.0582, -0.0842,  0.0580,  0.0954,\n",
       "         -0.0394,  0.1833,  0.0254, -0.1434, -0.0599, -0.1207,  0.0667,  0.1653,\n",
       "          0.1686,  0.1161,  0.1292],\n",
       "        [ 0.0586,  0.0301, -0.0405, -0.1412, -0.0177,  0.1443, -0.1167, -0.1251,\n",
       "          0.1026,  0.2707, -0.0441,  0.0246, -0.1885,  0.0945, -0.1433, -0.0347,\n",
       "         -0.0311, -0.0566, -0.1126, -0.0841,  0.0462, -0.1027, -0.0153, -0.1893,\n",
       "         -0.1215, -0.0328,  0.0179],\n",
       "        [-0.1062,  0.1182,  0.1801, -0.1266, -0.0668, -0.0649, -0.1420,  0.0911,\n",
       "          0.0277, -0.0415,  0.0984, -0.1419, -0.1563,  0.0379,  0.0675,  0.1467,\n",
       "         -0.0786, -0.0518, -0.0833, -0.0047, -0.1125,  0.0479,  0.0133, -0.1585,\n",
       "         -0.0301, -0.1761, -0.1814],\n",
       "        [-0.0938, -0.0214,  0.0502,  0.1838,  0.0314, -0.0302,  0.0498, -0.1398,\n",
       "         -0.0241,  0.1031, -0.0529,  0.1399, -0.1364,  0.0204, -0.0808,  0.0796,\n",
       "         -0.0918, -0.1217,  0.1630,  0.1279, -0.1195,  0.1279,  0.0412,  0.1062,\n",
       "          0.1131,  0.1642, -0.0890],\n",
       "        [-0.1638,  0.1496, -0.0925, -0.0513,  0.0761,  0.1609,  0.0850, -0.1657,\n",
       "          0.1335,  0.0852,  0.0477,  0.0067,  0.0353,  0.0046,  0.0548, -0.1047,\n",
       "          0.1070, -0.0553,  0.1221,  0.0874,  0.0544,  0.0959,  0.1543,  0.0457,\n",
       "         -0.1197, -0.1324, -0.0046],\n",
       "        [-0.0496, -0.0899,  0.1453,  0.0969,  0.0475,  0.1424, -0.2292,  0.0740,\n",
       "         -0.0156,  0.1233, -0.0676, -0.1066, -0.1679, -0.0608, -0.0167, -0.0416,\n",
       "          0.0850,  0.1121,  0.2119, -0.0603,  0.1648,  0.0595, -0.0851, -0.0988,\n",
       "         -0.0607, -0.0439,  0.0977],\n",
       "        [-0.1051, -0.1330,  0.0802, -0.0399, -0.1562, -0.0730,  0.0564, -0.0392,\n",
       "          0.1048,  0.1360, -0.0626, -0.1054,  0.0310,  0.1446,  0.1217,  0.1560,\n",
       "          0.0922,  0.1506,  0.1263,  0.1972,  0.0308, -0.1483, -0.1064, -0.0524,\n",
       "         -0.1032, -0.0659,  0.0447],\n",
       "        [ 0.0385,  0.0711, -0.1928,  0.0268, -0.0430,  0.0186,  0.0586,  0.1280,\n",
       "         -0.1819,  0.0062, -0.1062,  0.1479, -0.1585,  0.0678,  0.1190, -0.0165,\n",
       "         -0.1417,  0.1791,  0.0863,  0.2173, -0.0580,  0.0677, -0.1442, -0.2034,\n",
       "          0.1227, -0.0784, -0.0060],\n",
       "        [-0.0955, -0.1620, -0.1336, -0.0201,  0.0406,  0.0808, -0.0173,  0.0824,\n",
       "         -0.0684,  0.1449, -0.0524,  0.0645,  0.1089,  0.2385,  0.0951,  0.0684,\n",
       "         -0.0698, -0.0297,  0.1703, -0.0936,  0.1287, -0.0611,  0.1397, -0.0078,\n",
       "         -0.0837, -0.0155, -0.1124],\n",
       "        [ 0.0328, -0.1385, -0.0401,  0.1419, -0.0453,  0.1825,  0.0350, -0.1370,\n",
       "          0.0730, -0.1053, -0.0710, -0.0929, -0.1906, -0.0505,  0.1739,  0.0768,\n",
       "          0.0858, -0.2032, -0.0429, -0.0108,  0.0829, -0.1608,  0.1155,  0.0301,\n",
       "          0.1249, -0.0626,  0.1365],\n",
       "        [ 0.1161,  0.0408, -0.0170,  0.2049, -0.1181, -0.0744,  0.0605,  0.1620,\n",
       "          0.1152,  0.2119,  0.1152, -0.0250, -0.1473,  0.0847,  0.0914, -0.1162,\n",
       "          0.0497,  0.0582, -0.0352, -0.0456,  0.1228,  0.0055,  0.1684, -0.0878,\n",
       "         -0.0371, -0.0724, -0.0828],\n",
       "        [ 0.0056, -0.0490, -0.0327,  0.1023, -0.1598,  0.1561, -0.1728,  0.1182,\n",
       "         -0.1150,  0.0408, -0.1242, -0.0235,  0.0922, -0.0483,  0.0351,  0.0448,\n",
       "         -0.0349,  0.0594, -0.1484,  0.1139, -0.1813,  0.0578,  0.0923,  0.2307,\n",
       "         -0.0063, -0.1267,  0.0142],\n",
       "        [-0.0588, -0.0846,  0.0688,  0.0992,  0.0799,  0.1391,  0.1416, -0.0529,\n",
       "          0.1326,  0.0582, -0.1298, -0.1305,  0.1210, -0.0355,  0.0280, -0.0615,\n",
       "         -0.1931,  0.1106, -0.1151, -0.0130,  0.1529,  0.0386,  0.0461, -0.0940,\n",
       "          0.1305, -0.0575, -0.1124],\n",
       "        [-0.1340, -0.0470, -0.1487, -0.0557,  0.0199, -0.0124,  0.0062,  0.1722,\n",
       "          0.1734, -0.0082,  0.0233, -0.1337, -0.1107, -0.0863,  0.0646, -0.0648,\n",
       "         -0.0385, -0.0510, -0.0377,  0.1181,  0.0078, -0.0826, -0.0192,  0.0562,\n",
       "         -0.1101,  0.1687, -0.0484],\n",
       "        [ 0.0058, -0.0955, -0.0672,  0.0207,  0.0367, -0.0820, -0.2090, -0.1793,\n",
       "         -0.0056, -0.0721, -0.0011, -0.1095, -0.0784,  0.1463,  0.1668,  0.0057,\n",
       "          0.1378,  0.1701, -0.1166, -0.0285, -0.0907,  0.1067,  0.0700,  0.0668,\n",
       "          0.0402, -0.0087, -0.1766],\n",
       "        [-0.1843, -0.1064,  0.0930, -0.0498, -0.1135, -0.1061, -0.1017, -0.1386,\n",
       "         -0.1004,  0.0684,  0.1270, -0.0218,  0.0336, -0.0795,  0.0864, -0.1535,\n",
       "         -0.0792, -0.0287, -0.1361, -0.0304,  0.0785,  0.0924,  0.1543, -0.1558,\n",
       "         -0.0479,  0.1688,  0.1124],\n",
       "        [ 0.1170, -0.0986,  0.1366, -0.1685,  0.0970,  0.0425,  0.0848,  0.1219,\n",
       "         -0.1401,  0.0676,  0.0791, -0.1203, -0.0069,  0.0645,  0.0206,  0.0318,\n",
       "          0.0504,  0.0771, -0.1034,  0.1122, -0.1470,  0.2280,  0.1704, -0.0644,\n",
       "         -0.0359,  0.0971,  0.0022]], device='cuda:1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the linear analogy for keys first\n",
    "key_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "posted-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_repr_normalized = key_repr / torch.linalg.norm(key_repr, ord=2, dim=-1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "virtual-winner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 27.,  54.,   0.,   0.,  54.,  54.,  54.,  54.,  54.,  27.,  81.,\n",
       "         81., 108.,   0.,   0.,   0.,  27.,   0.,   0.,  27.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,  27.]),\n",
       " array([-0.08457807, -0.07557318, -0.06656829, -0.0575634 , -0.0485585 ,\n",
       "        -0.03955361, -0.03054872, -0.02154382, -0.01253893, -0.00353404,\n",
       "         0.00547085,  0.01447575,  0.02348064,  0.03248553,  0.04149043,\n",
       "         0.05049532,  0.05950021,  0.0685051 ,  0.07751   ,  0.08651489,\n",
       "         0.09551978,  0.10452468,  0.11352957,  0.12253446,  0.13153935,\n",
       "         0.14054425,  0.14954914,  0.15855403,  0.16755893,  0.17656382,\n",
       "         0.18556871,  0.1945736 ,  0.2035785 ,  0.21258339,  0.22158828,\n",
       "         0.23059318,  0.23959807,  0.24860296,  0.25760785,  0.26661275,\n",
       "         0.27561764,  0.28462253,  0.29362743,  0.30263232,  0.31163721,\n",
       "         0.3206421 ,  0.329647  ,  0.33865189,  0.34765678,  0.35666168,\n",
       "         0.36566657]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unnormalized\n",
    "distances = []\n",
    "\n",
    "for i in range(27):\n",
    "    nn_idx, nn_dists = find_nn(v=key_repr[0], Wv=key_repr, similarity_fn=find_dotproduct, k=27)\n",
    "    distances += nn_dists.tolist()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(distances, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "rocky-surprise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n",
      "torch.Size([27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 27.,  27.,  27.,   0.,  54.,  54.,  54.,  54.,  27.,  27.,  27.,\n",
       "         81., 108.,  81.,   0.,   0.,   0.,  27.,   0.,  27.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,  27.]),\n",
       " array([-0.24802266, -0.22306221, -0.19810175, -0.17314129, -0.14818084,\n",
       "        -0.12322038, -0.09825993, -0.07329947, -0.04833902, -0.02337856,\n",
       "         0.0015819 ,  0.02654235,  0.05150281,  0.07646326,  0.10142372,\n",
       "         0.12638417,  0.15134463,  0.17630508,  0.20126554,  0.226226  ,\n",
       "         0.25118645,  0.27614691,  0.30110736,  0.32606782,  0.35102827,\n",
       "         0.37598873,  0.40094918,  0.42590964,  0.4508701 ,  0.47583055,\n",
       "         0.50079101,  0.52575146,  0.55071192,  0.57567237,  0.60063283,\n",
       "         0.62559329,  0.65055374,  0.6755142 ,  0.70047465,  0.72543511,\n",
       "         0.75039556,  0.77535602,  0.80031647,  0.82527693,  0.85023739,\n",
       "         0.87519784,  0.9001583 ,  0.92511875,  0.95007921,  0.97503966,\n",
       "         1.00000012]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(27):\n",
    "    nn_idx, nn_dists = find_nn(v=key_repr_normalized[0], Wv=key_repr_normalized, similarity_fn=find_cos, k=27)\n",
    "    distances += nn_dists.tolist()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(distances, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "straight-click",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04986089455826979, 0.0226185692957154, 16.48893701657653)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(distances), np.mean(distances), np.sum(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "precious-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "card2idx_lookup, idx2card_lookup = construct_card_idx_lookup(game_data['num_attributes'], game_data['num_attr_vals'])\n",
    "\n",
    "\n",
    "def linear_analogy_by_props(propertiesA, propertiesB, propertiesC, card2idx_lookup, idx2card_lookup):\n",
    "    keyidxA = card2idx_lookup[propertiesA]\n",
    "    keyidxB = card2idx_lookup[propertiesB]\n",
    "    keyidxC = card2idx_lookup[propertiesC]\n",
    "\n",
    "    print(keyidxA, keyidxB, keyidxC)\n",
    "\n",
    "    vA = key_repr[keyidxA]\n",
    "    vB = key_repr[keyidxB]\n",
    "    vC = key_repr[keyidxC]\n",
    "\n",
    "    nns_idx, nns_distances = analogy(vA, vB, vC, key_repr, similarity_fn=find_cos, k=None)\n",
    "    nns_properties = [idx2card_lookup[idx.item()] for idx in nns_idx]\n",
    "    print(nns_idx, nns_distances)\n",
    "    print(nns_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a query that 27 got right, but 16 got wrong.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "historic-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 13\n",
      "torch.Size([27])\n",
      "tensor([13, 24, 21, 17,  0,  5, 19,  6, 18,  9, 16, 14, 12,  1, 26, 10,  4, 20,\n",
      "        15, 22, 23,  2,  3,  8, 11,  7, 25], device='cuda:1') tensor([ 5.9432e-01,  5.2089e-01,  1.8108e-01,  1.7092e-01,  1.5072e-01,\n",
      "         9.9470e-02,  8.8152e-02,  5.8378e-02,  5.0742e-02,  2.9587e-02,\n",
      "         2.6836e-02,  2.3646e-02, -3.2075e-04, -9.3897e-03, -3.5618e-02,\n",
      "        -4.0437e-02, -4.1036e-02, -5.6920e-02, -6.9848e-02, -8.6352e-02,\n",
      "        -1.0769e-01, -1.0988e-01, -1.1066e-01, -1.4922e-01, -1.7888e-01,\n",
      "        -1.9084e-01, -5.6350e-01], device='cuda:1')\n",
      "[(1, 1, 1), (2, 2, 0), (2, 1, 0), (1, 2, 2), (0, 0, 0), (0, 1, 2), (2, 0, 1), (0, 2, 0), (2, 0, 0), (1, 0, 0), (1, 2, 1), (1, 1, 2), (1, 1, 0), (0, 0, 1), (2, 2, 2), (1, 0, 1), (0, 1, 1), (2, 0, 2), (1, 2, 0), (2, 1, 1), (2, 1, 2), (0, 0, 2), (0, 1, 0), (0, 2, 2), (1, 0, 2), (0, 2, 1), (2, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "linear_analogy_by_props(\n",
    "    propertiesA = (2,2,1), \n",
    "    propertiesB = (2,2,0), \n",
    "    propertiesC = (1,1,1), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "manual-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 25 8\n",
      "torch.Size([27])\n",
      "tensor([ 8, 25,  6, 11,  3,  1, 23, 12, 20, 24, 26, 14, 22, 18,  0, 19,  5, 13,\n",
      "         9, 15,  4, 10, 16,  2, 17, 21,  7], device='cuda:1') tensor([ 0.5836,  0.5672,  0.1414,  0.1334,  0.0939,  0.0706,  0.0654,  0.0504,\n",
      "         0.0499,  0.0454,  0.0359,  0.0162,  0.0008, -0.0127, -0.0160, -0.0195,\n",
      "        -0.0250, -0.0378, -0.0395, -0.0437, -0.0445, -0.0795, -0.1001, -0.1075,\n",
      "        -0.1169, -0.1456, -0.4116], device='cuda:1')\n",
      "[(0, 2, 2), (2, 2, 1), (0, 2, 0), (1, 0, 2), (0, 1, 0), (0, 0, 1), (2, 1, 2), (1, 1, 0), (2, 0, 2), (2, 2, 0), (2, 2, 2), (1, 1, 2), (2, 1, 1), (2, 0, 0), (0, 0, 0), (2, 0, 1), (0, 1, 2), (1, 1, 1), (1, 0, 0), (1, 2, 0), (0, 1, 1), (1, 0, 1), (1, 2, 1), (0, 0, 2), (1, 2, 2), (2, 1, 0), (0, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "linear_analogy_by_props(\n",
    "    propertiesA = (0,2,1), \n",
    "    propertiesB = (2,2,1), \n",
    "    propertiesC = (0,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wound-actress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 19 26\n",
      "torch.Size([27])\n",
      "tensor([19, 26, 24,  0,  5, 21,  6, 13, 12, 10, 20, 23, 22, 14, 25,  2,  1, 11,\n",
      "         9,  3,  8, 17, 16, 15, 18,  4,  7], device='cuda:1') tensor([ 0.5747,  0.3474,  0.1983,  0.1816,  0.1047,  0.0855,  0.0849,  0.0837,\n",
      "         0.0797,  0.0752,  0.0469,  0.0442,  0.0374,  0.0358,  0.0024,  0.0024,\n",
      "        -0.0129, -0.0178, -0.0693, -0.0710, -0.0777, -0.1023, -0.1083, -0.1164,\n",
      "        -0.1206, -0.1305, -0.5392], device='cuda:1')\n",
      "[(2, 0, 1), (2, 2, 2), (2, 2, 0), (0, 0, 0), (0, 1, 2), (2, 1, 0), (0, 2, 0), (1, 1, 1), (1, 1, 0), (1, 0, 1), (2, 0, 2), (2, 1, 2), (2, 1, 1), (1, 1, 2), (2, 2, 1), (0, 0, 2), (0, 0, 1), (1, 0, 2), (1, 0, 0), (0, 1, 0), (0, 2, 2), (1, 2, 2), (1, 2, 1), (1, 2, 0), (2, 0, 0), (0, 1, 1), (0, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "linear_analogy_by_props(\n",
    "    propertiesA = (0,2,1), \n",
    "    propertiesB = (2,0,1), \n",
    "    propertiesC = (2,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rough-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 24\n",
      "torch.Size([27])\n",
      "tensor([24, 12, 21, 26,  3, 25,  0, 10, 19, 16, 20,  9,  2, 18,  5, 15, 13, 14,\n",
      "        22,  6,  7,  1, 17, 23,  8, 11,  4], device='cuda:1') tensor([ 1.0000,  0.2161,  0.1985,  0.1738,  0.1074,  0.1002,  0.0873,  0.0781,\n",
      "         0.0746,  0.0638,  0.0627,  0.0606,  0.0483,  0.0294,  0.0180, -0.0106,\n",
      "        -0.0149, -0.0169, -0.0192, -0.0278, -0.0422, -0.0437, -0.0440, -0.0567,\n",
      "        -0.0676, -0.0707, -0.0987], device='cuda:1')\n",
      "[(2, 2, 0), (1, 1, 0), (2, 1, 0), (2, 2, 2), (0, 1, 0), (2, 2, 1), (0, 0, 0), (1, 0, 1), (2, 0, 1), (1, 2, 1), (2, 0, 2), (1, 0, 0), (0, 0, 2), (2, 0, 0), (0, 1, 2), (1, 2, 0), (1, 1, 1), (1, 1, 2), (2, 1, 1), (0, 2, 0), (0, 2, 1), (0, 0, 1), (1, 2, 2), (2, 1, 2), (0, 2, 2), (1, 0, 2), (0, 1, 1)]\n"
     ]
    }
   ],
   "source": [
    "linear_analogy_by_props(\n",
    "    propertiesA = (2,2,1), \n",
    "    propertiesB = (2,2,1), \n",
    "    propertiesC = (2,2,0), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "familiar-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 19 8\n",
      "torch.Size([27])\n",
      "tensor([19,  8,  1,  5,  0,  6, 11, 23, 14, 20, 22, 24, 13, 18, 15, 16, 21, 10,\n",
      "         3, 12,  4,  2, 17, 25,  9, 26,  7], device='cuda:1') tensor([ 6.2927e-01,  5.0565e-01,  2.5410e-01,  2.0043e-01,  1.6078e-01,\n",
      "         1.3743e-01,  1.0221e-01,  7.0698e-02,  6.6436e-02,  5.0487e-02,\n",
      "         3.1856e-02,  2.9084e-02,  4.8149e-04, -1.0118e-02, -1.8662e-02,\n",
      "        -3.2290e-02, -3.4671e-02, -5.5464e-02, -5.6432e-02, -7.1705e-02,\n",
      "        -7.2535e-02, -7.8670e-02, -8.0427e-02, -9.1428e-02, -2.0399e-01,\n",
      "        -2.3895e-01, -5.0795e-01], device='cuda:1')\n",
      "[(2, 0, 1), (0, 2, 2), (0, 0, 1), (0, 1, 2), (0, 0, 0), (0, 2, 0), (1, 0, 2), (2, 1, 2), (1, 1, 2), (2, 0, 2), (2, 1, 1), (2, 2, 0), (1, 1, 1), (2, 0, 0), (1, 2, 0), (1, 2, 1), (2, 1, 0), (1, 0, 1), (0, 1, 0), (1, 1, 0), (0, 1, 1), (0, 0, 2), (1, 2, 2), (2, 2, 1), (1, 0, 0), (2, 2, 2), (0, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "linear_analogy_by_props(\n",
    "    propertiesA = (0,2,1), \n",
    "    propertiesB = (2,0,1), \n",
    "    propertiesC = (0,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "honey-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 19 17\n",
      "torch.Size([27])\n",
      "tensor([17, 19,  1,  0, 20,  5, 13, 21, 18,  8, 16, 15, 11, 22, 23,  2, 24, 14,\n",
      "        12,  6,  7,  4, 26, 25,  9,  3, 10], device='cuda:1') tensor([ 0.6621,  0.4171,  0.2801,  0.1884,  0.1854,  0.1191,  0.1019,  0.0783,\n",
      "         0.0723,  0.0655,  0.0533,  0.0518,  0.0305,  0.0282, -0.0138, -0.0203,\n",
      "        -0.0262, -0.0319, -0.0334, -0.0842, -0.0990, -0.1587, -0.1825, -0.2288,\n",
      "        -0.2484, -0.2989, -0.5968], device='cuda:1')\n",
      "[(1, 2, 2), (2, 0, 1), (0, 0, 1), (0, 0, 0), (2, 0, 2), (0, 1, 2), (1, 1, 1), (2, 1, 0), (2, 0, 0), (0, 2, 2), (1, 2, 1), (1, 2, 0), (1, 0, 2), (2, 1, 1), (2, 1, 2), (0, 0, 2), (2, 2, 0), (1, 1, 2), (1, 1, 0), (0, 2, 0), (0, 2, 1), (0, 1, 1), (2, 2, 2), (2, 2, 1), (1, 0, 0), (0, 1, 0), (1, 0, 1)]\n"
     ]
    }
   ],
   "source": [
    "linear_analogy_by_props(\n",
    "    propertiesA = (1,0,1), \n",
    "    propertiesB = (2,0,1), \n",
    "    propertiesC = (1,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distance between one card and all the other cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-palmer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
