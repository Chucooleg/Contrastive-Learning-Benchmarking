{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "general-tribe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.8.3 (default, May 19 2020, 18:47:26) \n",
      "[GCC 7.3.0]\n",
      "__pyTorch VERSION: 1.7.0\n",
      "__CUDA VERSION\n",
      "/usr/bin/sh: 1: nvcc: not found\n",
      "__CUDNN VERSION: 8003\n",
      "__Number CUDA Devices: 2\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  2\n",
      "Current cuda device  0\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/i-have-3-gpu-why-torch-cuda-device-count-only-return-1/7245/4\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confirmed-friendship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchucooleg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import main\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "urban-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.data_path = '../Raw_Datasets/SimpleShatter/SimpleShatter-Full-1Train-10Val.json'\n",
    "args.config_path = 'checkpoints/ContrastiveLearning-cardgame-Debug-Shattering/20210304-204003-SET;attr1-val10-nest1;contrastive;embedByProperty;d_model11;dot-product;params48.59K/config.json'\n",
    "args.generate_full_matrix = True\n",
    "args.checkpoint_dir = 'checkpoints'\n",
    "args.mode = 'resume_train'\n",
    "args.gpu = 0\n",
    "args.runID = '1yt1jz5u'\n",
    "args.project_name = \"ContrastiveLearning-cardgame-Debug-Shattering\"\n",
    "args.resume_max_epochs = 2000\n",
    "args.approve_before_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inclusive-angel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 1\n",
      "num_attr_vals : 10\n",
      "num_cards_per_query : 10\n",
      "nest_depth_int : 1\n",
      "key_support_size : 11\n",
      "query_support_size : 1024\n",
      "max_len_q : 10\n",
      "len_k : 1\n",
      "hold_out : False\n",
      "train_datapoints length : 5121\n",
      "val_datapoints length : 5121\n",
      "train_tokens length : 5121\n",
      "val_tokens length : 5121\n",
      "sparsity_estimate : 0.45463423295454547\n",
      "vocab_size : 18\n",
      "( : 11\n",
      ") : 12\n",
      "NULL : 13\n",
      "SEP : 14\n",
      "SOS : 15\n",
      "EOS : 16\n",
      "PAD : 17\n",
      "-----------------------\n",
      "----------hparams----------\n",
      "seed : 42\n",
      "batch_size : 512\n",
      "max_epochs : 2000\n",
      "d_model : 11\n",
      "embed_dropout : 0.0\n",
      "model : contrastive\n",
      "embedding_by_property : True\n",
      "encoder : transformer\n",
      "decoder : transformer\n",
      "d_ff : 1024\n",
      "num_heads : 1\n",
      "N_enc : 1\n",
      "N_dec : 1\n",
      "attn_wt_tying_scheme : tie_QKVO_zero_O\n",
      "attn_wt_dropout : 0.0\n",
      "heads_dropout : 0.0\n",
      "pff_dropout : 0.0\n",
      "representation_pos : 0\n",
      "dotproduct_bottleneck : True\n",
      "normalize_dotproduct : True\n",
      "contrastive_use_infoNCE : True\n",
      "loss_temperature_const : 1.0\n",
      "loss_smoothing_const : 0.1\n",
      "nonlinear_classifier_scale_down_factor : [2, 1]\n",
      "adam_lr : 0.001\n",
      "adam_beta1 : 0.9\n",
      "adam_beta2 : 0.999\n",
      "adam_epsilon : 1e-08\n",
      "adam_weight_decay : 0\n",
      "sgd_lr : 0.001\n",
      "sgd_momentum : 0\n",
      "scheduled_adam_beta1 : 0.9\n",
      "scheduled_adam_beta2 : 0.98\n",
      "scheduled_adam_epsilon : 1e-09\n",
      "scheduled_adam_warmup_steps : 8000\n",
      "gradient_clip_val : 0\n",
      "debug : False\n",
      "key_support_size : 11\n",
      "query_support_size : 1024\n",
      "num_attributes : 1\n",
      "num_attr_vals : 10\n",
      "num_cards_per_query : 10\n",
      "nest_depth_int : 1\n",
      "vocab_size : 18\n",
      "( : 11\n",
      ") : 12\n",
      "NULL : 13\n",
      "SEP : 14\n",
      "SOS : 15\n",
      "EOS : 16\n",
      "PAD : 17\n",
      "hold_out : False\n",
      "populate_logits_matrix : True\n",
      "max_len_q : 11\n",
      "len_k : 2\n",
      "---------------------------\n",
      "Continue to build model? (y/n)y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Full Matrix of Size 11 by 1024 = 11264\n",
      "Generating Full Matrix\n",
      "{'num_keys': 11, 'num_queries': 1024, 'tot_size': 11264, 'shape': (11, 1024), 'sparsity': 0.45463423295454547, 'xy_rank': 11, 'xy_div_xyind_rank': 11}\n",
      "   | Name                                                              | Type                   | Params\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "0  | metrics                                                           | ThresholdedMetrics     | 0     \n",
      "1  | model                                                             | EncoderPredictor       | 48.6 K\n",
      "2  | model.inp_query_layer                                             | Sequential             | 319   \n",
      "3  | model.inp_query_layer.scaled_embed                                | ScaledEmbedding        | 198   \n",
      "4  | model.inp_query_layer.scaled_embed.embedding                      | Embedding              | 198   \n",
      "5  | model.inp_query_layer.position_encoder                            | LearnedPositionEncoder | 121   \n",
      "6  | model.inp_query_layer.embed_dropout                               | Dropout                | 0     \n",
      "7  | model.inp_key_layer                                               | Sequential             | 319   \n",
      "8  | model.query_encoder                                               | Encoder                | 24.1 K\n",
      "9  | model.query_encoder.encoder_layers                                | ModuleList             | 24.1 K\n",
      "10 | model.query_encoder.encoder_layers.0                              | EncoderLayer           | 24.1 K\n",
      "11 | model.query_encoder.encoder_layers.0.poswise_ff                   | Positiontwise_FF       | 23.6 K\n",
      "12 | model.query_encoder.encoder_layers.0.poswise_ff.linear1           | Linear                 | 12.3 K\n",
      "13 | model.query_encoder.encoder_layers.0.poswise_ff.linear2           | Linear                 | 11.3 K\n",
      "14 | model.query_encoder.encoder_layers.0.self_attn                    | MultiHeadAttention     | 528   \n",
      "15 | model.query_encoder.encoder_layers.0.self_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "16 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO   | ModuleList             | 528   \n",
      "17 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.0 | Linear                 | 132   \n",
      "18 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.1 | Linear                 | 132   \n",
      "19 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.2 | Linear                 | 132   \n",
      "20 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.3 | Linear                 | 132   \n",
      "21 | model.query_encoder.encoder_layers.0.layer_norms                  | ModuleList             | 44    \n",
      "22 | model.query_encoder.encoder_layers.0.layer_norms.0                | LayerNorm              | 22    \n",
      "23 | model.query_encoder.encoder_layers.0.layer_norms.1                | LayerNorm              | 22    \n",
      "24 | model.query_encoder.encoder_layers.0.heads_dropout                | Dropout                | 0     \n",
      "25 | model.query_encoder.encoder_layers.0.pff_dropout                  | Dropout                | 0     \n",
      "26 | model.key_encoder                                                 | Encoder                | 24.1 K\n",
      "27 | model.key_encoder.encoder_layers                                  | ModuleList             | 24.1 K\n",
      "28 | model.key_encoder.encoder_layers.0                                | EncoderLayer           | 24.1 K\n",
      "29 | model.key_encoder.encoder_layers.0.poswise_ff                     | Positiontwise_FF       | 23.6 K\n",
      "30 | model.key_encoder.encoder_layers.0.poswise_ff.linear1             | Linear                 | 12.3 K\n",
      "31 | model.key_encoder.encoder_layers.0.poswise_ff.linear2             | Linear                 | 11.3 K\n",
      "32 | model.key_encoder.encoder_layers.0.self_attn                      | MultiHeadAttention     | 528   \n",
      "33 | model.key_encoder.encoder_layers.0.self_attn.attn_wt_dropout      | Dropout                | 0     \n",
      "34 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO     | ModuleList             | 528   \n",
      "35 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.0   | Linear                 | 132   \n",
      "36 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.1   | Linear                 | 132   \n",
      "37 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.2   | Linear                 | 132   \n",
      "38 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.3   | Linear                 | 132   \n",
      "39 | model.key_encoder.encoder_layers.0.layer_norms                    | ModuleList             | 44    \n",
      "40 | model.key_encoder.encoder_layers.0.layer_norms.0                  | LayerNorm              | 22    \n",
      "41 | model.key_encoder.encoder_layers.0.layer_norms.1                  | LayerNorm              | 22    \n",
      "42 | model.key_encoder.encoder_layers.0.heads_dropout                  | Dropout                | 0     \n",
      "43 | model.key_encoder.encoder_layers.0.pff_dropout                    | Dropout                | 0     \n",
      "44 | CE_criterion                                                      | CELoss                 | 0     \n",
      "45 | CE_criterion.CE_loss                                              | CrossEntropyLoss       | 0     \n",
      "46 | loss_criterion                                                    | InfoCELoss             | 0     \n",
      "47 | loss_criterion.CE_loss                                            | CrossEntropyLoss       | 0     \n",
      "48 | softmax                                                           | Softmax                | 0     \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "48.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.6 K    Total params\n",
      "0.194     Total estimated model params size (MB) \n",
      "\n",
      "RUN NAME :\n",
      " SET;attr1-val10-nest1;contrastive;embedByProperty;d_model11;dot-product;params48.59K\n",
      "Continue training? (y/n)y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Checkpoint directory checkpoints/ContrastiveLearning-cardgame-Debug-Shattering/20210304-204003-SET;attr1-val10-nest1;contrastive;embedByProperty;d_model11;dot-product;params48.59K exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Path:\n",
      " checkpoints/ContrastiveLearning-cardgame-Debug-Shattering/20210304-204003-SET;attr1-val10-nest1;contrastive;embedByProperty;d_model11;dot-product;params48.59K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/Contrastive-Learning-Benchmarking/SecondPass-CardGame-experiments/main.py:183: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">SET;attr1-val10-nest1;contrastive;embedByProperty;d_model11;dot-product;params48.59K</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chucooleg/ContrastiveLearning-cardgame-Debug-Shattering\" target=\"_blank\">https://wandb.ai/chucooleg/ContrastiveLearning-cardgame-Debug-Shattering</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chucooleg/ContrastiveLearning-cardgame-Debug-Shattering/runs/1yt1jz5u\" target=\"_blank\">https://wandb.ai/chucooleg/ContrastiveLearning-cardgame-Debug-Shattering/runs/1yt1jz5u</a><br/>\n",
       "                Run data is saved locally in <code>/app/Contrastive-Learning-Benchmarking/SecondPass-CardGame-experiments/wandb/run-20210304_213743-1yt1jz5u</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                                                              | Type                   | Params\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "0  | metrics                                                           | ThresholdedMetrics     | 0     \n",
      "1  | model                                                             | EncoderPredictor       | 48.6 K\n",
      "2  | model.inp_query_layer                                             | Sequential             | 319   \n",
      "3  | model.inp_query_layer.scaled_embed                                | ScaledEmbedding        | 198   \n",
      "4  | model.inp_query_layer.scaled_embed.embedding                      | Embedding              | 198   \n",
      "5  | model.inp_query_layer.position_encoder                            | LearnedPositionEncoder | 121   \n",
      "6  | model.inp_query_layer.embed_dropout                               | Dropout                | 0     \n",
      "7  | model.inp_key_layer                                               | Sequential             | 319   \n",
      "8  | model.query_encoder                                               | Encoder                | 24.1 K\n",
      "9  | model.query_encoder.encoder_layers                                | ModuleList             | 24.1 K\n",
      "10 | model.query_encoder.encoder_layers.0                              | EncoderLayer           | 24.1 K\n",
      "11 | model.query_encoder.encoder_layers.0.poswise_ff                   | Positiontwise_FF       | 23.6 K\n",
      "12 | model.query_encoder.encoder_layers.0.poswise_ff.linear1           | Linear                 | 12.3 K\n",
      "13 | model.query_encoder.encoder_layers.0.poswise_ff.linear2           | Linear                 | 11.3 K\n",
      "14 | model.query_encoder.encoder_layers.0.self_attn                    | MultiHeadAttention     | 528   \n",
      "15 | model.query_encoder.encoder_layers.0.self_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "16 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO   | ModuleList             | 528   \n",
      "17 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.0 | Linear                 | 132   \n",
      "18 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.1 | Linear                 | 132   \n",
      "19 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.2 | Linear                 | 132   \n",
      "20 | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.3 | Linear                 | 132   \n",
      "21 | model.query_encoder.encoder_layers.0.layer_norms                  | ModuleList             | 44    \n",
      "22 | model.query_encoder.encoder_layers.0.layer_norms.0                | LayerNorm              | 22    \n",
      "23 | model.query_encoder.encoder_layers.0.layer_norms.1                | LayerNorm              | 22    \n",
      "24 | model.query_encoder.encoder_layers.0.heads_dropout                | Dropout                | 0     \n",
      "25 | model.query_encoder.encoder_layers.0.pff_dropout                  | Dropout                | 0     \n",
      "26 | model.key_encoder                                                 | Encoder                | 24.1 K\n",
      "27 | model.key_encoder.encoder_layers                                  | ModuleList             | 24.1 K\n",
      "28 | model.key_encoder.encoder_layers.0                                | EncoderLayer           | 24.1 K\n",
      "29 | model.key_encoder.encoder_layers.0.poswise_ff                     | Positiontwise_FF       | 23.6 K\n",
      "30 | model.key_encoder.encoder_layers.0.poswise_ff.linear1             | Linear                 | 12.3 K\n",
      "31 | model.key_encoder.encoder_layers.0.poswise_ff.linear2             | Linear                 | 11.3 K\n",
      "32 | model.key_encoder.encoder_layers.0.self_attn                      | MultiHeadAttention     | 528   \n",
      "33 | model.key_encoder.encoder_layers.0.self_attn.attn_wt_dropout      | Dropout                | 0     \n",
      "34 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO     | ModuleList             | 528   \n",
      "35 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.0   | Linear                 | 132   \n",
      "36 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.1   | Linear                 | 132   \n",
      "37 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.2   | Linear                 | 132   \n",
      "38 | model.key_encoder.encoder_layers.0.self_attn.projections_QKVO.3   | Linear                 | 132   \n",
      "39 | model.key_encoder.encoder_layers.0.layer_norms                    | ModuleList             | 44    \n",
      "40 | model.key_encoder.encoder_layers.0.layer_norms.0                  | LayerNorm              | 22    \n",
      "41 | model.key_encoder.encoder_layers.0.layer_norms.1                  | LayerNorm              | 22    \n",
      "42 | model.key_encoder.encoder_layers.0.heads_dropout                  | Dropout                | 0     \n",
      "43 | model.key_encoder.encoder_layers.0.pff_dropout                    | Dropout                | 0     \n",
      "44 | CE_criterion                                                      | CELoss                 | 0     \n",
      "45 | CE_criterion.CE_loss                                              | CrossEntropyLoss       | 0     \n",
      "46 | loss_criterion                                                    | InfoCELoss             | 0     \n",
      "47 | loss_criterion.CE_loss                                            | CrossEntropyLoss       | 0     \n",
      "48 | softmax                                                           | Softmax                | 0     \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "48.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.6 K    Total params\n",
      "0.194     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/app/Contrastive-Learning-Benchmarking/SecondPass-CardGame-experiments/dataset.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt_binary_tensor = torch.tensor(gt_binary).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▍         | 1/22 [00:00<00:03,  6.67it/s]               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/torch/cuda/memory.py:231: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: RuntimeWarning: You are using `LearningRateMonitor` callback with models that have no learning rate schedulers. Please see documentation for `configure_optimizers` method.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 11/22 [00:01<00:01,  8.79it/s, loss=2.78e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 17/22 [00:01<00:00, 12.39it/s, loss=2.78e+03, v_num=jz5u]\n",
      "Epoch 0: 100%|██████████| 22/22 [00:01<00:00, 14.73it/s, loss=2.78e+03, v_num=jz5u]\n",
      "Epoch 1:  55%|█████▍    | 12/22 [00:01<00:01,  9.70it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 18/22 [00:01<00:00, 12.95it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 1: 100%|██████████| 22/22 [00:01<00:00, 14.85it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 2:  55%|█████▍    | 12/22 [00:01<00:01,  9.73it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 18/22 [00:01<00:00, 13.03it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 2: 100%|██████████| 22/22 [00:01<00:00, 14.75it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 3:  55%|█████▍    | 12/22 [00:01<00:01,  9.36it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 18/22 [00:01<00:00, 12.68it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 3: 100%|██████████| 22/22 [00:01<00:00, 13.98it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 4:  55%|█████▍    | 12/22 [00:01<00:01,  9.40it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 18/22 [00:01<00:00, 12.75it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 4: 100%|██████████| 22/22 [00:01<00:00, 14.62it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 5:  55%|█████▍    | 12/22 [00:01<00:00, 10.03it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 18/22 [00:01<00:00, 13.54it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 5: 100%|██████████| 22/22 [00:01<00:00, 15.47it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 6:  55%|█████▍    | 12/22 [00:01<00:00, 10.30it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 18/22 [00:01<00:00, 13.87it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 6: 100%|██████████| 22/22 [00:01<00:00, 15.84it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 7:  55%|█████▍    | 12/22 [00:01<00:01,  9.91it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 18/22 [00:01<00:00, 12.77it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 7: 100%|██████████| 22/22 [00:01<00:00, 14.56it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 8:  55%|█████▍    | 12/22 [00:01<00:01,  9.88it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 18/22 [00:01<00:00, 13.33it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 8: 100%|██████████| 22/22 [00:01<00:00, 15.21it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 9:  55%|█████▍    | 12/22 [00:01<00:01,  7.46it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 18/22 [00:01<00:00, 10.23it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 9: 100%|██████████| 22/22 [00:01<00:00, 11.87it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 10:  55%|█████▍    | 12/22 [00:01<00:01,  9.07it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 18/22 [00:01<00:00, 11.61it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 10: 100%|██████████| 22/22 [00:01<00:00, 13.17it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 11:  55%|█████▍    | 12/22 [00:01<00:00, 10.19it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 18/22 [00:01<00:00, 13.66it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 11: 100%|██████████| 22/22 [00:01<00:00, 15.41it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 12:  55%|█████▍    | 12/22 [00:01<00:01,  9.91it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 18/22 [00:01<00:00, 12.87it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 12: 100%|██████████| 22/22 [00:01<00:00, 14.76it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 13:  55%|█████▍    | 12/22 [00:01<00:01,  9.14it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  82%|████████▏ | 18/22 [00:01<00:00, 12.45it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 13: 100%|██████████| 22/22 [00:01<00:00, 14.31it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 14:  55%|█████▍    | 12/22 [00:01<00:01,  8.97it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  82%|████████▏ | 18/22 [00:01<00:00, 12.01it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 14: 100%|██████████| 22/22 [00:01<00:00, 13.69it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 15:  55%|█████▍    | 12/22 [00:01<00:01,  9.66it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  82%|████████▏ | 18/22 [00:01<00:00, 12.88it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating:  73%|███████▎  | 8/11 [00:00<00:00, 39.71it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 22/22 [00:01<00:00, 14.14it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 16:  55%|█████▍    | 12/22 [00:01<00:00, 10.00it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  82%|████████▏ | 18/22 [00:01<00:00, 13.48it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 16: 100%|██████████| 22/22 [00:01<00:00, 15.36it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 17:  55%|█████▍    | 12/22 [00:01<00:00, 10.29it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  82%|████████▏ | 18/22 [00:01<00:00, 13.71it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 17: 100%|██████████| 22/22 [00:01<00:00, 15.51it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 18:  55%|█████▍    | 12/22 [00:01<00:01,  8.42it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  82%|████████▏ | 18/22 [00:01<00:00, 11.55it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 18: 100%|██████████| 22/22 [00:01<00:00, 13.30it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 19:  55%|█████▍    | 12/22 [00:01<00:01,  9.77it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  82%|████████▏ | 18/22 [00:01<00:00, 13.20it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 19: 100%|██████████| 22/22 [00:01<00:00, 15.11it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 20:  55%|█████▍    | 12/22 [00:01<00:00, 10.33it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  82%|████████▏ | 18/22 [00:01<00:00, 13.88it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 20: 100%|██████████| 22/22 [00:01<00:00, 15.83it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 21:  55%|█████▍    | 12/22 [00:01<00:01,  9.98it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  82%|████████▏ | 18/22 [00:01<00:00, 13.37it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 21: 100%|██████████| 22/22 [00:01<00:00, 15.27it/s, loss=2.75e+03, v_num=jz5u]\n",
      "Epoch 22:  36%|███▋      | 8/22 [00:00<00:01,  9.07it/s, loss=2.75e+03, v_num=jz5u] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  36%|███▋      | 8/22 [00:01<00:01,  7.45it/s, loss=2.75e+03, v_num=jz5u]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ContrastiveTrainModule(\n",
       "   (metrics): ThresholdedMetrics()\n",
       "   (model): EncoderPredictor(\n",
       "     (inp_query_layer): Sequential(\n",
       "       (scaled_embed): ScaledEmbedding(\n",
       "         (embedding): Embedding(18, 11)\n",
       "       )\n",
       "       (position_encoder): LearnedPositionEncoder()\n",
       "       (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (inp_key_layer): Sequential(\n",
       "       (scaled_embed): ScaledEmbedding(\n",
       "         (embedding): Embedding(18, 11)\n",
       "       )\n",
       "       (position_encoder): LearnedPositionEncoder()\n",
       "       (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (query_encoder): Encoder(\n",
       "       (encoder_layers): ModuleList(\n",
       "         (0): EncoderLayer(\n",
       "           (poswise_ff): Positiontwise_FF(\n",
       "             (linear1): Linear(in_features=11, out_features=1024, bias=True)\n",
       "             (linear2): Linear(in_features=1024, out_features=11, bias=True)\n",
       "           )\n",
       "           (self_attn): MultiHeadAttention(\n",
       "             (attn_wt_dropout): Dropout(p=0.0, inplace=False)\n",
       "             (projections_QKVO): ModuleList(\n",
       "               (0): Linear(in_features=11, out_features=11, bias=True)\n",
       "               (1): Linear(in_features=11, out_features=11, bias=True)\n",
       "               (2): Linear(in_features=11, out_features=11, bias=True)\n",
       "               (3): Linear(in_features=11, out_features=11, bias=True)\n",
       "             )\n",
       "           )\n",
       "           (layer_norms): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "             (1): LayerNorm()\n",
       "           )\n",
       "           (heads_dropout): Dropout(p=0.0, inplace=False)\n",
       "           (pff_dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (key_encoder): Encoder(\n",
       "       (encoder_layers): ModuleList(\n",
       "         (0): EncoderLayer(\n",
       "           (poswise_ff): Positiontwise_FF(\n",
       "             (linear1): Linear(in_features=11, out_features=1024, bias=True)\n",
       "             (linear2): Linear(in_features=1024, out_features=11, bias=True)\n",
       "           )\n",
       "           (self_attn): MultiHeadAttention(\n",
       "             (attn_wt_dropout): Dropout(p=0.0, inplace=False)\n",
       "             (projections_QKVO): ModuleList(\n",
       "               (0): Linear(in_features=11, out_features=11, bias=True)\n",
       "               (1): Linear(in_features=11, out_features=11, bias=True)\n",
       "               (2): Linear(in_features=11, out_features=11, bias=True)\n",
       "               (3): Linear(in_features=11, out_features=11, bias=True)\n",
       "             )\n",
       "           )\n",
       "           (layer_norms): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "             (1): LayerNorm()\n",
       "           )\n",
       "           (heads_dropout): Dropout(p=0.0, inplace=False)\n",
       "           (pff_dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (CE_criterion): CELoss(\n",
       "     (CE_loss): CrossEntropyLoss()\n",
       "   )\n",
       "   (loss_criterion): InfoCELoss(\n",
       "     (CE_loss): CrossEntropyLoss()\n",
       "   )\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " <datamodule.GameDataModule at 0x7f9bd2f2a820>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log LR\n",
    "# and implement lr decay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
