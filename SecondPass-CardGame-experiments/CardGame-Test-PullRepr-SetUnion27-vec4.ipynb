{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "general-tribe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.8.3 (default, May 19 2020, 18:47:26) \n",
      "[GCC 7.3.0]\n",
      "__pyTorch VERSION: 1.7.0\n",
      "__CUDA VERSION\n",
      "/usr/bin/sh: 1: nvcc: not found\n",
      "__CUDNN VERSION: 8003\n",
      "__Number CUDA Devices: 2\n",
      "__Devices\n",
      "Active CUDA Device: GPU 1\n",
      "Available devices  2\n",
      "Current cuda device  1\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/i-have-3-gpu-why-torch-cuda-device-count-only-return-1/7245/4\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "solar-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import main\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "handmade-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.project_name = 'ContrastiveLearning-SET-Wildcard-Expand-Union-27'\n",
    "args.data_path = '../Raw_Datasets/SET/WildCardSETidxUnion-3Attr-3Vals-8Pairs-0Train-5120Val-5120Test.json'\n",
    "args.mode = 'test'\n",
    "args.resume_checkpoint_dir = (\n",
    "    'checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210401-160755-Con;Vec4;L8H8Lk4Hk2;scheduledAdamW36000;16871.56Kparams_runId_3aw2kmru')\n",
    "args.ckpt_name = 'last.ckpt'\n",
    "args.runID = '3aw2kmru'\n",
    "args.gpu = 1\n",
    "args.approve_before_training = False\n",
    "args.aml = False\n",
    "args.dataset_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "particular-remedy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "key_support_size : 27\n",
      "N_pairs : 8\n",
      "union_only : True\n",
      "max_len_q : 16\n",
      "len_k : 1\n",
      "train_gt_idxs length : 0\n",
      "val_gt_idxs length : 5120\n",
      "test_gt_idxs length : 5120\n",
      "train_tokens length : 0\n",
      "val_tokens length : 5120\n",
      "test_tokens length : 5120\n",
      "test_marginal_gt_idxs length : 5120\n",
      "test_marginal_tokens length : 5120\n",
      "vocab_size : 74\n",
      "symbol_vocab_token_lookup : {'(': 64, ')': 65, 'NULL': 66, 'SEP': 67, 'SOS': 68, 'EOS': 69, 'PAD': 70, 'PLH': 71, '|': 72, '!': 73}\n",
      "vocab_by_property : False\n",
      "-----------------------\n",
      "----------hparams----------\n",
      "seed : 42\n",
      "batch_size : 1024\n",
      "max_epochs : 20000000000\n",
      "val_every_n_epoch : 200\n",
      "d_model : 512\n",
      "embed_dropout : 0.0\n",
      "vec_repr : 4\n",
      "model : contrastive\n",
      "d_ff : 1024\n",
      "N_enc : 8\n",
      "num_heads : 8\n",
      "N_enc_key : 4\n",
      "num_heads_key : 2\n",
      "attn_wt_tying_scheme : untie_QKVO\n",
      "attn_wt_dropout : 0.0\n",
      "heads_dropout : 0.0\n",
      "pff_dropout : 0.0\n",
      "representation_pos : 0\n",
      "dotproduct_bottleneck : True\n",
      "normalize_dotproduct : False\n",
      "contrastive_use_infoNCE : True\n",
      "loss_temperature_const : 1.0\n",
      "loss_smoothing_const : 0.1\n",
      "nonlinear_classifier_scale_down_factor : [1, 1, 1]\n",
      "contrastive_optimizer : scheduled_adam\n",
      "cosine_annealing_T_max : 30\n",
      "adam_lr : 1e-05\n",
      "adam_beta1 : 0.9\n",
      "adam_beta2 : 0.999\n",
      "adam_epsilon : 1e-08\n",
      "adam_weight_decay : 0\n",
      "sgd_lr : 0.001\n",
      "sgd_momentum : 0\n",
      "scheduled_adam_beta1 : 0.9\n",
      "scheduled_adam_beta2 : 0.98\n",
      "scheduled_adam_epsilon : 1e-06\n",
      "scheduled_adam_warmup_steps : 36000\n",
      "additional_lr_decay : False\n",
      "additional_lr_decay_gamma : 0.9\n",
      "decay_lr_starts : 36000\n",
      "decay_lr_stops : 300000\n",
      "decay_lr_interval : 2000\n",
      "generative_overall_lr_scale : 1.0\n",
      "contrastive_overall_lr_scale : 1.0\n",
      "gradient_clip_val : 0.0\n",
      "debug : False\n",
      "extra_monitors : False\n",
      "mode : test\n",
      "key_support_size : 27\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "union_only : True\n",
      "vocab_size : 74\n",
      "vocab_by_property : False\n",
      "( : 64\n",
      ") : 65\n",
      "NULL : 66\n",
      "SEP : 67\n",
      "SOS : 68\n",
      "EOS : 69\n",
      "PAD : 70\n",
      "PLH : 71\n",
      "| : 72\n",
      "! : 73\n",
      "max_len_q : 16\n",
      "N_pairs : 8\n",
      "len_k : 1\n",
      "resume_checkpoint_dir : checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210401-160755-Con;Vec4;L8H8Lk4Hk2;scheduledAdamW36000;16871.56Kparams_runId_3aw2kmru\n",
      "---------------------------\n",
      "    | Name                                                              | Type                    | Params\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "0   | metrics                                                           | ThresholdedMetrics      | 0     \n",
      "1   | KLdiv_criterion                                                   | KLdivLoss               | 0     \n",
      "2   | KLdiv_criterion.KLdiv_criterion                                   | KLDivLoss               | 0     \n",
      "3   | KLdiv_criterion.KLdiv_criterion_full                              | KLDivLoss               | 0     \n",
      "4   | KLdiv_criterion.logprob                                           | LogSoftmax              | 0     \n",
      "5   | model                                                             | EncoderPredictor        | 16.9 M\n",
      "6   | model.inp_query_layer                                             | Sequential              | 47.1 K\n",
      "7   | model.inp_query_layer.scaled_embed                                | ScaledEmbedding         | 37.9 K\n",
      "8   | model.inp_query_layer.scaled_embed.embedding                      | Embedding               | 37.9 K\n",
      "9   | model.inp_query_layer.position_encoder                            | LearnedPositionEncoder  | 9.2 K \n",
      "10  | model.inp_query_layer.embed_dropout                               | Dropout                 | 0     \n",
      "11  | model.inp_key_layer                                               | Sequential              | 108   \n",
      "12  | model.inp_key_layer.scaled_embed                                  | ScaledEmbedding         | 108   \n",
      "13  | model.inp_key_layer.scaled_embed.embedding                        | Embedding               | 108   \n",
      "14  | model.query_encoder                                               | Encoder                 | 16.8 M\n",
      "15  | model.query_encoder.encoder_layers                                | ModuleList              | 16.8 M\n",
      "16  | model.query_encoder.encoder_layers.0                              | EncoderLayer            | 2.1 M \n",
      "17  | model.query_encoder.encoder_layers.0.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "18  | model.query_encoder.encoder_layers.0.poswise_ff.linear1           | Linear                  | 525 K \n",
      "19  | model.query_encoder.encoder_layers.0.poswise_ff.linear2           | Linear                  | 524 K \n",
      "20  | model.query_encoder.encoder_layers.0.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "21  | model.query_encoder.encoder_layers.0.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "22  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "23  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "24  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "25  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "26  | model.query_encoder.encoder_layers.0.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "27  | model.query_encoder.encoder_layers.0.layer_norms                  | ModuleList              | 2.0 K \n",
      "28  | model.query_encoder.encoder_layers.0.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "29  | model.query_encoder.encoder_layers.0.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "30  | model.query_encoder.encoder_layers.0.heads_dropout                | Dropout                 | 0     \n",
      "31  | model.query_encoder.encoder_layers.0.pff_dropout                  | Dropout                 | 0     \n",
      "32  | model.query_encoder.encoder_layers.1                              | EncoderLayer            | 2.1 M \n",
      "33  | model.query_encoder.encoder_layers.1.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "34  | model.query_encoder.encoder_layers.1.poswise_ff.linear1           | Linear                  | 525 K \n",
      "35  | model.query_encoder.encoder_layers.1.poswise_ff.linear2           | Linear                  | 524 K \n",
      "36  | model.query_encoder.encoder_layers.1.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "37  | model.query_encoder.encoder_layers.1.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "38  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "39  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "40  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "41  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "42  | model.query_encoder.encoder_layers.1.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "43  | model.query_encoder.encoder_layers.1.layer_norms                  | ModuleList              | 2.0 K \n",
      "44  | model.query_encoder.encoder_layers.1.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "45  | model.query_encoder.encoder_layers.1.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "46  | model.query_encoder.encoder_layers.1.heads_dropout                | Dropout                 | 0     \n",
      "47  | model.query_encoder.encoder_layers.1.pff_dropout                  | Dropout                 | 0     \n",
      "48  | model.query_encoder.encoder_layers.2                              | EncoderLayer            | 2.1 M \n",
      "49  | model.query_encoder.encoder_layers.2.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "50  | model.query_encoder.encoder_layers.2.poswise_ff.linear1           | Linear                  | 525 K \n",
      "51  | model.query_encoder.encoder_layers.2.poswise_ff.linear2           | Linear                  | 524 K \n",
      "52  | model.query_encoder.encoder_layers.2.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "53  | model.query_encoder.encoder_layers.2.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "54  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "55  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "56  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "57  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "58  | model.query_encoder.encoder_layers.2.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "59  | model.query_encoder.encoder_layers.2.layer_norms                  | ModuleList              | 2.0 K \n",
      "60  | model.query_encoder.encoder_layers.2.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "61  | model.query_encoder.encoder_layers.2.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "62  | model.query_encoder.encoder_layers.2.heads_dropout                | Dropout                 | 0     \n",
      "63  | model.query_encoder.encoder_layers.2.pff_dropout                  | Dropout                 | 0     \n",
      "64  | model.query_encoder.encoder_layers.3                              | EncoderLayer            | 2.1 M \n",
      "65  | model.query_encoder.encoder_layers.3.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "66  | model.query_encoder.encoder_layers.3.poswise_ff.linear1           | Linear                  | 525 K \n",
      "67  | model.query_encoder.encoder_layers.3.poswise_ff.linear2           | Linear                  | 524 K \n",
      "68  | model.query_encoder.encoder_layers.3.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "69  | model.query_encoder.encoder_layers.3.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "70  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "71  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "72  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "73  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "74  | model.query_encoder.encoder_layers.3.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "75  | model.query_encoder.encoder_layers.3.layer_norms                  | ModuleList              | 2.0 K \n",
      "76  | model.query_encoder.encoder_layers.3.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "77  | model.query_encoder.encoder_layers.3.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "78  | model.query_encoder.encoder_layers.3.heads_dropout                | Dropout                 | 0     \n",
      "79  | model.query_encoder.encoder_layers.3.pff_dropout                  | Dropout                 | 0     \n",
      "80  | model.query_encoder.encoder_layers.4                              | EncoderLayer            | 2.1 M \n",
      "81  | model.query_encoder.encoder_layers.4.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "82  | model.query_encoder.encoder_layers.4.poswise_ff.linear1           | Linear                  | 525 K \n",
      "83  | model.query_encoder.encoder_layers.4.poswise_ff.linear2           | Linear                  | 524 K \n",
      "84  | model.query_encoder.encoder_layers.4.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "85  | model.query_encoder.encoder_layers.4.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "86  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "87  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "88  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "89  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "90  | model.query_encoder.encoder_layers.4.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "91  | model.query_encoder.encoder_layers.4.layer_norms                  | ModuleList              | 2.0 K \n",
      "92  | model.query_encoder.encoder_layers.4.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "93  | model.query_encoder.encoder_layers.4.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "94  | model.query_encoder.encoder_layers.4.heads_dropout                | Dropout                 | 0     \n",
      "95  | model.query_encoder.encoder_layers.4.pff_dropout                  | Dropout                 | 0     \n",
      "96  | model.query_encoder.encoder_layers.5                              | EncoderLayer            | 2.1 M \n",
      "97  | model.query_encoder.encoder_layers.5.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "98  | model.query_encoder.encoder_layers.5.poswise_ff.linear1           | Linear                  | 525 K \n",
      "99  | model.query_encoder.encoder_layers.5.poswise_ff.linear2           | Linear                  | 524 K \n",
      "100 | model.query_encoder.encoder_layers.5.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "101 | model.query_encoder.encoder_layers.5.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "102 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "103 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "104 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "105 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "106 | model.query_encoder.encoder_layers.5.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "107 | model.query_encoder.encoder_layers.5.layer_norms                  | ModuleList              | 2.0 K \n",
      "108 | model.query_encoder.encoder_layers.5.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "109 | model.query_encoder.encoder_layers.5.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "110 | model.query_encoder.encoder_layers.5.heads_dropout                | Dropout                 | 0     \n",
      "111 | model.query_encoder.encoder_layers.5.pff_dropout                  | Dropout                 | 0     \n",
      "112 | model.query_encoder.encoder_layers.6                              | EncoderLayer            | 2.1 M \n",
      "113 | model.query_encoder.encoder_layers.6.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "114 | model.query_encoder.encoder_layers.6.poswise_ff.linear1           | Linear                  | 525 K \n",
      "115 | model.query_encoder.encoder_layers.6.poswise_ff.linear2           | Linear                  | 524 K \n",
      "116 | model.query_encoder.encoder_layers.6.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "117 | model.query_encoder.encoder_layers.6.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "118 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "119 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "120 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "121 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "122 | model.query_encoder.encoder_layers.6.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "123 | model.query_encoder.encoder_layers.6.layer_norms                  | ModuleList              | 2.0 K \n",
      "124 | model.query_encoder.encoder_layers.6.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "125 | model.query_encoder.encoder_layers.6.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "126 | model.query_encoder.encoder_layers.6.heads_dropout                | Dropout                 | 0     \n",
      "127 | model.query_encoder.encoder_layers.6.pff_dropout                  | Dropout                 | 0     \n",
      "128 | model.query_encoder.encoder_layers.7                              | EncoderLayer            | 2.1 M \n",
      "129 | model.query_encoder.encoder_layers.7.poswise_ff                   | Positiontwise_FF        | 1.1 M \n",
      "130 | model.query_encoder.encoder_layers.7.poswise_ff.linear1           | Linear                  | 525 K \n",
      "131 | model.query_encoder.encoder_layers.7.poswise_ff.linear2           | Linear                  | 524 K \n",
      "132 | model.query_encoder.encoder_layers.7.self_attn                    | MultiHeadAttention      | 1.1 M \n",
      "133 | model.query_encoder.encoder_layers.7.self_attn.attn_wt_dropout    | Dropout                 | 0     \n",
      "134 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO   | ModuleList              | 1.1 M \n",
      "135 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.0 | Linear                  | 262 K \n",
      "136 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.1 | Linear                  | 262 K \n",
      "137 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.2 | Linear                  | 262 K \n",
      "138 | model.query_encoder.encoder_layers.7.self_attn.projections_QKVO.3 | Linear                  | 262 K \n",
      "139 | model.query_encoder.encoder_layers.7.layer_norms                  | ModuleList              | 2.0 K \n",
      "140 | model.query_encoder.encoder_layers.7.layer_norms.0                | LayerNorm               | 1.0 K \n",
      "141 | model.query_encoder.encoder_layers.7.layer_norms.1                | LayerNorm               | 1.0 K \n",
      "142 | model.query_encoder.encoder_layers.7.heads_dropout                | Dropout                 | 0     \n",
      "143 | model.query_encoder.encoder_layers.7.pff_dropout                  | Dropout                 | 0     \n",
      "144 | model.query_projection                                            | Linear                  | 2.1 K \n",
      "145 | CE_criterion                                                      | CELoss                  | 0     \n",
      "146 | CE_criterion.CE_loss                                              | CrossEntropyLoss        | 0     \n",
      "147 | loss_criterion                                                    | InfoCELoss              | 0     \n",
      "148 | loss_criterion.CE_loss                                            | CrossEntropyLoss        | 0     \n",
      "149 | debug_metrics                                                     | ContrastiveDebugMetrics | 0     \n",
      "150 | softmax                                                           | Softmax                 | 0     \n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "16.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.9 M    Total params\n",
      "67.486    Total estimated model params size (MB) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN NAME :\n",
      " Con;Vec4;L8H8Lk4Hk2;scheduledAdamW36000;16871.56Kparams\n",
      "Resuming From and Saving to Checkpoint Path:\n",
      " checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210401-160755-Con;Vec4;L8H8Lk4Hk2;scheduledAdamW36000;16871.56Kparams_runId_3aw2kmru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 5/5 [00:04<00:00,  1.24it/s]{0.2977279722690582, 0.6298671364784241, 0.6890408396720886, 0.9075267910957336, 0.7316441535949707, 0.9100871086120605, 0.6233341097831726, 0.7398847937583923, 5.24666690826416, 7.103480815887451, 8.242130279541016, 11.512972831726074, 12.5045804977417, 13.675265312194824, 10.288473129272461, 15.993766784667969, 9.161714553833008, 17.194751739501953, 14.931619644165039, 19.732831954956055, 18.529630661010742, 21.006927490234375, 22.60555648803711, 23.84492301940918, 16.153593063354492, 25.200000762939453, 5.126667022705078, 27.0, 5.912381172180176, 5.720000267028809, 0.03726695105433464, 6.091323375701904, 6.912744998931885, 0.04374265298247337, 0.03703700006008148, 0.03970102593302727, 7.6533331871032715, 7.395744323730469, 0.044832345098257065, 0.052808430045843124, 0.041113801300525665, 8.787619590759277, 8.108551025390625, 8.5747709274292, 0.025698412209749222, 9.6204252243042, 9.946065902709961, 9.43868637084961, 0.841160750800946, 10.197443008422852, 10.701904296875, 10.039999961853027, 10.766988754272461, 10.209938049316406, 11.692594528198242, 11.418886184692383, 11.660685539245605, 11.891379356384277, 11.604361534118652, 11.783905982971191, 12.376303672790527, 11.809392929077148, 11.592744827270508, 11.010527610778809, 12.949853897094727, 12.585844993591309, 13.88166332244873, 13.884126663208008, 13.531305313110352, 13.665908813476562, 14.476117134094238, 14.294761657714844, 14.75, 13.829363822937012, 14.309887886047363, 14.24476146697998, 14.699999809265137, 0.025315484032034874, 0.025846248492598534, 0.026105446740984917, 0.028788579627871513, 0.025286151096224785, 0.025640053674578667, 0.04992803558707237, 0.041909318417310715, 0.04877867549657822, 0.04598966985940933, 0.04668007045984268, 0.038378264755010605, 0.03893818333745003, 0.04748646169900894, 0.05105941370129585, 0.04291248321533203, 1024.0, 0.027643729001283646, 0.02817447856068611, 0.037779662758111954, 0.06282948702573776, nan, 0.027334004640579224, 0.027754202485084534, 11.675080299377441, 11.656554222106934, 11.048436164855957, 11.95541000366211, 11.865683555603027, 11.122058868408203, 11.8134126663208, 0.040293317288160324, 0.025465358048677444, 304.8734436035156, 12.13027286529541, 13.088316917419434, 0.02915133908390999, 0.02665223553776741, 0.025637486949563026, 0.02630721963942051, 0.02617705799639225, 0.03105924464762211, 0.025389153510332108}\n",
      "Also saved to : checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210401-160755-Con;Vec4;L8H8Lk4Hk2;scheduledAdamW36000;16871.56Kparams_runId_3aw2kmru/test_metrics.json\n",
      "Testing: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_batch_size': 1024.0,\n",
      " 'avg_test_KL_loss': 304.8734436035156,\n",
      " 'avg_test_KL_loss_per_example': 0.2977279722690582,\n",
      " 'avg_test_accuracy_by_Query': 0.6890408396720886,\n",
      " 'avg_test_accuracy_by_QueryKey': 0.6890408396720886,\n",
      " 'avg_test_f1_by_Query': 0.7316441535949707,\n",
      " 'avg_test_f1_by_QueryKey': 0.7398847937583923,\n",
      " 'avg_test_gt10;gt_logits_above_threshold_count': 6.912744998931885,\n",
      " 'avg_test_gt10;gt_pred_scores': 0.05105941370129585,\n",
      " 'avg_test_gt10;not_gt_pred_scores': 0.028788579627871513,\n",
      " 'avg_test_gt10;top10_overlap_count': 6.091323375701904,\n",
      " 'avg_test_gt10;top10_pred_above_threshold_count': 9.6204252243042,\n",
      " 'avg_test_gt10;total_pred_above_threshold_count': 11.783905982971191,\n",
      " 'avg_test_gt11;gt_logits_above_threshold_count': 7.395744323730469,\n",
      " 'avg_test_gt11;gt_pred_scores': 0.04992803558707237,\n",
      " 'avg_test_gt11;not_gt_pred_scores': 0.02817447856068611,\n",
      " 'avg_test_gt11;top11_overlap_count': 7.103480815887451,\n",
      " 'avg_test_gt11;top11_pred_above_threshold_count': 10.197443008422852,\n",
      " 'avg_test_gt11;total_pred_above_threshold_count': 11.418886184692383,\n",
      " 'avg_test_gt12;gt_logits_above_threshold_count': 8.108551025390625,\n",
      " 'avg_test_gt12;gt_pred_scores': 0.04877867549657822,\n",
      " 'avg_test_gt12;not_gt_pred_scores': 0.027643729001283646,\n",
      " 'avg_test_gt12;top12_overlap_count': 8.242130279541016,\n",
      " 'avg_test_gt12;top12_pred_above_threshold_count': 11.010527610778809,\n",
      " 'avg_test_gt12;total_pred_above_threshold_count': 11.660685539245605,\n",
      " 'avg_test_gt13;gt_logits_above_threshold_count': 8.5747709274292,\n",
      " 'avg_test_gt13;gt_pred_scores': 0.04748646169900894,\n",
      " 'avg_test_gt13;not_gt_pred_scores': 0.027334004640579224,\n",
      " 'avg_test_gt13;top13_overlap_count': 9.161714553833008,\n",
      " 'avg_test_gt13;top13_pred_above_threshold_count': 11.048436164855957,\n",
      " 'avg_test_gt13;total_pred_above_threshold_count': 11.604361534118652,\n",
      " 'avg_test_gt14;gt_logits_above_threshold_count': 9.43868637084961,\n",
      " 'avg_test_gt14;gt_pred_scores': 0.04668007045984268,\n",
      " 'avg_test_gt14;not_gt_pred_scores': 0.02665223553776741,\n",
      " 'avg_test_gt14;top14_overlap_count': 10.288473129272461,\n",
      " 'avg_test_gt14;top14_pred_above_threshold_count': 11.656554222106934,\n",
      " 'avg_test_gt14;total_pred_above_threshold_count': 12.13027286529541,\n",
      " 'avg_test_gt15;gt_logits_above_threshold_count': 9.946065902709961,\n",
      " 'avg_test_gt15;gt_pred_scores': 0.04598966985940933,\n",
      " 'avg_test_gt15;not_gt_pred_scores': 0.025846248492598534,\n",
      " 'avg_test_gt15;top15_overlap_count': 11.512972831726074,\n",
      " 'avg_test_gt15;top15_pred_above_threshold_count': 11.675080299377441,\n",
      " 'avg_test_gt15;total_pred_above_threshold_count': 11.891379356384277,\n",
      " 'avg_test_gt16;gt_logits_above_threshold_count': 10.209938049316406,\n",
      " 'avg_test_gt16;gt_pred_scores': 0.044832345098257065,\n",
      " 'avg_test_gt16;not_gt_pred_scores': 0.025698412209749222,\n",
      " 'avg_test_gt16;top16_overlap_count': 12.5045804977417,\n",
      " 'avg_test_gt16;top16_pred_above_threshold_count': 11.592744827270508,\n",
      " 'avg_test_gt16;total_pred_above_threshold_count': 11.692594528198242,\n",
      " 'avg_test_gt17;gt_logits_above_threshold_count': 10.766988754272461,\n",
      " 'avg_test_gt17;gt_pred_scores': 0.04374265298247337,\n",
      " 'avg_test_gt17;not_gt_pred_scores': 0.025637486949563026,\n",
      " 'avg_test_gt17;top17_overlap_count': 13.675265312194824,\n",
      " 'avg_test_gt17;top17_pred_above_threshold_count': 11.809392929077148,\n",
      " 'avg_test_gt17;total_pred_above_threshold_count': 11.865683555603027,\n",
      " 'avg_test_gt18;gt_logits_above_threshold_count': 11.122058868408203,\n",
      " 'avg_test_gt18;gt_pred_scores': 0.04291248321533203,\n",
      " 'avg_test_gt18;not_gt_pred_scores': 0.025286151096224785,\n",
      " 'avg_test_gt18;top18_overlap_count': 14.931619644165039,\n",
      " 'avg_test_gt18;top18_pred_above_threshold_count': 11.95541000366211,\n",
      " 'avg_test_gt18;total_pred_above_threshold_count': 11.95541000366211,\n",
      " 'avg_test_gt19;gt_logits_above_threshold_count': 11.8134126663208,\n",
      " 'avg_test_gt19;gt_pred_scores': 0.041909318417310715,\n",
      " 'avg_test_gt19;not_gt_pred_scores': 0.025465358048677444,\n",
      " 'avg_test_gt19;top19_overlap_count': 15.993766784667969,\n",
      " 'avg_test_gt19;top19_pred_above_threshold_count': 12.585844993591309,\n",
      " 'avg_test_gt19;total_pred_above_threshold_count': 12.585844993591309,\n",
      " 'avg_test_gt20;gt_logits_above_threshold_count': 12.376303672790527,\n",
      " 'avg_test_gt20;gt_pred_scores': 0.041113801300525665,\n",
      " 'avg_test_gt20;not_gt_pred_scores': 0.025389153510332108,\n",
      " 'avg_test_gt20;top20_overlap_count': 17.194751739501953,\n",
      " 'avg_test_gt20;top20_pred_above_threshold_count': 12.949853897094727,\n",
      " 'avg_test_gt20;total_pred_above_threshold_count': 12.949853897094727,\n",
      " 'avg_test_gt21;gt_logits_above_threshold_count': 13.088316917419434,\n",
      " 'avg_test_gt21;gt_pred_scores': 0.040293317288160324,\n",
      " 'avg_test_gt21;not_gt_pred_scores': 0.025640053674578667,\n",
      " 'avg_test_gt21;top21_overlap_count': 18.529630661010742,\n",
      " 'avg_test_gt21;top21_pred_above_threshold_count': 13.531305313110352,\n",
      " 'avg_test_gt21;total_pred_above_threshold_count': 13.531305313110352,\n",
      " 'avg_test_gt22;gt_logits_above_threshold_count': 13.665908813476562,\n",
      " 'avg_test_gt22;gt_pred_scores': 0.03970102593302727,\n",
      " 'avg_test_gt22;not_gt_pred_scores': 0.025315484032034874,\n",
      " 'avg_test_gt22;top22_overlap_count': 19.732831954956055,\n",
      " 'avg_test_gt22;top22_pred_above_threshold_count': 13.88166332244873,\n",
      " 'avg_test_gt22;total_pred_above_threshold_count': 13.88166332244873,\n",
      " 'avg_test_gt23;gt_logits_above_threshold_count': 14.309887886047363,\n",
      " 'avg_test_gt23;gt_pred_scores': 0.03893818333745003,\n",
      " 'avg_test_gt23;not_gt_pred_scores': 0.026105446740984917,\n",
      " 'avg_test_gt23;top23_overlap_count': 21.006927490234375,\n",
      " 'avg_test_gt23;top23_pred_above_threshold_count': 14.476117134094238,\n",
      " 'avg_test_gt23;total_pred_above_threshold_count': 14.476117134094238,\n",
      " 'avg_test_gt24;gt_logits_above_threshold_count': 13.829363822937012,\n",
      " 'avg_test_gt24;gt_pred_scores': 0.038378264755010605,\n",
      " 'avg_test_gt24;not_gt_pred_scores': 0.02630721963942051,\n",
      " 'avg_test_gt24;top24_overlap_count': 22.60555648803711,\n",
      " 'avg_test_gt24;top24_pred_above_threshold_count': 13.884126663208008,\n",
      " 'avg_test_gt24;total_pred_above_threshold_count': 13.884126663208008,\n",
      " 'avg_test_gt25;gt_logits_above_threshold_count': 14.24476146697998,\n",
      " 'avg_test_gt25;gt_pred_scores': 0.037779662758111954,\n",
      " 'avg_test_gt25;not_gt_pred_scores': 0.027754202485084534,\n",
      " 'avg_test_gt25;top25_overlap_count': 23.84492301940918,\n",
      " 'avg_test_gt25;top25_pred_above_threshold_count': 14.294761657714844,\n",
      " 'avg_test_gt25;total_pred_above_threshold_count': 14.294761657714844,\n",
      " 'avg_test_gt26;gt_logits_above_threshold_count': 14.699999809265137,\n",
      " 'avg_test_gt26;gt_pred_scores': 0.03726695105433464,\n",
      " 'avg_test_gt26;not_gt_pred_scores': 0.03105924464762211,\n",
      " 'avg_test_gt26;top26_overlap_count': 25.200000762939453,\n",
      " 'avg_test_gt26;top26_pred_above_threshold_count': 14.75,\n",
      " 'avg_test_gt26;total_pred_above_threshold_count': 14.75,\n",
      " 'avg_test_gt27;gt_logits_above_threshold_count': 16.153593063354492,\n",
      " 'avg_test_gt27;gt_pred_scores': 0.03703700006008148,\n",
      " 'avg_test_gt27;not_gt_pred_scores': nan,\n",
      " 'avg_test_gt27;top27_overlap_count': 27.0,\n",
      " 'avg_test_gt27;top27_pred_above_threshold_count': 16.153593063354492,\n",
      " 'avg_test_gt27;total_pred_above_threshold_count': 16.153593063354492,\n",
      " 'avg_test_gt8;gt_logits_above_threshold_count': 5.720000267028809,\n",
      " 'avg_test_gt8;gt_pred_scores': 0.06282948702573776,\n",
      " 'avg_test_gt8;not_gt_pred_scores': 0.02617705799639225,\n",
      " 'avg_test_gt8;top8_overlap_count': 5.126667022705078,\n",
      " 'avg_test_gt8;top8_pred_above_threshold_count': 7.6533331871032715,\n",
      " 'avg_test_gt8;total_pred_above_threshold_count': 10.039999961853027,\n",
      " 'avg_test_gt9;gt_logits_above_threshold_count': 5.912381172180176,\n",
      " 'avg_test_gt9;gt_pred_scores': 0.052808430045843124,\n",
      " 'avg_test_gt9;not_gt_pred_scores': 0.02915133908390999,\n",
      " 'avg_test_gt9;top9_overlap_count': 5.24666690826416,\n",
      " 'avg_test_gt9;top9_pred_above_threshold_count': 8.787619590759277,\n",
      " 'avg_test_gt9;total_pred_above_threshold_count': 10.701904296875,\n",
      " 'avg_test_precision_by_Query': 0.9075267910957336,\n",
      " 'avg_test_precision_by_QueryKey': 0.9100871086120605,\n",
      " 'avg_test_recall_by_Query': 0.6298671364784241,\n",
      " 'avg_test_recall_by_QueryKey': 0.6233341097831726,\n",
      " 'avg_test_topK_overall_overlap_ratio': 0.841160750800946,\n",
      " 'test_KL_loss': 304.8734436035156,\n",
      " 'test_KL_loss_per_example': 0.2977279722690582,\n",
      " 'test_accuracy_by_Query': 0.6890408396720886,\n",
      " 'test_accuracy_by_QueryKey': 0.6890407800674438,\n",
      " 'test_f1_by_Query': 0.7316440939903259,\n",
      " 'test_f1_by_QueryKey': 0.7398847937583923,\n",
      " 'test_gt10;gt_logits_above_threshold_count': 6.912744998931885,\n",
      " 'test_gt10;gt_pred_scores': 0.05105941370129585,\n",
      " 'test_gt10;not_gt_pred_scores': 0.028788577765226364,\n",
      " 'test_gt10;top10_overlap_count': 6.0913238525390625,\n",
      " 'test_gt10;top10_pred_above_threshold_count': 9.620424270629883,\n",
      " 'test_gt10;total_pred_above_threshold_count': 11.783905982971191,\n",
      " 'test_gt11;gt_logits_above_threshold_count': 7.395744323730469,\n",
      " 'test_gt11;gt_pred_scores': 0.04992803558707237,\n",
      " 'test_gt11;not_gt_pred_scores': 0.02817447856068611,\n",
      " 'test_gt11;top11_overlap_count': 7.103480339050293,\n",
      " 'test_gt11;top11_pred_above_threshold_count': 10.197443008422852,\n",
      " 'test_gt11;total_pred_above_threshold_count': 11.418886184692383,\n",
      " 'test_gt12;gt_logits_above_threshold_count': 8.108551025390625,\n",
      " 'test_gt12;gt_pred_scores': 0.04877867549657822,\n",
      " 'test_gt12;not_gt_pred_scores': 0.027643729001283646,\n",
      " 'test_gt12;top12_overlap_count': 8.242130279541016,\n",
      " 'test_gt12;top12_pred_above_threshold_count': 11.010526657104492,\n",
      " 'test_gt12;total_pred_above_threshold_count': 11.660685539245605,\n",
      " 'test_gt13;gt_logits_above_threshold_count': 8.5747709274292,\n",
      " 'test_gt13;gt_pred_scores': 0.04748646169900894,\n",
      " 'test_gt13;not_gt_pred_scores': 0.027334004640579224,\n",
      " 'test_gt13;top13_overlap_count': 9.161714553833008,\n",
      " 'test_gt13;top13_pred_above_threshold_count': 11.048436164855957,\n",
      " 'test_gt13;total_pred_above_threshold_count': 11.604360580444336,\n",
      " 'test_gt14;gt_logits_above_threshold_count': 9.43868637084961,\n",
      " 'test_gt14;gt_pred_scores': 0.04668007045984268,\n",
      " 'test_gt14;not_gt_pred_scores': 0.02665223553776741,\n",
      " 'test_gt14;top14_overlap_count': 10.288473129272461,\n",
      " 'test_gt14;top14_pred_above_threshold_count': 11.656553268432617,\n",
      " 'test_gt14;total_pred_above_threshold_count': 12.13027286529541,\n",
      " 'test_gt15;gt_logits_above_threshold_count': 9.946065902709961,\n",
      " 'test_gt15;gt_pred_scores': 0.04598966985940933,\n",
      " 'test_gt15;not_gt_pred_scores': 0.025846248492598534,\n",
      " 'test_gt15;top15_overlap_count': 11.512971878051758,\n",
      " 'test_gt15;top15_pred_above_threshold_count': 11.675080299377441,\n",
      " 'test_gt15;total_pred_above_threshold_count': 11.891379356384277,\n",
      " 'test_gt16;gt_logits_above_threshold_count': 10.209938049316406,\n",
      " 'test_gt16;gt_pred_scores': 0.044832341372966766,\n",
      " 'test_gt16;not_gt_pred_scores': 0.025698412209749222,\n",
      " 'test_gt16;top16_overlap_count': 12.5045804977417,\n",
      " 'test_gt16;top16_pred_above_threshold_count': 11.592744827270508,\n",
      " 'test_gt16;total_pred_above_threshold_count': 11.692594528198242,\n",
      " 'test_gt17;gt_logits_above_threshold_count': 10.766987800598145,\n",
      " 'test_gt17;gt_pred_scores': 0.04374265298247337,\n",
      " 'test_gt17;not_gt_pred_scores': 0.025637486949563026,\n",
      " 'test_gt17;top17_overlap_count': 13.675265312194824,\n",
      " 'test_gt17;top17_pred_above_threshold_count': 11.809392929077148,\n",
      " 'test_gt17;total_pred_above_threshold_count': 11.865682601928711,\n",
      " 'test_gt18;gt_logits_above_threshold_count': 11.12205982208252,\n",
      " 'test_gt18;gt_pred_scores': 0.04291248321533203,\n",
      " 'test_gt18;not_gt_pred_scores': 0.025286149233579636,\n",
      " 'test_gt18;top18_overlap_count': 14.931619644165039,\n",
      " 'test_gt18;top18_pred_above_threshold_count': 11.95541000366211,\n",
      " 'test_gt18;total_pred_above_threshold_count': 11.95541000366211,\n",
      " 'test_gt19;gt_logits_above_threshold_count': 11.8134126663208,\n",
      " 'test_gt19;gt_pred_scores': 0.041909318417310715,\n",
      " 'test_gt19;not_gt_pred_scores': 0.025465358048677444,\n",
      " 'test_gt19;top19_overlap_count': 15.993766784667969,\n",
      " 'test_gt19;top19_pred_above_threshold_count': 12.585844039916992,\n",
      " 'test_gt19;total_pred_above_threshold_count': 12.585844039916992,\n",
      " 'test_gt20;gt_logits_above_threshold_count': 12.376302719116211,\n",
      " 'test_gt20;gt_pred_scores': 0.04111379757523537,\n",
      " 'test_gt20;not_gt_pred_scores': 0.025389153510332108,\n",
      " 'test_gt20;top20_overlap_count': 17.194751739501953,\n",
      " 'test_gt20;top20_pred_above_threshold_count': 12.949853897094727,\n",
      " 'test_gt20;total_pred_above_threshold_count': 12.949853897094727,\n",
      " 'test_gt21;gt_logits_above_threshold_count': 13.088315963745117,\n",
      " 'test_gt21;gt_pred_scores': 0.040293317288160324,\n",
      " 'test_gt21;not_gt_pred_scores': 0.025640051811933517,\n",
      " 'test_gt21;top21_overlap_count': 18.52962875366211,\n",
      " 'test_gt21;top21_pred_above_threshold_count': 13.531306266784668,\n",
      " 'test_gt21;total_pred_above_threshold_count': 13.531306266784668,\n",
      " 'test_gt22;gt_logits_above_threshold_count': 13.665908813476562,\n",
      " 'test_gt22;gt_pred_scores': 0.03970102593302727,\n",
      " 'test_gt22;not_gt_pred_scores': 0.025315487757325172,\n",
      " 'test_gt22;top22_overlap_count': 19.732830047607422,\n",
      " 'test_gt22;top22_pred_above_threshold_count': 13.88166332244873,\n",
      " 'test_gt22;total_pred_above_threshold_count': 13.88166332244873,\n",
      " 'test_gt23;gt_logits_above_threshold_count': 14.309887886047363,\n",
      " 'test_gt23;gt_pred_scores': 0.03893818333745003,\n",
      " 'test_gt23;not_gt_pred_scores': 0.026105444878339767,\n",
      " 'test_gt23;top23_overlap_count': 21.006927490234375,\n",
      " 'test_gt23;top23_pred_above_threshold_count': 14.476117134094238,\n",
      " 'test_gt23;total_pred_above_threshold_count': 14.476117134094238,\n",
      " 'test_gt24;gt_logits_above_threshold_count': 13.829363822937012,\n",
      " 'test_gt24;gt_pred_scores': 0.038378261029720306,\n",
      " 'test_gt24;not_gt_pred_scores': 0.02630721963942051,\n",
      " 'test_gt24;top24_overlap_count': 22.60555648803711,\n",
      " 'test_gt24;top24_pred_above_threshold_count': 13.884126663208008,\n",
      " 'test_gt24;total_pred_above_threshold_count': 13.884126663208008,\n",
      " 'test_gt25;gt_logits_above_threshold_count': 14.24476146697998,\n",
      " 'test_gt25;gt_pred_scores': 0.03777966648340225,\n",
      " 'test_gt25;not_gt_pred_scores': 0.027754206210374832,\n",
      " 'test_gt25;top25_overlap_count': 23.844921112060547,\n",
      " 'test_gt25;top25_pred_above_threshold_count': 14.294761657714844,\n",
      " 'test_gt25;total_pred_above_threshold_count': 14.294761657714844,\n",
      " 'test_gt26;gt_logits_above_threshold_count': 14.699999809265137,\n",
      " 'test_gt26;gt_pred_scores': 0.03726695105433464,\n",
      " 'test_gt26;not_gt_pred_scores': 0.03105924092233181,\n",
      " 'test_gt26;top26_overlap_count': 25.200000762939453,\n",
      " 'test_gt26;top26_pred_above_threshold_count': 14.75,\n",
      " 'test_gt26;total_pred_above_threshold_count': 14.75,\n",
      " 'test_gt27;gt_logits_above_threshold_count': 16.15359115600586,\n",
      " 'test_gt27;gt_pred_scores': 0.03703700006008148,\n",
      " 'test_gt27;not_gt_pred_scores': nan,\n",
      " 'test_gt27;top27_overlap_count': 27.0,\n",
      " 'test_gt27;top27_pred_above_threshold_count': 16.15359115600586,\n",
      " 'test_gt27;total_pred_above_threshold_count': 16.15359115600586,\n",
      " 'test_gt6;gt_logits_above_threshold_count': 6.0,\n",
      " 'test_gt6;gt_pred_scores': 0.07239755243062973,\n",
      " 'test_gt6;not_gt_pred_scores': 0.02693403698503971,\n",
      " 'test_gt6;top6_overlap_count': 3.0,\n",
      " 'test_gt6;top6_pred_above_threshold_count': 6.0,\n",
      " 'test_gt6;total_pred_above_threshold_count': 12.0,\n",
      " 'test_gt7;gt_logits_above_threshold_count': 5.0,\n",
      " 'test_gt7;gt_pred_scores': 0.04638945683836937,\n",
      " 'test_gt7;not_gt_pred_scores': 0.033763691782951355,\n",
      " 'test_gt7;top7_overlap_count': 2.8333332538604736,\n",
      " 'test_gt7;top7_pred_above_threshold_count': 7.0,\n",
      " 'test_gt7;total_pred_above_threshold_count': 14.5,\n",
      " 'test_gt8;gt_logits_above_threshold_count': 5.720000267028809,\n",
      " 'test_gt8;gt_pred_scores': 0.06282947957515717,\n",
      " 'test_gt8;not_gt_pred_scores': 0.02617705799639225,\n",
      " 'test_gt8;top8_overlap_count': 5.126667022705078,\n",
      " 'test_gt8;top8_pred_above_threshold_count': 7.6533331871032715,\n",
      " 'test_gt8;total_pred_above_threshold_count': 10.039999008178711,\n",
      " 'test_gt9;gt_logits_above_threshold_count': 5.912381172180176,\n",
      " 'test_gt9;gt_pred_scores': 0.052808426320552826,\n",
      " 'test_gt9;not_gt_pred_scores': 0.02915133908390999,\n",
      " 'test_gt9;top9_overlap_count': 5.24666690826416,\n",
      " 'test_gt9;top9_pred_above_threshold_count': 8.787618637084961,\n",
      " 'test_gt9;total_pred_above_threshold_count': 10.701904296875,\n",
      " 'test_precision_by_Query': 0.9075267910957336,\n",
      " 'test_precision_by_QueryKey': 0.9100871086120605,\n",
      " 'test_recall_by_Query': 0.6298671364784241,\n",
      " 'test_recall_by_QueryKey': 0.6233341097831726,\n",
      " 'test_topK_overall_overlap_ratio': 0.841160774230957}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainmodule, game_datamodule = main.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-output",
   "metadata": {},
   "source": [
    "## KL Loss Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "together-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(np.array(x) - np.max(x, axis=-1).reshape(-1, 1))\n",
    "    return e_x / np.sum(e_x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def entropy(x):\n",
    "    return - np.sum(x * np.log2(x), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fancy-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 50th data indices by kl loss [ 515 4454 4204 2398  638 1378 4059 4356 3896 1921 3935 4653 3535 3518\n",
      " 4367 1651 2780 3141 4478 3302  646 5056 2590  530 1667 4625 4228 1156\n",
      " 4442 1253 3698 4952 2536 3685  267 1846  808 3315 4836 3761 1168 1434\n",
      " 4868 3045 3178 4784  181 2013  497 1989]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1215.,  989., 1349.,  759.,  391.,  251.,  108.,   47.,    6.,\n",
       "           5.]),\n",
       " array([2.13004806e-04, 1.28074274e-01, 2.55935544e-01, 3.83796813e-01,\n",
       "        5.11658083e-01, 6.39519353e-01, 7.67380622e-01, 8.95241892e-01,\n",
       "        1.02310316e+00, 1.15096443e+00, 1.27882570e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 'checkpoints/ContrastiveLearning-SET-Wildcard-Expand-Union-27/20210401-160755-Con;Vec4;L8H8Lk4Hk2;scheduledAdamW36000;16871.56Kparams_runId_3aw2kmru/test_metrics.json'\n",
    "with open(p, 'r') as f:\n",
    "    res = json.load(f)\n",
    "    \n",
    "full_kl_loss = [row for batch in res['full_kl_loss'] for row in batch]\n",
    "full_logits = [row for batch in res['full_logits'] for row in batch]\n",
    "full_probs = softmax(full_logits)\n",
    "\n",
    "full_kl_loss_sum_row = np.sum(np.array(full_kl_loss), axis=-1)\n",
    "sorted_indices = np.argsort(full_kl_loss_sum_row)\n",
    "print('top 50th data indices by kl loss', sorted_indices[:50])\n",
    "\n",
    "plt.hist(full_kl_loss_sum_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "essential-benefit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.13004806e-04, 2.15035968e-04, 2.17419860e-04, ...,\n",
       "       1.24028135e+00, 1.24115565e+00, 1.27882570e+00])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_kl_loss_sum_row[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ranging-plymouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "key_support_size : 27\n",
      "N_pairs : 8\n",
      "union_only : True\n",
      "max_len_q : 16\n",
      "len_k : 1\n",
      "train_gt_idxs length : 0\n",
      "val_gt_idxs length : 5120\n",
      "test_gt_idxs length : 5120\n",
      "train_tokens length : 0\n",
      "val_tokens length : 5120\n",
      "test_tokens length : 5120\n",
      "test_marginal_gt_idxs length : 5120\n",
      "test_marginal_tokens length : 5120\n",
      "vocab_size : 74\n",
      "symbol_vocab_token_lookup : {'(': 64, ')': 65, 'NULL': 66, 'SEP': 67, 'SOS': 68, 'EOS': 69, 'PAD': 70, 'PLH': 71, '|': 72, '!': 73}\n",
      "vocab_by_property : False\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "game_data = main.load_data(args.data_path)\n",
    "gt_counts = np.array([len(gt_idxs) for gt_idxs in game_data['test_gt_idxs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "diverse-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 7, 8, 8, 10, 8, 9, 9, 9, 7, 10, 9, 10, 8, 10, 9, 9, 9, 10, 8, 9, 9, 9, 10, 9, 10, 9, 10, 9, 11, 9, 9, 11, 10, 10, 8, 10, 8, 10, 8, 9, 6, 9, 9, 9, 10, 9, 11, 11, 11, 9, 9, 10, 10, 9, 10, 11, 11, 11, 8, 9, 10, 10, 9, 11, 10, 11, 11, 10, 11, 9, 10, 10, 11, 9, 9, 11, 9, 11, 11, 8, 11, 12, 10, 11, 10, 9, 11, 9, 11, 10, 11, 11, 9, 10, 8, 10, 10, 12, 10, 9, 11, 11, 10, 10, 8, 11, 12, 11, 11, 12, 11, 12, 11, 11, 10, 10, 11, 12, 10, 11, 11, 12, 11, 11, 12, 13, 12, 11, 11, 11, 12, 10, 11, 12, 11, 10, 9, 10, 12, 12, 11, 12, 10, 10, 12, 12, 11, 11, 10, 12, 12, 11, 12, 12, 11, 10, 11, 11, 11, 12, 9, 12, 12, 12, 12, 11, 13, 11, 12, 11, 11, 13, 12, 8, 10, 11, 12, 11, 12, 12, 10, 9, 11, 13, 11, 11, 11, 10, 12, 11, 12, 11, 11, 13, 12, 12, 12, 12, 10, 11, 10, 12, 11, 12, 12, 12, 13, 13, 13, 13, 11, 13, 12, 13, 13, 11, 13, 10, 12, 10, 9, 13, 12, 12, 12, 13, 11, 13, 13, 13, 12, 13, 11, 12, 11, 13, 12, 11, 12, 13, 13, 13, 13, 11, 13, 11, 11, 13, 13, 12, 15, 13, 12, 11, 12, 13, 11, 9, 13, 12, 13, 12, 10, 11, 12, 13, 11, 10, 13, 11, 12, 10, 12, 13, 10, 11, 8, 10, 13, 13, 9, 13, 11, 10, 12, 13, 11, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 11, 13, 13, 12, 13, 13, 11, 12, 9, 12, 9, 13, 13, 13, 11, 13, 11, 13, 11, 12, 13, 11, 11, 12, 14, 12, 13, 13, 13, 12, 12, 11, 12, 12, 13, 8, 10, 12, 13, 13, 13, 11, 13, 13, 13, 12, 13, 11, 9, 12, 14, 11, 11, 11, 13, 13, 12, 12, 12, 13, 12, 14, 12, 14, 10, 14, 14, 11, 14, 13, 14, 12, 14, 13, 10, 13, 13, 12, 14, 12, 14, 13, 12, 12, 11, 11, 13, 12, 14, 13, 12, 14, 11, 13, 10, 14, 14, 14, 13, 12, 13, 13, 12, 13, 13, 14, 12, 12, 10, 13, 14, 14, 11, 13, 14, 13, 12, 14, 12, 14, 13, 14, 14, 13, 14, 14, 11, 11, 14, 10, 13, 13, 12, 14, 14, 11, 14, 13, 13, 12, 13, 14, 11, 13, 14, 11, 12, 11, 12, 13, 12, 14, 12, 14, 12, 11, 14, 13, 11, 14, 13, 14, 13, 13, 13, 13, 14, 12, 13, 13, 14, 11, 14, 14, 14, 14, 12, 10, 14, 14, 14, 13, 14, 14, 10, 13, 12, 12, 14, 13, 13, 14, 14, 14, 12, 14, 13, 14, 11, 13, 13, 14, 13, 13, 14, 13, 14, 13, 12, 11, 12, 14, 13, 12, 14, 13, 14, 14, 15, 15, 14, 13, 14, 14, 14, 14, 15, 14, 14, 15, 13, 14, 14, 15, 14, 14, 11, 12, 13, 8, 13, 14, 13, 13, 13, 15, 9, 12, 14, 13, 11, 14, 15, 14, 14, 12, 12, 12, 12, 13, 12, 14, 12, 13, 13, 14, 15, 14, 15, 13, 14, 13, 13, 15, 14, 15, 14, 14, 13, 14, 13, 14, 15, 14, 14, 14, 12, 10, 15, 13, 11, 14, 15, 13, 13, 15, 14, 11, 15, 15, 14, 13, 14, 14, 15, 15, 12, 14, 11, 13, 15, 14, 14, 15, 15, 14, 12, 14, 15, 15, 13, 13, 15, 15, 13, 15, 15, 15, 14, 15, 13, 15, 14, 15, 14, 11, 15, 13, 14, 11, 12, 15, 15, 14, 12, 13, 13, 15, 12, 15, 14, 13, 12, 14, 14, 13, 14, 13, 15, 11, 11, 15, 15, 14, 14, 14, 15, 15, 14, 13, 15, 14, 14, 14, 15, 13, 11, 15, 14, 15, 15, 15, 11, 15, 15, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 15, 15, 15, 14, 14, 13, 12, 14, 15, 15, 13, 15, 15, 14, 15, 14, 14, 13, 12, 15, 13, 13, 15, 12, 15, 13, 13, 13, 14, 13, 15, 15, 15, 13, 15, 15, 15, 15, 13, 16, 15, 14, 14, 14, 13, 13, 14, 15, 15, 15, 14, 15, 12, 15, 15, 14, 16, 15, 15, 16, 16, 15, 16, 15, 15, 15, 14, 15, 15, 15, 10, 14, 16, 14, 15, 15, 14, 15, 10, 16, 13, 16, 14, 16, 15, 15, 16, 14, 16, 15, 16, 13, 11, 16, 16, 13, 12, 14, 13, 16, 16, 16, 15, 16, 15, 13, 15, 16, 14, 15, 16, 16, 16, 15, 16, 15, 13, 15, 10, 16, 16, 10, 16, 14, 16, 15, 16, 15, 11, 15, 15, 16, 16, 16, 16, 15, 11, 15, 15, 14, 16, 15, 15, 11, 15, 15, 15, 13, 16, 16, 15, 14, 14, 15, 16, 15, 11, 13, 15, 16, 11, 16, 16, 16, 14, 15, 16, 15, 16, 16, 13, 12, 11, 16, 16, 16, 8, 16, 16, 15, 16, 16, 15, 16, 16, 14, 16, 16, 16, 16, 16, 15, 16, 16, 15, 14, 16, 14, 16, 14, 16, 15, 16, 16, 10, 15, 16, 16, 15, 16, 16, 15, 16, 16, 14, 16, 15, 13, 16, 16, 12, 11, 16, 16, 13, 15, 13, 16, 15, 14, 15, 16, 16, 16, 14, 16, 15, 15, 16, 16, 16, 15, 16, 16, 16, 14, 15, 16, 17, 17, 16, 13, 16, 16, 14, 13, 11, 16, 16, 16, 16, 16, 17, 14, 13, 14, 16, 13, 16, 16, 16, 11, 16, 15, 15, 14, 13, 16, 14, 11, 15, 15, 13, 13, 16, 16, 17, 17, 15, 8, 13, 16, 14, 12, 16, 13, 16, 14, 15, 15, 12, 16, 12, 10, 13, 17, 15, 12, 13, 15, 14, 12, 14, 17, 16, 16, 12, 17, 15, 15, 13, 17, 16, 17, 13, 14, 16, 14, 16, 13, 13, 14, 14, 17, 15, 17, 17, 16, 16, 15, 17, 14, 17, 17, 16, 16, 13, 17, 15, 15, 17, 15, 16, 16, 17, 16, 12, 15, 16, 17, 14, 15, 17, 17, 17, 14, 15, 15, 14, 17, 14, 17, 14, 17, 17, 17, 14, 17, 17, 14, 14, 15, 14, 17, 13, 14, 15, 12, 16, 16, 14, 15, 14, 14, 16, 16, 14, 17, 14, 12, 13, 17, 17, 16, 16, 17, 12, 16, 16, 16, 16, 15, 17, 12, 14, 16, 17, 17, 13, 12, 17, 16, 15, 15, 17, 17, 17, 15, 16, 17, 17, 17, 16, 15, 16, 15, 16, 17, 15, 14, 14, 12, 16, 17, 17, 16, 17, 17, 17, 13, 15, 13, 17, 16, 13, 17, 14, 17, 13, 14, 15, 15, 15, 13, 15, 17, 17, 15, 13, 16, 16, 17, 12, 13, 13, 15, 17, 12, 15, 12, 17, 13, 17, 16, 16, 13, 16, 13, 15, 15, 16, 13, 14, 15, 16, 14, 15, 15, 16, 15, 12, 12, 14, 17, 14, 17, 17, 15, 15, 17, 16, 17, 14, 17, 16, 17, 17, 15, 16, 17, 17, 13, 12, 17, 15, 14, 12, 15, 17, 17, 13, 15, 15, 17, 16, 14, 15, 16, 17, 13, 15, 16, 14, 15, 16, 15, 17, 15, 15, 16, 16, 14, 15, 14, 16, 17, 13, 13, 18, 15, 16, 16, 13, 12, 16, 15, 16, 17, 17, 17, 17, 17, 16, 15, 15, 14, 15, 15, 17, 12, 16, 17, 15, 17, 16, 14, 18, 15, 14, 15, 11, 16, 16, 13, 17, 17, 17, 15, 15, 15, 15, 16, 16, 14, 16, 17, 16, 17, 12, 17, 16, 15, 16, 18, 16, 16, 17, 17, 16, 17, 16, 17, 18, 18, 17, 16, 17, 16, 16, 14, 16, 14, 15, 16, 14, 15, 16, 16, 18, 14, 16, 17, 16, 16, 16, 15, 13, 16, 15, 12, 15, 15, 15, 16, 14, 17, 13, 15, 16, 15, 15, 14, 18, 16, 15, 14, 16, 17, 15, 18, 18, 14, 15, 16, 18, 16, 15, 16, 16, 15, 16, 17, 17, 17, 15, 14, 17, 16, 17, 16, 18, 15, 17, 16, 18, 17, 18, 14, 15, 15, 15, 16, 13, 13, 17, 15, 15, 15, 15, 18, 14, 14, 15, 13, 14, 17, 18, 17, 14, 13, 14, 17, 13, 15, 16, 18, 17, 14, 15, 16, 16, 13, 16, 14, 18, 17, 18, 15, 17, 17, 17, 18, 17, 15, 16, 17, 16, 16, 14, 16, 13, 18, 18, 17, 18, 15, 12, 16, 15, 16, 17, 17, 14, 17, 16, 16, 14, 13, 13, 16, 17, 16, 17, 13, 16, 16, 16, 15, 16, 17, 16, 16, 16, 16, 17, 18, 13, 11, 17, 17, 14, 16, 18, 14, 16, 18, 16, 16, 17, 15, 16, 12, 16, 16, 16, 18, 15, 17, 16, 17, 11, 13, 17, 17, 16, 17, 18, 16, 16, 16, 14, 16, 16, 17, 15, 18, 15, 16, 17, 18, 17, 14, 17, 17, 16, 16, 15, 16, 17, 14, 14, 17, 17, 16, 15, 14, 16, 17, 16, 17, 15, 17, 15, 15, 12, 13, 13, 15, 16, 15, 16, 16, 17, 15, 17, 17, 17, 17, 14, 17, 13, 16, 17, 16, 17, 15, 17, 17, 14, 17, 15, 18, 15, 16, 16, 17, 17, 17, 16, 18, 18, 16, 15, 17, 16, 17, 17, 17, 18, 17, 16, 13, 17, 16, 18, 17, 14, 18, 15, 17, 17, 11, 13, 16, 15, 17, 17, 15, 18, 17, 13, 18, 17, 17, 18, 17, 15, 17, 17, 17, 14, 18, 17, 14, 14, 17, 17, 18, 18, 17, 14, 18, 17, 17, 15, 17, 18, 17, 16, 17, 17, 17, 16, 18, 15, 18, 18, 17, 18, 17, 18, 17, 14, 17, 17, 17, 17, 17, 17, 17, 17, 16, 15, 18, 14, 17, 17, 15, 14, 17, 16, 17, 17, 16, 17, 17, 18, 17, 16, 15, 17, 16, 17, 15, 17, 18, 16, 18, 17, 17, 15, 15, 16, 17, 18, 17, 16, 17, 17, 14, 16, 17, 15, 17, 17, 17, 14, 18, 17, 17, 18, 17, 17, 17, 16, 17, 17, 15, 18, 14, 18, 15, 18, 16, 17, 14, 16, 15, 17, 18, 15, 17, 17, 14, 16, 18, 17, 15, 14, 16, 17, 17, 17, 17, 17, 18, 18, 15, 15, 18, 16, 17, 17, 17, 17, 18, 17, 17, 17, 17, 14, 17, 17, 17, 17, 17, 16, 16, 18, 17, 17, 18, 16, 18, 17, 17, 17, 16, 19, 19, 17, 16, 16, 15, 15, 17, 17, 17, 18, 17, 17, 17, 19, 17, 18, 18, 16, 13, 18, 17, 18, 17, 18, 16, 18, 17, 15, 16, 17, 17, 19, 18, 15, 17, 19, 17, 17, 17, 17, 15, 18, 17, 16, 14, 16, 17, 16, 18, 19, 15, 17, 14, 19, 19, 15, 16, 17, 15, 17, 17, 16, 15, 16, 19, 18, 16, 16, 17, 17, 18, 17, 16, 19, 18, 16, 16, 17, 17, 17, 16, 15, 16, 17, 19, 18, 19, 18, 17, 17, 19, 17, 18, 16, 16, 17, 19, 18, 18, 17, 16, 16, 16, 18, 15, 18, 19, 15, 18, 19, 17, 18, 18, 19, 19, 17, 15, 16, 17, 15, 16, 17, 19, 19, 18, 19, 16, 15, 15, 18, 19, 16, 18, 18, 18, 18, 16, 18, 14, 18, 16, 19, 18, 18, 18, 14, 16, 17, 18, 17, 18, 16, 17, 17, 18, 15, 18, 16, 19, 16, 15, 16, 17, 19, 18, 16, 15, 19, 18, 15, 17, 16, 18, 17, 18, 17, 18, 18, 14, 18, 17, 18, 17, 17, 17, 18, 18, 19, 18, 18, 18, 17, 18, 18, 14, 15, 18, 18, 18, 18, 18, 16, 16, 17, 18, 18, 18, 18, 17, 18, 18, 18, 17, 15, 16, 17, 15, 18, 19, 17, 18, 16, 18, 17, 18, 18, 18, 19, 18, 18, 17, 17, 18, 14, 18, 19, 19, 19, 18, 18, 18, 18, 19, 14, 19, 18, 18, 17, 17, 17, 18, 15, 17, 17, 18, 17, 18, 19, 15, 18, 16, 16, 19, 18, 17, 18, 18, 13, 18, 13, 15, 18, 18, 18, 18, 18, 18, 15, 18, 15, 17, 13, 18, 18, 18, 18, 15, 16, 18, 18, 18, 18, 18, 18, 18, 18, 16, 18, 18, 18, 18, 18, 18, 18, 14, 16, 17, 18, 19, 18, 21, 18, 18, 18, 18, 17, 18, 17, 17, 18, 18, 15, 18, 16, 16, 18, 18, 18, 15, 18, 18, 12, 17, 15, 19, 18, 17, 18, 15, 19, 14, 18, 19, 17, 15, 17, 19, 18, 11, 14, 17, 19, 15, 18, 18, 19, 18, 16, 17, 19, 17, 18, 12, 19, 17, 18, 16, 18, 18, 17, 17, 19, 18, 18, 16, 17, 17, 18, 18, 18, 19, 18, 19, 16, 19, 18, 18, 19, 17, 18, 17, 18, 17, 18, 18, 18, 18, 19, 18, 18, 18, 18, 18, 18, 17, 18, 18, 15, 18, 17, 19, 18, 18, 17, 17, 16, 18, 13, 18, 18, 19, 17, 18, 16, 19, 15, 18, 13, 17, 18, 18, 16, 19, 18, 19, 16, 18, 17, 17, 18, 13, 17, 15, 17, 18, 18, 19, 18, 18, 18, 18, 18, 18, 18, 16, 19, 18, 17, 17, 17, 18, 18, 18, 17, 19, 19, 19, 17, 17, 17, 15, 17, 19, 17, 16, 16, 17, 19, 18, 19, 18, 17, 18, 18, 15, 15, 18, 17, 19, 18, 17, 18, 18, 16, 15, 17, 19, 18, 19, 18, 18, 17, 18, 18, 16, 18, 17, 19, 18, 17, 18, 17, 19, 19, 18, 18, 18, 17, 16, 17, 19, 19, 18, 19, 17, 16, 19, 18, 18, 18, 18, 18, 19, 19, 18, 19, 17, 19, 19, 18, 18, 19, 19, 18, 19, 19, 18, 19, 18, 18, 20, 15, 17, 19, 18, 19, 18, 18, 16, 19, 19, 19, 15, 19, 19, 19, 19, 13, 19, 17, 16, 20, 18, 17, 17, 19, 20, 19, 17, 18, 19, 19, 19, 18, 19, 17, 19, 19, 19, 19, 19, 20, 20, 19, 16, 19, 17, 19, 17, 19, 17, 13, 16, 17, 17, 15, 20, 19, 19, 17, 17, 19, 17, 19, 18, 19, 19, 19, 20, 19, 20, 18, 20, 19, 17, 20, 17, 19, 19, 20, 17, 19, 20, 17, 19, 20, 19, 19, 19, 19, 19, 19, 19, 19, 17, 18, 19, 20, 19, 16, 17, 19, 19, 20, 19, 18, 19, 19, 17, 17, 17, 19, 17, 19, 19, 20, 19, 19, 20, 17, 19, 19, 19, 19, 18, 19, 19, 19, 19, 19, 19, 17, 19, 19, 19, 17, 16, 20, 19, 19, 17, 19, 19, 19, 20, 18, 17, 19, 20, 17, 19, 19, 17, 19, 15, 18, 17, 19, 17, 16, 19, 20, 16, 16, 16, 19, 15, 19, 18, 16, 19, 20, 17, 19, 19, 20, 17, 20, 19, 17, 18, 19, 19, 18, 20, 17, 19, 19, 19, 20, 18, 20, 19, 13, 16, 19, 19, 19, 19, 17, 17, 20, 16, 18, 18, 20, 19, 19, 19, 18, 17, 18, 19, 18, 19, 20, 19, 19, 18, 20, 20, 19, 18, 19, 16, 16, 18, 19, 17, 19, 17, 19, 18, 19, 20, 20, 19, 19, 18, 17, 18, 20, 17, 19, 20, 16, 19, 20, 18, 19, 17, 19, 18, 17, 17, 19, 18, 19, 16, 17, 16, 20, 18, 16, 17, 20, 20, 19, 19, 19, 18, 16, 18, 19, 19, 18, 16, 18, 19, 15, 18, 19, 20, 18, 17, 20, 17, 19, 17, 20, 19, 18, 20, 19, 19, 16, 18, 18, 18, 18, 19, 16, 18, 17, 18, 17, 20, 19, 19, 18, 20, 19, 19, 16, 18, 17, 16, 17, 20, 20, 19, 18, 17, 18, 17, 19, 19, 18, 18, 18, 18, 18, 17, 16, 19, 18, 20, 20, 18, 16, 19, 19, 19, 18, 18, 19, 14, 20, 19, 18, 17, 19, 18, 16, 20, 18, 20, 19, 16, 19, 20, 19, 16, 19, 19, 20, 19, 18, 20, 18, 19, 19, 19, 19, 20, 20, 19, 20, 18, 20, 19, 19, 18, 16, 20, 16, 19, 19, 16, 20, 20, 19, 20, 19, 20, 19, 20, 19, 19, 16, 19, 20, 20, 20, 20, 20, 20, 19, 19, 19, 20, 19, 19, 20, 16, 14, 20, 20, 19, 20, 19, 18, 20, 19, 19, 20, 19, 18, 19, 20, 20, 21, 18, 20, 18, 18, 19, 19, 14, 18, 20, 20, 14, 19, 18, 18, 19, 20, 19, 20, 20, 19, 19, 18, 19, 19, 19, 20, 20, 20, 16, 20, 20, 19, 19, 18, 20, 18, 19, 20, 20, 21, 19, 19, 20, 17, 19, 19, 18, 19, 20, 20, 18, 18, 19, 20, 20, 19, 19, 17, 18, 16, 19, 19, 19, 20, 20, 20, 16, 19, 20, 20, 17, 18, 18, 19, 18, 20, 20, 14, 20, 19, 20, 20, 20, 21, 20, 20, 19, 20, 20, 20, 20, 18, 20, 19, 17, 19, 20, 18, 18, 20, 20, 20, 21, 18, 19, 18, 20, 19, 20, 18, 20, 20, 20, 20, 20, 20, 19, 19, 18, 18, 14, 19, 17, 19, 19, 14, 18, 20, 19, 19, 18, 20, 20, 20, 20, 20, 20, 19, 19, 18, 21, 20, 19, 19, 19, 18, 20, 20, 20, 18, 18, 19, 19, 20, 20, 20, 20, 20, 19, 20, 19, 17, 21, 20, 20, 20, 16, 20, 19, 20, 20, 19, 18, 21, 18, 20, 18, 20, 20, 19, 20, 20, 21, 20, 20, 21, 20, 20, 20, 18, 18, 20, 20, 20, 21, 20, 21, 20, 21, 19, 20, 21, 19, 20, 20, 20, 20, 20, 19, 20, 21, 21, 19, 19, 21, 20, 21, 20, 20, 19, 20, 20, 20, 20, 19, 19, 20, 19, 20, 17, 20, 19, 20, 21, 19, 20, 19, 21, 20, 21, 21, 21, 21, 21, 19, 21, 20, 21, 19, 21, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 17, 18, 18, 20, 20, 18, 21, 20, 20, 21, 20, 14, 20, 18, 20, 18, 20, 20, 20, 20, 20, 21, 19, 21, 18, 18, 18, 20, 20, 20, 18, 20, 21, 21, 21, 21, 20, 20, 21, 20, 20, 18, 18, 14, 18, 20, 21, 18, 20, 20, 20, 20, 20, 21, 20, 20, 17, 21, 20, 21, 21, 21, 17, 20, 20, 21, 20, 20, 20, 17, 18, 21, 20, 19, 19, 21, 17, 21, 21, 20, 20, 21, 21, 18, 18, 20, 21, 20, 21, 20, 20, 21, 21, 18, 21, 20, 19, 20, 20, 21, 21, 20, 21, 20, 21, 21, 19, 15, 21, 21, 21, 21, 21, 17, 15, 18, 19, 21, 17, 20, 20, 20, 18, 18, 21, 21, 21, 21, 21, 18, 21, 21, 21, 21, 21, 21, 19, 21, 20, 17, 21, 21, 18, 20, 21, 20, 21, 19, 17, 17, 21, 21, 21, 21, 19, 21, 20, 21, 21, 21, 19, 21, 21, 21, 21, 17, 21, 20, 21, 21, 20, 20, 20, 21, 21, 20, 21, 19, 21, 21, 21, 21, 21, 20, 21, 20, 20, 20, 21, 17, 20, 20, 20, 21, 21, 20, 21, 22, 20, 20, 21, 20, 19, 20, 21, 21, 20, 20, 21, 19, 17, 20, 21, 21, 19, 17, 20, 20, 21, 19, 15, 20, 21, 20, 21, 20, 21, 20, 20, 19, 21, 22, 20, 21, 19, 20, 21, 21, 20, 20, 20, 20, 17, 19, 20, 17, 21, 19, 15, 21, 21, 17, 21, 20, 19, 15, 21, 19, 21, 21, 21, 19, 19, 15, 21, 21, 21, 21, 21, 19, 19, 21, 21, 21, 20, 21, 19, 21, 21, 22, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 19, 21, 21, 21, 21, 17, 21, 21, 21, 21, 21, 20, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 15, 21, 20, 21, 22, 21, 21, 21, 21, 21, 21, 21, 22, 21, 22, 20, 19, 21, 21, 22, 21, 21, 22, 22, 22, 19, 15, 22, 21, 22, 20, 20, 21, 21, 21, 21, 21, 22, 20, 21, 22, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 22, 21, 22, 21, 20, 21, 22, 21, 22, 21, 22, 21, 22, 21, 21, 22, 21, 22, 20, 22, 21, 22, 21, 22, 21, 21, 22, 22, 22, 21, 22, 22, 22, 22, 22, 22, 22, 21, 22, 22, 22, 22, 22, 22, 22, 22, 21, 22, 22, 21, 22, 22, 22, 22, 22, 22, 22, 18, 22, 22, 22, 22, 20, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 19, 22, 22, 22, 22, 22, 18, 21, 18, 22, 21, 22, 22, 22, 22, 22, 20, 21, 21, 22, 22, 22, 21, 22, 20, 20, 22, 22, 22, 22, 22, 22, 22, 22, 22, 21, 22, 22, 22, 22, 22, 21, 22, 22, 22, 22, 22, 21, 22, 22, 20, 22, 22, 22, 22, 22, 21, 22, 21, 22, 21, 22, 22, 21, 20, 16, 22, 22, 18, 22, 21, 22, 21, 23, 18, 22, 21, 22, 22, 22, 22, 20, 22, 23, 16, 22, 21, 21, 22, 22, 22, 22, 22, 22, 21, 22, 21, 23, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 21, 23, 21, 21, 21, 23, 23, 22, 21, 21, 21, 23, 21, 23, 21, 21, 21, 21, 20, 21, 23, 21, 21, 21, 21, 22, 21, 21, 23, 20, 23, 20, 21, 23, 21, 20, 23, 23, 23, 22, 23, 23, 23, 21, 23, 20, 21, 20, 16, 23, 22, 20, 21, 23, 21, 21, 21, 20, 23, 23, 23, 22, 21, 23, 21, 23, 23, 22, 23, 22, 23, 20, 22, 22, 23, 22, 22, 23, 20, 21, 23, 20, 23, 23, 22, 22, 23, 20, 21, 23, 20, 20, 21, 22, 20, 22, 23, 22, 22, 21, 22, 23, 23, 20, 20, 21, 21, 21, 22, 22, 22, 20, 22, 23, 23, 23, 22, 23, 23, 23, 23, 20, 23, 20, 22, 20, 23, 22, 23, 23, 23, 22, 22, 23, 22, 23, 23, 20, 21, 23, 20, 22, 23, 22, 22, 22, 20, 23, 22, 20, 20, 21, 22, 22, 22, 22, 22, 22, 23, 22, 23, 22, 22, 22, 22, 21, 21, 20, 23, 22, 23, 22, 21, 23, 20, 23, 22, 22, 22, 23, 22, 23, 22, 22, 20, 22, 22, 22, 21, 20, 20, 23, 22, 23, 23, 23, 20, 22, 20, 23, 23, 23, 23, 20, 20, 23, 23, 20, 21, 23, 21, 21, 20, 21, 21, 23, 21, 23, 16, 21, 21, 21, 22, 21, 22, 21, 22, 21, 22, 22, 23, 19, 23, 23, 21, 23, 22, 23, 22, 23, 22, 21, 20, 21, 20, 22, 22, 22, 22, 22, 21, 23, 22, 20, 22, 23, 22, 23, 21, 22, 22, 22, 22, 22, 23, 22, 19, 21, 22, 22, 22, 22, 22, 23, 22, 22, 22, 22, 22, 19, 23, 22, 22, 22, 23, 22, 19, 23, 23, 23, 22, 23, 23, 23, 22, 19, 23, 23, 22, 23, 23, 23, 23, 23, 19, 19, 23, 19, 23, 23, 23, 23, 23, 23, 23, 23, 23, 19, 23, 19, 23, 23, 19, 23, 23, 23, 23, 24, 24, 23, 23, 23, 23, 19, 23, 23, 23, 23, 23, 19, 23, 23, 24, 23, 23, 23, 23, 23, 19, 23, 23, 23, 23, 23, 19, 23, 19, 23, 19, 23, 23, 23, 19, 23, 23, 23, 23, 23, 19, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 19, 23, 19, 24, 24, 23, 23, 23, 23, 19, 23, 19, 19, 19, 23, 23, 19, 24, 23, 24, 23, 23, 24, 24, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 19, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 18, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 24, 24, 25, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 18, 18, 18, 26, 26, 18, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27]\n"
     ]
    }
   ],
   "source": [
    "print(gt_counts[sorted_indices].tolist()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "corrected-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 23, 25, 45, 25, 15, 23, 20, 21, 53, 11, 40, 7, 50, 25, 9], [14]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data['test_tokens'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "natural-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 26, 21, 17, 1, 10, 12, 19, 23, 25, 5, 16, 14, 9, 22, 15, 8, 11, 13]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data['test_gt_idxs'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "together-asset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2607528865337372,\n",
       " -0.18946902453899384,\n",
       " -0.019131429493427277,\n",
       " 0.3027925491333008,\n",
       " 0.3879525065422058,\n",
       " 0.5372862815856934,\n",
       " -0.15449096262454987,\n",
       " -0.09109770506620407,\n",
       " 0.07241824269294739,\n",
       " -0.2592978775501251,\n",
       " -0.2001717984676361,\n",
       " -0.03276039659976959,\n",
       " 0.29945528507232666,\n",
       " 0.3904013931751251,\n",
       " 0.5381737351417542,\n",
       " -0.1515546441078186,\n",
       " -0.08330095559358597,\n",
       " 0.0774780809879303,\n",
       " -0.26492661237716675,\n",
       " -0.19803792238235474,\n",
       " -0.035699404776096344,\n",
       " 0.3032645583152771,\n",
       " 0.40066784620285034,\n",
       " 0.5301229953765869,\n",
       " -0.15448129177093506,\n",
       " -0.07599586993455887,\n",
       " 0.08032497763633728]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_logits[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "soviet-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 515, 4454, 4204, ..., 1603, 3381, 4675])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "minor-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 9., 0., 0., 0., 3., 3., 0., 6.]),\n",
       " array([0.23930625, 0.48039344, 0.72148062, 0.9625678 , 1.20365499,\n",
       "        1.44474217, 1.68582935, 1.92691653, 2.16800372, 2.4090909 ,\n",
       "        2.65017808]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(full_logits[1207]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "posted-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.646452872984402"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(entropy(full_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "impressive-brunswick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 9., 0., 0., 0., 3., 3., 0., 6.]),\n",
       " array([1.00655529, 1.01340389, 1.02025249, 1.0271011 , 1.0339497 ,\n",
       "        1.0407983 , 1.04764691, 1.05449551, 1.06134411, 1.06819272,\n",
       "        1.07504132]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(full_probs[1207]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "smooth-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 0., 1., 5., 0., 6., 0., 6., 3.]),\n",
       " array([-0.66409099, -0.53514907, -0.40620716, -0.27726524, -0.14832332,\n",
       "        -0.0193814 ,  0.10956051,  0.23850243,  0.36744435,  0.49638627,\n",
       "         0.62532818]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(full_logits[373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bridal-graduation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 3., 3., 3., 3., 0., 3., 3., 3.]),\n",
       " array([0.01653922, 0.02089015, 0.02524109, 0.02959202, 0.03394296,\n",
       "        0.03829389, 0.04264483, 0.04699576, 0.0513467 , 0.05569763,\n",
       "        0.06004857]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(full_probs[373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "rotary-transport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.,  0.,  4., 11.,  0.,  0.,  0.,  0.,  0.,  6.]),\n",
       " array([1.01513383, 1.02077151, 1.02640918, 1.03204685, 1.03768453,\n",
       "        1.0433222 , 1.04895988, 1.05459755, 1.06023523, 1.0658729 ,\n",
       "        1.07151057]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAL/UlEQVR4nO3dbYyld1nH8e+PDi3Ugi3upKEP26laiMSn1hGLVaItJEiN5QXBVtG2MdkYg1YjMWt80bclFgMGo65aBcHyohZtLGibaiUm0DhbNtB2xdZa6UKxQ4hoIVoKly/OaZhOdh723Pecsxf9fpLNnMe5r//Oznfuuc/DpqqQJPXzgkUPIEmajQGXpKYMuCQ1ZcAlqSkDLklNLc1zY/v27auVlZV5blKS2jt8+PAXqmp58+VzDfjKygpra2vz3KQktZfkP453uYdQJKkpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqam5vhJTPawcvHNh237spisXtm2pG/fAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktTUjgFPckuSJ5M8sOGylyW5O8nD049n7e2YkqTNdrMH/mfAGzZddhC4p6ouAu6ZnpckzdGOAa+qjwJf3HTxVcB7p6ffC7xp3LEkSTuZ9Rj42VX1xPT054GzR5pHkrRLgx/ErKoCaqvrkxxIspZkbX19fejmJElTswb8P5O8HGD68cmtblhVh6pqtapWl5eXZ9ycJGmzWQN+B3Dt9PS1wF+PM44kabd28zTCW4GPAa9McizJLwA3Aa9P8jDwuul5SdIcLe10g6q6Zourrhh5FknSCfCVmJLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNDQp4kl9L8mCSB5LcmuRFYw0mSdrezAFPci7wK8BqVX03cApw9ViDSZK2N/QQyhLw4iRLwOnA54aPJEnajZkDXlWfBW4GPgM8AXypqu7afLskB5KsJVlbX1+ffVJJ0nMMOYRyFnAVcCFwDvAtSd66+XZVdaiqVqtqdXl5efZJJUnPMeQQyuuAf6+q9ar6KnA78MPjjCVJ2smQgH8GuDTJ6UkCXAEcHWcsSdJOhhwDvw+4Dbgf+NT0cx0aaS5J0g6Whty5qm4EbhxpFknSCfCVmJLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNDQp4kjOT3JbkX5IcTfKasQaTJG1vaeD93w38bVW9OcmpwOkjzCRJ2oWZA57kW4HXAtcBVNXTwNPjjCVJ2smQPfALgXXgT5N8H3AYuKGqvrzxRkkOAAcA9u/fP/PGVg7eOfukAzx205UL2a6k8X2zdWTIMfAl4BLg96vqYuDLwMHNN6qqQ1W1WlWry8vLAzYnSdpoSMCPAceq6r7p+duYBF2SNAczB7yqPg88nuSV04uuAB4aZSpJ0o6GPgvll4EPTJ+B8ihw/fCRJEm7MSjgVXUEWB1nFEnSifCVmJLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqanBAU9ySpJPJPmbMQaSJO3OGHvgNwBHR/g8kqQTMCjgSc4DrgT+eJxxJEm7tTTw/u8CfgN4yVY3SHIAOACwf//+gZt7flk5eOeiR5B0Ept5DzzJTwJPVtXh7W5XVYeqarWqVpeXl2fdnCRpkyGHUC4DfirJY8AHgcuTvH+UqSRJO5o54FX1m1V1XlWtAFcDf19Vbx1tMknStnweuCQ1NfRBTACq6l7g3jE+lyRpd9wDl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWpq5oAnOT/JPyR5KMmDSW4YczBJ0vaWBtz3GeDXq+r+JC8BDie5u6oeGmk2SdI2Zt4Dr6onqur+6en/AY4C5441mCRpe6McA0+yAlwM3Hec6w4kWUuytr6+PsbmJEmMEPAkZwB/CfxqVf335uur6lBVrVbV6vLy8tDNSZKmBgU8yQuZxPsDVXX7OCNJknZjyLNQAvwJcLSqfme8kSRJuzFkD/wy4OeAy5Mcmf5540hzSZJ2MPPTCKvqn4CMOIsk6QT4SkxJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgYFPMkbknw6ySNJDo41lCRpZzMHPMkpwO8BPwG8CrgmyavGGkyStL0he+CvBh6pqker6mngg8BV44wlSdrJ0oD7ngs8vuH8MeCHNt8oyQHgwPTsU0k+PWCb87AP+MKzZ/KOBU4yrues62Q1w993i3XNwHX1su26RujIBce7cEjAd6WqDgGH9no7Y0myVlWri55jbK6rF9fVy6LWNeQQymeB8zecP296mSRpDoYE/J+Bi5JcmORU4GrgjnHGkiTtZOZDKFX1TJK3AX8HnALcUlUPjjbZ4rQ53HOCXFcvrquXhawrVbWI7UqSBvKVmJLUlAGXpKaeNwFPckuSJ5M8sMX1SfK707cF+GSSS6aXf3+SjyV5cHr5T8938u0NWNcFSe5PcmS6tl+c7+Tbm3VdG65/aZJjSd4zn4l3Z8i6knxt+vU6kuSkesLAwHXtT3JXkqNJHkqyMrfBdzDg++vHN3ytjiT53yRvGn3Aqnpe/AFeC1wCPLDF9W8EPgIEuBS4b3r5K4CLpqfPAZ4Azlz0ekZY16nAadPTZwCPAecsej1D17Xh+ncDfwG8Z9FrGWtdwFOLnn+P1nUv8Prp6TOA0xe9njHWteE2LwO+uBfret7sgVfVR5n8JW7lKuB9NfFx4MwkL6+qf62qh6ef43PAk8Dy3k+8OwPW9XRV/d/0Nqdxkv02Nuu6AJL8AHA2cNfeT3pihqzrZDbruqbvn7RUVXdPP89TVfWVOYy8KyN9vd4MfGQv1nVSfdMu2PHeGuDcjTdI8mome67/Nse5htpyXUnOT/LJ6fXvmP6A6uK460ryAuCdwNsXMtVw2/07fFGStSQf35Nfx/fWVut6BfBfSW5P8okkvz19o7wuduwGk9fI3LoXGzfguzT9qfrnwPVV9fVFzzOGqnq8qr4X+E7g2iRnL3qmEfwS8OGqOrboQfbABTV5ufbPAO9K8h2LHmgES8CPMvmB+4PAtwPXLXKgMU278T1MXi8zOgP+DVu+NUCSlwJ3Ar81/TWpkx3f8mC65/0Ak2+kLrZa12uAtyV5DLgZ+PkkN81/vJlt+fWqqmc/PsrkuPHF8x5ugK3WdQw4UpN3NX0G+Csmx5y72On76y3Ah6rqq3uxcQP+DXcw+WZPkkuBL1XVE9O3CfgQk+Ncty12xJlsta7zkrwYIMlZwI8AJ/s7RW503HVV1c9W1f6qWmGyV/e+qur0n41s9fU6K8lpAEn2AZcBDy1y0BN03HUxeUuOM5M8+7jS5XxzrOtZ17BHh09gDu9GeLJIcivwY8C+JMeAG4EXAlTVHwAfZvKI8iPAV4Drp3d9C5NHor8tyXXTy66rqiPzmn07A9b1XcA7kxSTR9BvrqpPzXf6rQ1Y10lt4NfrD5N8ncmO101VddKEbtZ1VdXXkrwduCdJgMPAH819AVsY8u9w+nTI84F/3LP5pk9zkSQ14yEUSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqan/B2rEruauefOdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(full_probs[3834]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "looking-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.65568089949748"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(full_probs[373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "elder-trail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5999638296259455"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_probs_10_20 = np.array(full_probs)[(gt_counts > 10) & (gt_counts <20)]\n",
    "np.mean(entropy(full_probs_10_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "conservative-charles",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.632594633883542"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_probs_12_15 = np.array(full_probs)[(gt_counts > 12) & (gt_counts <25)]\n",
    "np.mean(entropy(full_probs_12_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "compatible-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.754887502163469"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_probs = np.array([1/27.0]*27)\n",
    "entropy(even_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "distant-silicon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7004397181410926"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_pos_probs = np.array([1/13.0]*13)\n",
    "entropy(half_pos_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "persistent-split",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 28 artists>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_idxs_373 = sorted(game_data['test_gt_idxs'][373])\n",
    "not_gt_idxs_373 = [i for i in range(27) if not i in gt_idxs_373]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.ylim(0.0, 0.1)\n",
    "\n",
    "plt.axhline(y=1./gt_counts[373], color='r', linestyle='-')\n",
    "\n",
    "plt.bar(\n",
    "    [str(idx) for idx in gt_idxs_373] + [' '] + [str(idx) for idx in not_gt_idxs_373],  \n",
    "    list(full_probs[373][gt_idxs_373]) + [0] + list(full_probs[373][not_gt_idxs_373]),\n",
    "    color='k'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "painted-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.65568089949748"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(entropy(full_probs[373]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "introductory-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.646452872984402"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(entropy(full_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "american-surprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5999638296259455"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_probs_10_20 = np.array(full_probs)[(gt_counts > 10) & (gt_counts <20)]\n",
    "np.mean(entropy(full_probs_10_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-consideration",
   "metadata": {},
   "source": [
    "## Embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "every-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import BatchFetcher\n",
    "from metrics import find_nn, analogy, find_cos, find_dotproduct, find_euclidean\n",
    "from dataraw_sampling import construct_card_idx_lookup\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "statewide-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data----------\n",
      "num_attributes : 3\n",
      "num_attr_vals : 3\n",
      "key_support_size : 27\n",
      "N_pairs : 8\n",
      "union_only : True\n",
      "max_len_q : 16\n",
      "len_k : 1\n",
      "train_gt_idxs length : 0\n",
      "val_gt_idxs length : 5120\n",
      "test_gt_idxs length : 5120\n",
      "train_tokens length : 0\n",
      "val_tokens length : 5120\n",
      "test_tokens length : 5120\n",
      "test_marginal_gt_idxs length : 5120\n",
      "test_marginal_tokens length : 5120\n",
      "vocab_size : 74\n",
      "symbol_vocab_token_lookup : {'(': 64, ')': 65, 'NULL': 66, 'SEP': 67, 'SOS': 68, 'EOS': 69, 'PAD': 70, 'PLH': 71, '|': 72, '!': 73}\n",
      "vocab_by_property : False\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "cuda_device = trainmodule.model._parameters['key_bias_terms'].device\n",
    "\n",
    "game_data = main.load_data(args.data_path)\n",
    "batch_fecther = BatchFetcher(\n",
    "    raw_data = game_data, device=cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "minimal-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [[(0,1,3),(0,0,0)], [(0,1,3),(1,2,0)]]\n",
    "keys = [[(0,0,0)],[(0,1,0)],[(2,2,2)]]\n",
    "X_query, X_key = batch_fecther.make_query_batch(X_query_properties=queries, X_key_properties=None, X_key=[i for i in range(game_data['key_support_size'])])\n",
    "query_repr, key_repr = trainmodule.pull_repr(X_query, X_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "center-assurance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5362,  0.1149,  0.2039, -0.6667],\n",
       "        [ 0.7600,  0.8585,  0.1213, -0.7373]], device='cuda:1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "automotive-burst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1285,  0.3697,  0.1037, -0.3848],\n",
       "        [ 0.0716,  0.3787,  0.2297,  0.2128],\n",
       "        [ 0.2780,  0.3077, -0.4586,  0.2832],\n",
       "        [ 0.2182, -0.1689,  0.2326, -0.4170],\n",
       "        [ 0.1571, -0.1834,  0.3700,  0.1400],\n",
       "        [ 0.3425, -0.2402, -0.2569,  0.1979],\n",
       "        [-0.4150, -0.1103,  0.0543, -0.3910],\n",
       "        [-0.4920, -0.1250,  0.1852,  0.1586],\n",
       "        [-0.2886, -0.1841, -0.4735,  0.2308],\n",
       "        [ 0.1239,  0.3700,  0.0996, -0.3745],\n",
       "        [ 0.0675,  0.3882,  0.2190,  0.2171],\n",
       "        [ 0.2672,  0.3158, -0.4508,  0.2811],\n",
       "        [ 0.2115, -0.1694,  0.2412, -0.4202],\n",
       "        [ 0.1557, -0.1894,  0.3686,  0.1346],\n",
       "        [ 0.3394, -0.2440, -0.2548,  0.1889],\n",
       "        [-0.4050, -0.1114,  0.0601, -0.3999],\n",
       "        [-0.4858, -0.1274,  0.1860,  0.1566],\n",
       "        [-0.2858, -0.1858, -0.4659,  0.2312],\n",
       "        [ 0.1243,  0.3742,  0.1115, -0.3745],\n",
       "        [ 0.0703,  0.3855,  0.2255,  0.2105],\n",
       "        [ 0.2640,  0.3147, -0.4559,  0.2879],\n",
       "        [ 0.2024, -0.1831,  0.2370, -0.4243],\n",
       "        [ 0.1671, -0.1943,  0.3650,  0.1346],\n",
       "        [ 0.3400, -0.2299, -0.2457,  0.1894],\n",
       "        [-0.4061, -0.1090,  0.0512, -0.3931],\n",
       "        [-0.4818, -0.1298,  0.1847,  0.1638],\n",
       "        [-0.2854, -0.1879, -0.4675,  0.2307]], device='cuda:1')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the linear analogy for keys first\n",
    "key_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "earlier-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_repr_normalized = key_repr / torch.linalg.norm(key_repr, ord=2, dim=-1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acting-agenda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 81.,   0.,   0.,   0.,   0.,  54., 108.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  81.,   0.,   0.,   0.,   0.,   0.,  27.,  54.,   0.,\n",
       "          0.,   0.,   0.,   0.,  81.,   0.,   0.,   0.,  81.,   0.,   0.,\n",
       "          0.,  81.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,  81.]),\n",
       " array([-0.69899642, -0.6650165 , -0.63103657, -0.59705664, -0.56307671,\n",
       "        -0.52909678, -0.49511685, -0.46113693, -0.427157  , -0.39317707,\n",
       "        -0.35919714, -0.32521721, -0.29123728, -0.25725735, -0.22327743,\n",
       "        -0.1892975 , -0.15531757, -0.12133764, -0.08735771, -0.05337778,\n",
       "        -0.01939785,  0.01458207,  0.048562  ,  0.08254193,  0.11652186,\n",
       "         0.15050179,  0.18448172,  0.21846164,  0.25244157,  0.2864215 ,\n",
       "         0.32040143,  0.35438136,  0.38836129,  0.42234122,  0.45632114,\n",
       "         0.49030107,  0.524281  ,  0.55826093,  0.59224086,  0.62622079,\n",
       "         0.66020072,  0.69418064,  0.72816057,  0.7621405 ,  0.79612043,\n",
       "         0.83010036,  0.86408029,  0.89806021,  0.93204014,  0.96602007,\n",
       "         1.        ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for i in range(27):\n",
    "    nn_idx, nn_dists = find_nn(v=key_repr_normalized[0], Wv=key_repr_normalized, similarity_fn=find_dotproduct, k=27)\n",
    "    distances += nn_dists.tolist()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(distances, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "covered-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.267389101506436, 0.007929454247156778, 5.780572146177292)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(distances), np.mean(distances), np.sum(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "constitutional-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "card2idx_lookup, idx2card_lookup = construct_card_idx_lookup(game_data['num_attributes'], game_data['num_attr_vals'])\n",
    "\n",
    "def linear_analogy_by_props(propertiesA, propertiesB, propertiesC, card2idx_lookup, idx2card_lookup):\n",
    "    keyidxA = card2idx_lookup[propertiesA]\n",
    "    keyidxB = card2idx_lookup[propertiesB]\n",
    "    keyidxC = card2idx_lookup[propertiesC]\n",
    "\n",
    "    print(keyidxA, keyidxB, keyidxC)\n",
    "\n",
    "    vA = key_repr[keyidxA]\n",
    "    vB = key_repr[keyidxB]\n",
    "    vC = key_repr[keyidxC]\n",
    "\n",
    "    nns_idx, nns_distances = analogy(vA, vB, vC, key_repr, similarity_fn=find_cos, k=None)\n",
    "    nns_properties = [idx2card_lookup[idx.item()] for idx in nns_idx]\n",
    "    print(nns_idx, nns_distances)\n",
    "    print(nns_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "underlying-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 13\n",
      "torch.Size([16])\n",
      "tensor([13, 12, 14, 16, 23,  5,  9, 21,  0, 22,  1, 18,  2,  4, 15, 26, 20,  8,\n",
      "         3, 24, 10,  6, 11, 19, 17,  7, 25], device='cuda:1') tensor([ 0.6625,  0.4359,  0.3446,  0.3238,  0.2579,  0.1624,  0.1402,  0.0975,\n",
      "         0.0765,  0.0410,  0.0308,  0.0256,  0.0198,  0.0019, -0.0131, -0.0144,\n",
      "        -0.0170, -0.0299, -0.0357, -0.0589, -0.0685, -0.0906, -0.1622, -0.1782,\n",
      "        -0.3266, -0.3419, -0.7537], device='cuda:1')\n",
      "[(1, 1, 1), (1, 1, 0), (1, 1, 2), (1, 2, 1), (2, 1, 2), (0, 1, 2), (1, 0, 0), (2, 1, 0), (0, 0, 0), (2, 1, 1), (0, 0, 1), (2, 0, 0), (0, 0, 2), (0, 1, 1), (1, 2, 0), (2, 2, 2), (2, 0, 2), (0, 2, 2), (0, 1, 0), (2, 2, 0), (1, 0, 1), (0, 2, 0), (1, 0, 2), (2, 0, 1), (1, 2, 2), (0, 2, 1), (2, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# vec 16\n",
    "linear_analogy_by_props(\n",
    "    propertiesA = (2,2,1), \n",
    "    propertiesB = (2,2,0), \n",
    "    propertiesC = (1,1,1), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ultimate-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 25 8\n",
      "torch.Size([16])\n",
      "tensor([ 8,  2, 25, 26, 11, 17, 19, 20, 23, 24,  1,  7, 15, 10, 22,  0,  6,  5,\n",
      "         9, 14,  3, 18,  4, 12, 13, 16, 21], device='cuda:1') tensor([ 0.7596,  0.6634,  0.5691,  0.2043,  0.1940,  0.1902,  0.1802,  0.1696,\n",
      "         0.1669,  0.1637,  0.1636,  0.1083,  0.0911,  0.0883,  0.0881,  0.0621,\n",
      "         0.0537,  0.0247,  0.0077, -0.0104, -0.0909, -0.0942, -0.0956, -0.1043,\n",
      "        -0.1195, -0.1235, -0.1400], device='cuda:1')\n",
      "[(0, 2, 2), (0, 0, 2), (2, 2, 1), (2, 2, 2), (1, 0, 2), (1, 2, 2), (2, 0, 1), (2, 0, 2), (2, 1, 2), (2, 2, 0), (0, 0, 1), (0, 2, 1), (1, 2, 0), (1, 0, 1), (2, 1, 1), (0, 0, 0), (0, 2, 0), (0, 1, 2), (1, 0, 0), (1, 1, 2), (0, 1, 0), (2, 0, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 2, 1), (2, 1, 0)]\n"
     ]
    }
   ],
   "source": [
    "# vec 16\n",
    "linear_analogy_by_props(\n",
    "    propertiesA = (0,2,1), \n",
    "    propertiesB = (2,2,1), \n",
    "    propertiesC = (0,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "latest-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 19 26\n",
      "torch.Size([16])\n",
      "tensor([26, 24, 15, 23, 14, 25, 19, 22, 10, 13, 17, 12,  8, 20,  5,  6,  9,  2,\n",
      "         1, 11,  7, 16, 18,  4,  0,  3, 21], device='cuda:1') tensor([ 0.9753,  0.8072,  0.2070,  0.1994,  0.1990,  0.1950,  0.1725,  0.1418,\n",
      "         0.1245,  0.1155,  0.1090,  0.0992,  0.0880,  0.0651,  0.0485,  0.0293,\n",
      "         0.0229,  0.0038, -0.0039, -0.0489, -0.0514, -0.0604, -0.0615, -0.0621,\n",
      "        -0.0839, -0.1860, -0.2537], device='cuda:1')\n",
      "[(2, 2, 2), (2, 2, 0), (1, 2, 0), (2, 1, 2), (1, 1, 2), (2, 2, 1), (2, 0, 1), (2, 1, 1), (1, 0, 1), (1, 1, 1), (1, 2, 2), (1, 1, 0), (0, 2, 2), (2, 0, 2), (0, 1, 2), (0, 2, 0), (1, 0, 0), (0, 0, 2), (0, 0, 1), (1, 0, 2), (0, 2, 1), (1, 2, 1), (2, 0, 0), (0, 1, 1), (0, 0, 0), (0, 1, 0), (2, 1, 0)]\n"
     ]
    }
   ],
   "source": [
    "# vec 16\n",
    "linear_analogy_by_props(\n",
    "    propertiesA = (0,2,1), \n",
    "    propertiesB = (2,0,1), \n",
    "    propertiesC = (2,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "natural-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 24\n",
      "torch.Size([16])\n",
      "tensor([24, 26, 15,  6, 25, 14, 12, 17, 13, 23,  1, 19, 22, 10,  9,  7,  8,  5,\n",
      "        18,  4, 16, 20,  2,  0, 21,  3, 11], device='cuda:1') tensor([ 1.0000e+00,  8.0590e-01,  7.1588e-01,  3.3758e-01,  2.6389e-01,\n",
      "         1.4120e-01,  1.2782e-01,  7.0533e-02,  5.3902e-02,  5.0637e-02,\n",
      "         4.9744e-02,  4.2136e-02,  3.9595e-02,  2.7262e-02,  8.0941e-04,\n",
      "        -9.2919e-05, -1.8811e-02, -3.5239e-02, -4.4427e-02, -6.1315e-02,\n",
      "        -6.8744e-02, -8.2491e-02, -8.9917e-02, -9.1402e-02, -1.1744e-01,\n",
      "        -1.7063e-01, -1.8255e-01], device='cuda:1')\n",
      "[(2, 2, 0), (2, 2, 2), (1, 2, 0), (0, 2, 0), (2, 2, 1), (1, 1, 2), (1, 1, 0), (1, 2, 2), (1, 1, 1), (2, 1, 2), (0, 0, 1), (2, 0, 1), (2, 1, 1), (1, 0, 1), (1, 0, 0), (0, 2, 1), (0, 2, 2), (0, 1, 2), (2, 0, 0), (0, 1, 1), (1, 2, 1), (2, 0, 2), (0, 0, 2), (0, 0, 0), (2, 1, 0), (0, 1, 0), (1, 0, 2)]\n"
     ]
    }
   ],
   "source": [
    "# vec 16\n",
    "linear_analogy_by_props(\n",
    "    propertiesA = (2,2,1), \n",
    "    propertiesB = (2,2,1), \n",
    "    propertiesC = (2,2,0), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "separated-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 19 8\n",
      "torch.Size([16])\n",
      "tensor([ 8,  2, 20, 23, 11, 19,  5,  0, 10,  1,  9, 26, 22, 14, 12, 24, 17, 18,\n",
      "        15,  6,  4,  3, 21, 25, 13,  7, 16], device='cuda:1') tensor([ 0.9787,  0.8681,  0.2565,  0.2357,  0.2029,  0.1656,  0.1350,  0.1323,\n",
      "         0.1244,  0.1075,  0.1044,  0.0708,  0.0520,  0.0360,  0.0177, -0.0134,\n",
      "        -0.0149, -0.0178, -0.0231, -0.0232, -0.0708, -0.0786, -0.0800, -0.1057,\n",
      "        -0.1314, -0.1510, -0.2267], device='cuda:1')\n",
      "[(0, 2, 2), (0, 0, 2), (2, 0, 2), (2, 1, 2), (1, 0, 2), (2, 0, 1), (0, 1, 2), (0, 0, 0), (1, 0, 1), (0, 0, 1), (1, 0, 0), (2, 2, 2), (2, 1, 1), (1, 1, 2), (1, 1, 0), (2, 2, 0), (1, 2, 2), (2, 0, 0), (1, 2, 0), (0, 2, 0), (0, 1, 1), (0, 1, 0), (2, 1, 0), (2, 2, 1), (1, 1, 1), (0, 2, 1), (1, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# vec 16\n",
    "linear_analogy_by_props(\n",
    "    propertiesA = (0,2,1), \n",
    "    propertiesB = (2,0,1), \n",
    "    propertiesC = (0,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "threatened-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 19 17\n",
      "torch.Size([16])\n",
      "tensor([17, 25,  1,  6,  3, 14, 22, 11,  0, 15, 24, 26, 21,  2,  8,  7,  4, 13,\n",
      "        16,  9, 12, 18, 23,  5, 19, 20, 10], device='cuda:1') tensor([ 0.7326,  0.2305,  0.2158,  0.1826,  0.1689,  0.1486,  0.1200,  0.0872,\n",
      "         0.0645,  0.0563,  0.0404,  0.0294, -0.0498, -0.0510, -0.0714, -0.0722,\n",
      "        -0.0835, -0.0843, -0.1142, -0.1253, -0.1441, -0.1522, -0.1546, -0.1856,\n",
      "        -0.1955, -0.2414, -0.6082], device='cuda:1')\n",
      "[(1, 2, 2), (2, 2, 1), (0, 0, 1), (0, 2, 0), (0, 1, 0), (1, 1, 2), (2, 1, 1), (1, 0, 2), (0, 0, 0), (1, 2, 0), (2, 2, 0), (2, 2, 2), (2, 1, 0), (0, 0, 2), (0, 2, 2), (0, 2, 1), (0, 1, 1), (1, 1, 1), (1, 2, 1), (1, 0, 0), (1, 1, 0), (2, 0, 0), (2, 1, 2), (0, 1, 2), (2, 0, 1), (2, 0, 2), (1, 0, 1)]\n"
     ]
    }
   ],
   "source": [
    "# vec 16\n",
    "linear_analogy_by_props(\n",
    "    propertiesA = (1,0,1), \n",
    "    propertiesB = (2,0,1), \n",
    "    propertiesC = (1,2,2), \n",
    "    card2idx_lookup=card2idx_lookup, \n",
    "    idx2card_lookup=idx2card_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-coordinate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
